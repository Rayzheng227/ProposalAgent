import arxiv
from langchain_community.tools import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging

"""
APIçš„é…ç½®â€”â€”[TODO]åŒæ­¥åˆ°ç½‘ä¸Šå‰è®°å¾—ä¿®æ”¹ï¼
"""
base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
DASHSCOPE_API_KEY = "sk-eafdf8e1d0fb4717a883c87788e76182"

Tavily_API_KEY = "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"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

class ProposalState(TypedDict):
    """å®šä¹‰Proposalç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŠ¶æ€"""
    research_field: str
    query: str
    arxiv_papers: List[Dict]
    web_search_results: List[Dict]
    background: str
    objectives: str
    methodology: str
    timeline: str
    expected_outcomes: str
    final_proposal: str
    messages: List[Any]
    research_plan: str
    available_tools: List[Dict]  # å­˜å‚¨å¯ç”¨å·¥å…·ä¿¡æ¯
    execution_plan: List[Dict]  # å¯æ‰§è¡Œçš„è®¡åˆ’
    execution_memory: List[Dict]  # å·²ç»æ‰§è¡Œçš„è®°å¿†
    current_step: int  # å½“å‰æ‰§è¡Œçš„æ­¥éª¤
    max_iterations: int  # æœ€å¤§è¿­ä»£æ¬¡æ•°



@tool
def search_arxiv_papers_tool(query: str, max_results: int = 5, Download = True) -> List[Dict]:
    """æœç´¢å¹¶ä¸‹è½½ArXivè®ºæ–‡çš„å·¥å…·
    
    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ç¯‡
    
    Returns:
        åŒ…å«è®ºæ–‡ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        ä»¥åŠå­˜å‚¨åœ¨Papersç›®å½•ä¸‹çš„å‚è€ƒæ–‡çŒ®
    """

    try:
        client = arxiv.Client()
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate
        )
        
        papers_dir = "./Papers"
        if not os.path.exists(papers_dir):
            os.makedirs(papers_dir)
        
        papers = []
        for paper in client.results(search):
            paper_info = {
                "title": paper.title,
                "authors": [author.name for author in paper.authors],
                "summary": paper.summary[:300] + "...",  # æˆªæ–­æ‘˜è¦
                "published": paper.published.strftime("%Y-%m-%d"),
                "pdf_url": paper.pdf_url,
                "categories": paper.categories,
                "arxiv_id": paper.entry_id.split('/')[-1]
            }
            if Download:
                try:
                    # ä¸‹è½½PDF
                    safe_title = "".join(c for c in paper.title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    safe_title = safe_title[:50]
                    filename = f"{paper_info['arxiv_id']}_{safe_title}.pdf"
                    
                    paper.download_pdf(dirpath=papers_dir, filename=filename)
                    paper_info["local_pdf_path"] = os.path.join(papers_dir, filename)
                    
                except Exception as e:
                    paper_info["local_pdf_path"] = None
                
            papers.append(paper_info)
        
        return papers
    
    except Exception as e:
        return [{"error": f"ArXivæœç´¢å¤±è´¥: {str(e)}"}]
    

# å®šä¹‰ç½‘ç»œæœç´¢å·¥å…·
@tool
def search_web_content_tool(query: str) -> List[Dict]:
    """ä½¿ç”¨Tavilyæœç´¢ç½‘ç»œå†…å®¹çš„å·¥å…·
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY
        tavily_tool = TavilySearchResults(
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=True
        )
        
        results = tavily_tool.invoke({"query": query})
        return results
    
    except Exception as e:
        return [{"error": f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}"}]
    

class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key= DASHSCOPE_API_KEY,
            model="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0
        )
        
        # è®¾ç½®Tavily APIå¯†é’¥
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY

        self.tools = [search_arxiv_papers_tool, search_web_content_tool]
        self.tools_description = self.load_tools_description()
        self.agent_with_tools = create_react_agent(self.llm, self.tools)
        self.workflow = self._build_workflow()

    
    def load_tools_description(self) -> List[Dict]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·¥å…·æè¿°"""
        try:
            with open('tools.json', 'r', encoding='utf-8') as f:
                tools_description = json.load(f)
            return tools_description
        except FileNotFoundError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        except json.JSONDecodeError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        

    def get_tools_info_text(self) -> str:
        """å°†å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if not self.tools_description:
            return "æš‚æ— å¯ç”¨å·¥å…·ä¿¡æ¯"
        
        tools_text = "å¯ç”¨å·¥å…·åˆ—è¡¨:\n\n"
        for tool_info in self.tools_description:
            func_info = tool_info.get("function", {})
            name = func_info.get("name", "æœªçŸ¥å·¥å…·")
            description = func_info.get("description", "æ— æè¿°")
            
            tools_text += f"ğŸ”§ **{name}**\n"
            tools_text += f"   æè¿°: {description}\n"
            
            # æ·»åŠ å‚æ•°ä¿¡æ¯
            params = func_info.get("parameters", {}).get("properties", {})
            if params:
                tools_text += f"   å‚æ•°:\n"
                for param_name, param_info in params.items():
                    param_desc = param_info.get("description", "æ— æè¿°")
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    required = param_name in func_info.get("parameters", {}).get("required", [])
                    required_text = "å¿…éœ€" if required else "å¯é€‰"
                    tools_text += f"     - {param_name} ({param_type}, {required_text}): {param_desc}\n"
            
            tools_text += "\n"
        
        return tools_text
    

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“çš„è§„åˆ’(ä¸åŒäºProposal)"""
        research_field = state["research_field"]

        tools_info = self.get_tools_info_text()

        master_planning_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç§‘ç ”ä¸“å®¶å’Œé¡¹ç›®è§„åˆ’å¸ˆã€‚ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªç ”ç©¶é—®é¢˜æˆ–é¢†åŸŸï¼š"{research_field}"

        ä½ æœ‰ä»¥ä¸‹çš„å·¥å…·å¯ä»¥ä½¿ç”¨:{tools_info}

        è¯·ä½ åˆ¶å®šä¸€ä¸ªå…¨é¢çš„ç ”ç©¶è®¡åˆ’ï¼Œè¿™ä¸ªè®¡åˆ’åº”è¯¥åŒ…æ‹¬ï¼š

        1. **é—®é¢˜ç†è§£ä¸åˆ†æ**
        - å¯¹ç ”ç©¶é—®é¢˜çš„æ·±å…¥ç†è§£
        - é—®é¢˜çš„é‡è¦æ€§å’Œç ”ç©¶ä»·å€¼
        - é¢„æœŸçš„ç ”ç©¶éš¾ç‚¹å’ŒæŒ‘æˆ˜

        2. **æ–‡çŒ®è°ƒç ”è®¡åˆ’**
        - éœ€è¦æ£€ç´¢å“ªäº›å…³é”®è¯
        - é‡ç‚¹å…³æ³¨å“ªäº›ç ”ç©¶æ–¹å‘
        - éœ€è¦æŸ¥æ‰¾å“ªäº›ç±»å‹çš„æ–‡çŒ®ï¼ˆç†è®ºã€å®éªŒã€ç»¼è¿°ç­‰ï¼‰
        - æ–‡çŒ®æ£€ç´¢çš„ä¼˜å…ˆçº§

        3. **ç ”ç©¶ç›®æ ‡è®¾å®š**
        - æ€»ä½“ç ”ç©¶ç›®æ ‡
        - åˆ†è§£çš„å­ç›®æ ‡
        - å„ç›®æ ‡çš„ä¼˜å…ˆçº§

        4. **æŠ€æœ¯è·¯çº¿è§„åˆ’**
        - é‡‡ç”¨ä»€ä¹ˆç ”ç©¶æ–¹æ³•
        - æŠ€æœ¯å®ç°æ€è·¯
        - å®éªŒè®¾è®¡æ–¹æ¡ˆ

        5. **å·¥ä½œå®‰æ’**
        - å„é˜¶æ®µçš„å·¥ä½œå†…å®¹
        - æ—¶é—´åˆ†é…
        - é‡Œç¨‹ç¢‘è®¾å®š

        6. **é¢„æœŸæˆæœ**
        - æœŸæœ›è¾¾åˆ°çš„ç›®æ ‡
        - å¯äº¤ä»˜çš„æˆæœ

        è¯·åŸºäº"{research_field}"è¿™ä¸ªç ”ç©¶é—®é¢˜ï¼Œåˆ¶å®šä¸€ä¸ªè¯¦ç»†ã€å¯è¡Œçš„ç ”ç©¶è®¡åˆ’ã€‚
        è®¡åˆ’è¦å…·æœ‰æŒ‡å¯¼æ€§ï¼Œåç»­çš„æ‰€æœ‰å·¥ä½œéƒ½å°†åŸºäºè¿™ä¸ªè®¡åˆ’æ¥æ‰§è¡Œã€‚
        """
        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field}' åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
        response = self.llm.invoke([HumanMessage(content=master_planning_prompt)])
        
        state["research_plan"] = response.content
        state["available_tools"] = self.tools_description
        state["execution_memory"] = []
        state["current_step"] = 0
        state["max_iterations"] = 10

        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")

        return state
    


    def plan_analysis_node(self, state: ProposalState) -> ProposalState:
        """è§£æç ”ç©¶è®¡åˆ’,ç”Ÿæˆå¯æ‰§è¡Œæ­¥éª¤"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        tools_info = self.get_tools_info_text()
        execution_memory = state.get("execution_memory", [])


        memory_text = ""
        if execution_memory:
            memory_text = "\n\næ‰§è¡Œå†å²:\n"
            for step in execution_memory:
                description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
                result = step.get('result', 'æ— ç»“æœ')
                success = step.get('success', False)
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                memory_text += f"- {description}: {status} - {result[:100]}...\n"

        
        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        plan_analysis_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç§‘ç ”ä¸“å®¶å’Œæ–‡çŒ®æ£€ç´¢ä¸“å®¶ã€‚ç”¨æˆ·äº†è§£äº†ä¸€ä¸ªç ”ç©¶é¢†åŸŸï¼š"{research_field}"ï¼Œå¹¶åˆ¶å®šäº†ä¸€ä¸ªè®¡åˆ’ã€‚
        è¯·åŸºäºä»¥ä¸‹çš„ç ”ç©¶è®¡åˆ’ï¼Œåˆ†æå¹¶ç¡®ç«‹æ¥ä¸‹æ¥çš„æ­¥éª¤
        ç ”ç©¶è®¡åˆ’ï¼š
        {research_plan}
        ä½ æœ‰ä»¥ä¸‹çš„å·¥å…·å¯ä»¥è°ƒç”¨ï¼š{tools_info}

        {memory_text}
        
        åŸºäºä¸Šè¿°ç ”ç©¶è®¡åˆ’å’Œæ‰§è¡Œå†å²ï¼Œè¯·ç”Ÿæˆæ¥ä¸‹æ¥éœ€è¦æ‰§è¡Œçš„å…·ä½“æ­¥éª¤ã€‚æ¯ä¸ªæ­¥éª¤åº”è¯¥æ˜¯å¯æ‰§è¡Œçš„è¡ŒåŠ¨ã€‚
        
        è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›æ‰§è¡Œè®¡åˆ’ï¼š
        {{
            "steps": [
                {{
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {{"query": "å…³é”®è¯", "max_results": 5}},
                    "description": "æœç´¢ArXivä¸Šå…³äºxxxçš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }},
                {{
                    "step_id": 2,
                    "action": "search_web_content",
                    "parameters": {{"query": "å…³é”®è¯"}},
                    "description": "æœç´¢ç½‘ç»œä¸Šå…³äºxxxçš„æœ€æ–°ä¿¡æ¯",
                    "expected_outcome": "è·å–æœ€æ–°çš„ç ”ç©¶åŠ¨æ€"
                }}
            ]
        }}
        
        æ³¨æ„ï¼š
        1. å¦‚æœä¹‹å‰çš„æ‰§è¡Œç»“æœä¸ç†æƒ³ï¼Œè¯·è°ƒæ•´ç­–ç•¥
        2. æ¯æ¬¡æœ€å¤šç”Ÿæˆ3-5ä¸ªæ­¥éª¤
        3. æ­¥éª¤åº”è¯¥æ˜¯å…·ä½“çš„ã€å¯æ‰§è¡Œçš„
        4. è€ƒè™‘æ‰§è¡Œå†å²ï¼Œé¿å…é‡å¤æ— æ•ˆçš„æœç´¢
        """
        logging.info("ğŸ” Agentæ­£åœ¨åˆ†æè®¡åˆ’å¹¶ç”Ÿæˆæ‰§è¡Œæ­¥éª¤...")
        response = self.llm.invoke([HumanMessage(content=plan_analysis_prompt)])
        logging.info("ç”Ÿæˆè®¡åˆ’", response.content)
        try:
            # è§£æJSONå“åº”
            response_text = response.content.strip()
           # å¦‚æœå“åº”åŒ…å«```jsonï¼Œåˆ™æå–JSONéƒ¨åˆ†
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            elif "```" in response_text:
                start = response_text.find("```") + 3
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            
            plan_data = json.loads(response_text)
            state["execution_plan"] = plan_data.get("steps", [])
        except json.JSONDecodeError:
            logging.error("æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’JSONï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
            logging.error(f"åŸå§‹å“åº”: {response.content[:500]}...")
            # é»˜è®¤æ‰§è¡Œè®¡åˆ’
            state["execution_plan"] = [
                {
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {"query": research_field, "max_results": 5},
                    "description": f"æœç´¢ArXivä¸Šå…³äº{research_field}çš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }
            ]
        
        logging.info(f"âœ… ç”Ÿæˆäº† {len(state['execution_plan'])} ä¸ªæ‰§è¡Œæ­¥éª¤")

        return state
    

    def execute_step_node(self, state: ProposalState) -> ProposalState:
        """æ‰§è¡Œå½“å‰æ­¥éª¤"""
        execution_plan = state.get("execution_plan", [])
        current_step = state.get("current_step", 0)
        execution_memory = state.get("execution_memory", [])
        
        if current_step >= len(execution_plan):
            logging.info("æ‰€æœ‰æ­¥éª¤å·²æ‰§è¡Œå®Œæˆ")
            return state
        
        current_action = execution_plan[current_step]
        action_name = current_action.get("action")
        parameters = current_action.get("parameters", {})
        description = current_action.get("description", "")
        
        logging.info(f"ğŸš€ æ‰§è¡Œæ­¥éª¤ {current_step + 1}: {description}")
        
        # æ‰§è¡Œå¯¹åº”çš„å·¥å…·
        result = None
        try:
            if action_name == "search_arxiv_papers":
                result = search_arxiv_papers_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["arxiv_papers"].extend(result)
                    
            elif action_name == "search_web_content":
                result = search_web_content_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["web_search_results"].extend(result)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": str(result)[:200] if result else "æ— ç»“æœ",
                "success": result is not None and (not isinstance(result, list) or len(result) > 0)
            })
            
        except Exception as e:
            logging.error(f"æ‰§è¡Œæ­¥éª¤å¤±è´¥: {e}")
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False
            })
        
        state["execution_memory"] = execution_memory
        state["current_step"] = current_step + 1
        
        return state
    

    def should_continue(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–é‡æ–°è§„åˆ’"""
        current_step = state.get("current_step", 0)
        execution_plan = state.get("execution_plan", [])
        execution_memory = state.get("execution_memory", [])
        max_iterations = state.get("max_iterations", 10)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if len(execution_memory) >= max_iterations:
            return "end"
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ­¥éª¤è¦æ‰§è¡Œ
        if current_step < len(execution_plan):
            return "execute_step"
        
        # æ£€æŸ¥æœ€è¿‘çš„æ‰§è¡Œç»“æœ
        recent_results = execution_memory[-3:] if len(execution_memory) >= 3 else execution_memory
        successful_results = [r for r in recent_results if r.get("success", False)]
        
        # å¦‚æœæœ€è¿‘çš„ç»“æœéƒ½ä¸æˆåŠŸï¼Œæˆ–è€…éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œé‡æ–°è§„åˆ’
        if len(successful_results) < len(recent_results) * 0.5:
            logging.info("æœ€è¿‘æ‰§è¡Œç»“æœä¸ç†æƒ³ï¼Œé‡æ–°è§„åˆ’...")
            return "plan_analysis"
        
        # æ£€æŸ¥æ˜¯å¦æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        
        if len(arxiv_papers) < 3 and len(web_results) < 3:
            logging.info("ä¿¡æ¯æ”¶é›†ä¸è¶³ï¼Œç»§ç»­è§„åˆ’...")
            return "plan_analysis"
        
        return "end"
    
    
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("create_master_plan", self.create_master_plan_node)
        workflow.add_node("plan_analysis", self.plan_analysis_node)
        workflow.add_node("execute_step", self.execute_step_node)
        
        # å®šä¹‰æµç¨‹
        workflow.set_entry_point("create_master_plan")
        workflow.add_edge("create_master_plan", "plan_analysis")
        
        # æ¡ä»¶è¾¹ï¼šæ ¹æ®æ‰§è¡Œæƒ…å†µå†³å®šä¸‹ä¸€æ­¥
        workflow.add_conditional_edges(
            "plan_analysis",
            lambda state: "execute_step",  # ç”Ÿæˆè®¡åˆ’åæ‰§è¡Œæ­¥éª¤
            {"execute_step": "execute_step"}
        )
        
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue,  # æ ¹æ®æ‰§è¡Œç»“æœå†³å®šä¸‹ä¸€æ­¥
            {
                "execute_step": "execute_step",  # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
                "plan_analysis": "plan_analysis",  # é‡æ–°è§„åˆ’
                "end": END  # ç»“æŸ
            }
        )
        
        return workflow.compile()
    
    def generate_proposal(self, research_field: str) -> Dict[str, Any]:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦"""
        initial_state = ProposalState(
            research_field=research_field,
            query="",
            arxiv_papers=[],
            web_search_results=[],
            background="",
            objectives="",
            methodology="",
            timeline="",
            expected_outcomes="",
            final_proposal="",
            messages=[],
            research_plan="",
            available_tools=[],
            execution_plan=[],
            execution_memory=[],
            current_step=0,
            max_iterations=10
        )
        
        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶é—®é¢˜: '{research_field}'")
        result = self.workflow.invoke(initial_state)
        return result

if __name__ == "__main__":
    agent = ProposalAgent()
    research_question = "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"
    result = agent.generate_proposal(research_question)
    print("\n" + "="*60)
    print("ç ”ç©¶è®¡åˆ’:")
    print(result["research_plan"])
    print("\n" + "="*60)
    print(f"æ‰§è¡Œå†å²: {len(result['execution_memory'])} ä¸ªæ­¥éª¤")
    for memory in result["execution_memory"]:
        print(f"- {memory['description']}: {'æˆåŠŸ' if memory['success'] else 'å¤±è´¥'}")
    print("\n" + "="*60)
    print(f"æ”¶é›†åˆ°çš„è®ºæ–‡: {len(result['arxiv_papers'])} ç¯‡")
    print(f"ç½‘ç»œæœç´¢ç»“æœ: {len(result['web_search_results'])} æ¡")