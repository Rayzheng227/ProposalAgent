import arxiv
from langchain_community.tools import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging
from prompts import *

"""
APIçš„é…ç½®â€”â€”[TODO]åŒæ­¥åˆ°ç½‘ä¸Šå‰è®°å¾—ä¿®æ”¹ï¼
"""
base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
DASHSCOPE_API_KEY = "sk-eafdf8e1d0fb4717a883c87788e76182"

Tavily_API_KEY = "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"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

class ProposalState(TypedDict):
    """å®šä¹‰Proposalç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŠ¶æ€"""
    research_field: str
    query: str
    arxiv_papers: List[Dict]
    web_search_results: List[Dict]
    background: str
    objectives: str
    methodology: str
    timeline: str
    expected_outcomes: str
    final_proposal: str
    messages: List[Any]
    research_plan: str
    available_tools: List[Dict]  # å­˜å‚¨å¯ç”¨å·¥å…·ä¿¡æ¯
    execution_plan: List[Dict]  # å¯æ‰§è¡Œçš„è®¡åˆ’
    execution_memory: List[Dict]  # å·²ç»æ‰§è¡Œçš„è®°å¿†
    current_step: int  # å½“å‰æ‰§è¡Œçš„æ­¥éª¤
    max_iterations: int  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    introduction: str
    literature_review: str
    research_design: str
    timeline_plan: str
    expected_results: str
    reference_list: List[Dict]  # ç»Ÿä¸€çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
    ref_counter: int  # å‚è€ƒæ–‡çŒ®è®¡æ•°å™¨
    final_references: str  # æœ€ç»ˆçš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†




@tool
def search_arxiv_papers_tool(query: str, max_results: int = 5, Download = True) -> List[Dict]:
    """æœç´¢å¹¶ä¸‹è½½ArXivè®ºæ–‡çš„å·¥å…·
    
    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ç¯‡
    
    Returns:
        åŒ…å«è®ºæ–‡ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        ä»¥åŠå­˜å‚¨åœ¨Papersç›®å½•ä¸‹çš„å‚è€ƒæ–‡çŒ®
    """

    try:
        client = arxiv.Client()
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate
        )
        
        papers_dir = "./Papers"
        if not os.path.exists(papers_dir):
            os.makedirs(papers_dir)
        
        papers = []
        for paper in client.results(search):
            paper_info = {
                "title": paper.title,
                "authors": [author.name for author in paper.authors],
                "summary": paper.summary[:300] + "...",  # æˆªæ–­æ‘˜è¦
                "published": paper.published.strftime("%Y-%m-%d"),
                "pdf_url": paper.pdf_url,
                "categories": paper.categories,
                "arxiv_id": paper.entry_id.split('/')[-1]
            }
            if Download:
                try:
                    # ä¸‹è½½PDF
                    safe_title = "".join(c for c in paper.title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    safe_title = safe_title[:50]
                    filename = f"{paper_info['arxiv_id']}_{safe_title}.pdf"
                    
                    paper.download_pdf(dirpath=papers_dir, filename=filename)
                    paper_info["local_pdf_path"] = os.path.join(papers_dir, filename)
                    
                except Exception as e:
                    paper_info["local_pdf_path"] = None
                
            papers.append(paper_info)
        
        return papers
    
    except Exception as e:
        return [{"error": f"ArXivæœç´¢å¤±è´¥: {str(e)}"}]
    

# å®šä¹‰ç½‘ç»œæœç´¢å·¥å…·
@tool
def search_web_content_tool(query: str) -> List[Dict]:
    """ä½¿ç”¨Tavilyæœç´¢ç½‘ç»œå†…å®¹çš„å·¥å…·
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY
        tavily_tool = TavilySearchResults(
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=True
        )
        
        results = tavily_tool.invoke({"query": query})
        return results
    
    except Exception as e:
        return [{"error": f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}"}]
    

class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key= DASHSCOPE_API_KEY,
            model="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0
        )
        
        # è®¾ç½®Tavily APIå¯†é’¥
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY

        self.tools = [search_arxiv_papers_tool, search_web_content_tool]
        self.tools_description = self.load_tools_description()
        self.agent_with_tools = create_react_agent(self.llm, self.tools)
        self.workflow = self._build_workflow()

    
    def load_tools_description(self) -> List[Dict]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·¥å…·æè¿°"""
        try:
            with open('tools.json', 'r', encoding='utf-8') as f:
                tools_description = json.load(f)
            return tools_description
        except FileNotFoundError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        except json.JSONDecodeError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        

    def get_tools_info_text(self) -> str:
        """å°†å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if not self.tools_description:
            return "æš‚æ— å¯ç”¨å·¥å…·ä¿¡æ¯"
        
        tools_text = "å¯ç”¨å·¥å…·åˆ—è¡¨:\n\n"
        for tool_info in self.tools_description:
            func_info = tool_info.get("function", {})
            name = func_info.get("name", "æœªçŸ¥å·¥å…·")
            description = func_info.get("description", "æ— æè¿°")
            
            tools_text += f"ğŸ”§ **{name}**\n"
            tools_text += f"   æè¿°: {description}\n"
            
            # æ·»åŠ å‚æ•°ä¿¡æ¯
            params = func_info.get("parameters", {}).get("properties", {})
            if params:
                tools_text += f"   å‚æ•°:\n"
                for param_name, param_info in params.items():
                    param_desc = param_info.get("description", "æ— æè¿°")
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    required = param_name in func_info.get("parameters", {}).get("required", [])
                    required_text = "å¿…éœ€" if required else "å¯é€‰"
                    tools_text += f"     - {param_name} ({param_type}, {required_text}): {param_desc}\n"
            
            tools_text += "\n"
        
        return tools_text
    

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“çš„è§„åˆ’(ä¸åŒäºProposal)"""
        research_field = state["research_field"]

        tools_info = self.get_tools_info_text()

        master_planning_prompt = master_plan_instruction.format(
            research_field=research_field,
            tools_info=tools_info
        )
        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field}' åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
        response = self.llm.invoke([HumanMessage(content=master_planning_prompt)])
        
        state["research_plan"] = response.content
        state["available_tools"] = self.tools_description
        state["execution_memory"] = []
        state["current_step"] = 0
        state["max_iterations"] = 10

        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")
        logging.info(f"ç ”ç©¶è®¡åˆ’å†…å®¹: {state['research_plan']}...")

        return state
    


    def plan_analysis_node(self, state: ProposalState) -> ProposalState:
        """è§£æç ”ç©¶è®¡åˆ’,ç”Ÿæˆå¯æ‰§è¡Œæ­¥éª¤"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        tools_info = self.get_tools_info_text()
        execution_memory = state.get("execution_memory", [])


        memory_text = ""
        if execution_memory:
            memory_text = "\n\næ‰§è¡Œå†å²:\n"
            for step in execution_memory:
                description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
                result = step.get('result', 'æ— ç»“æœ')
                success = step.get('success', False)
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                memory_text += f"- {description}: {status} - {result[:100]}...\n"

        
        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        plan_analysis_prompt = EXECUTION_PLAN_PROMPT.format(
            research_field=research_field,
            research_plan=research_plan,
            tools_info=tools_info,
            memory_text=memory_text
        )
        logging.info("ğŸ” Agentæ­£åœ¨åˆ†æè®¡åˆ’å¹¶ç”Ÿæˆæ‰§è¡Œæ­¥éª¤...")
        response = self.llm.invoke([HumanMessage(content=plan_analysis_prompt)])
        logging.info("ç”Ÿæˆè®¡åˆ’", response.content)
        try:
            # è§£æJSONå“åº”
            response_text = response.content.strip()
           # å¦‚æœå“åº”åŒ…å«```jsonï¼Œåˆ™æå–JSONéƒ¨åˆ†
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            elif "```" in response_text:
                start = response_text.find("```") + 3
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            
            plan_data = json.loads(response_text)
            state["execution_plan"] = plan_data.get("steps", [])
        except json.JSONDecodeError:
            logging.error("æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’JSONï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
            logging.error(f"åŸå§‹å“åº”: {response.content[:500]}...")
            # é»˜è®¤æ‰§è¡Œè®¡åˆ’
            state["execution_plan"] = [
                {
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {"query": research_field, "max_results": 5},
                    "description": f"æœç´¢ArXivä¸Šå…³äº{research_field}çš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }
            ]
        
        logging.info(f"âœ… ç”Ÿæˆäº† {len(state['execution_plan'])} ä¸ªæ‰§è¡Œæ­¥éª¤")

        return state
    

    def execute_step_node(self, state: ProposalState) -> ProposalState:
        """æ‰§è¡Œå½“å‰æ­¥éª¤"""
        execution_plan = state.get("execution_plan", [])
        current_step = state.get("current_step", 0)
        execution_memory = state.get("execution_memory", [])
        
        if current_step >= len(execution_plan):
            logging.info("æ‰€æœ‰æ­¥éª¤å·²æ‰§è¡Œå®Œæˆ")
            return state
        
        current_action = execution_plan[current_step]
        action_name = current_action.get("action")
        parameters = current_action.get("parameters", {})
        description = current_action.get("description", "")
        
        logging.info(f"ğŸš€ æ‰§è¡Œæ­¥éª¤ {current_step + 1}: {description}")
        
        # æ‰§è¡Œå¯¹åº”çš„å·¥å…·
        result = None
        try:
            if action_name == "search_arxiv_papers":
                result = search_arxiv_papers_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["arxiv_papers"].extend(result)
                    
            elif action_name == "search_web_content":
                result = search_web_content_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["web_search_results"].extend(result)
            
            # æ¯æ¬¡æ”¶é›†åˆ°æ–°æ•°æ®åï¼Œç«‹å³æ›´æ–°å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            state = self.add_references_from_data(state)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": str(result)[:200] if result else "æ— ç»“æœ",
                "success": result is not None and (not isinstance(result, list) or len(result) > 0)
            })
            
        except Exception as e:
            logging.error(f"æ‰§è¡Œæ­¥éª¤å¤±è´¥: {e}")
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False
            })
        
        state["execution_memory"] = execution_memory
        state["current_step"] = current_step + 1
        
        return state
    
    def add_references_from_data(self, state: ProposalState) -> ProposalState:
        """ä»æ”¶é›†çš„æ•°æ®ä¸­æå–å¹¶æ·»åŠ å‚è€ƒæ–‡çŒ®"""
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        reference_list = state.get("reference_list", [])
        ref_counter = state.get("ref_counter", 1)
        
        # å¤„ç†ArXivè®ºæ–‡
        for paper in arxiv_papers:
            if "error" not in paper:
                # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
                paper_title = paper.get('title', 'Unknown')
                existing_ref = next((ref for ref in reference_list if ref.get('title') == paper_title), None)
                
                if not existing_ref:
                    reference_list.append({
                        "id": ref_counter,
                        "type": "ArXiv",
                        "title": paper_title,
                        "authors": paper.get('authors', []),
                        "published": paper.get('published', 'Unknown'),
                        "arxiv_id": paper.get('arxiv_id', ''),
                        "categories": paper.get('categories', []),
                        "summary": paper.get('summary', '')
                    })
                    ref_counter += 1
        
        # å¤„ç†ç½‘ç»œæœç´¢ç»“æœ
        for result in web_results:
            if "error" not in result:
                result_title = result.get('title', result.get('url', 'Unknown'))
                existing_ref = next((ref for ref in reference_list if ref.get('title') == result_title), None)
                
                if not existing_ref:
                    reference_list.append({
                        "id": ref_counter,
                        "type": "Web",
                        "title": result_title,
                        "url": result.get('url', ''),
                        "content_preview": result.get('content', result.get('snippet', 'No content'))[:200]
                    })
                    ref_counter += 1
        
        state["reference_list"] = reference_list
        state["ref_counter"] = ref_counter
        
        return state
    
    def get_literature_summary_with_refs(self, state: ProposalState) -> str:
        """è·å–å¸¦æœ‰ç»Ÿä¸€ç¼–å·çš„æ–‡çŒ®æ‘˜è¦"""
        reference_list = state.get("reference_list", [])
        
        literature_summary = ""
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        arxiv_refs = [ref for ref in reference_list if ref.get("type") == "ArXiv"]
        web_refs = [ref for ref in reference_list if ref.get("type") == "Web"]
        
        if arxiv_refs:
            literature_summary += "\n\n**ç›¸å…³ArXivè®ºæ–‡ï¼š**\n"
            for ref in arxiv_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   ä½œè€…: {', '.join(ref['authors'])}\n"
                literature_summary += f"   å‘è¡¨æ—¶é—´: {ref['published']}\n"
                literature_summary += f"   æ‘˜è¦: {ref['summary']}\n"
                literature_summary += f"   åˆ†ç±»: {', '.join(ref['categories'])}\n\n"
        
        if web_refs:
            literature_summary += "\n**ç›¸å…³ç½‘ç»œä¿¡æ¯ï¼š**\n"
            for ref in web_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   æ¥æº: {ref['url']}\n"
                literature_summary += f"   å†…å®¹æ‘˜è¦: {ref['content_preview']}...\n\n"
        
        return literature_summary
    
    def generate_reference_section(self, state: ProposalState) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_list = state.get("reference_list", [])
        
        if not reference_list:
            return ""
        
        ref_text = "\n\n## å‚è€ƒæ–‡çŒ®\n\n"
        
        for ref in reference_list:
            if ref["type"] == "ArXiv":
                # ArXivè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                categories_str = ", ".join(ref["categories"]) if ref["categories"] else ""
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. arXiv:{ref['arxiv_id']} ({ref['published']})"
                if categories_str:
                    ref_text += f". Categories: {categories_str}"
                ref_text += "\n\n"
            elif ref["type"] == "Web":
                # ç½‘ç»œèµ„æºæ ¼å¼
                ref_text += f"[{ref['id']}] {ref['title']}. è®¿é—®æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}. URL: {ref['url']}\n\n"
        
        return ref_text

    def write_introduction_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„å¼•è¨€éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›[1]ï¼Œç‰¹åˆ«æ˜¯åœ¨å½±åƒè¯†åˆ«é¢†åŸŸ[2]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2] çš„æ ¼å¼
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„instruction
        introduction_prompt = f"""
        {proposal_introduction_instruction}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        {citation_instruction}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„å¼•è¨€éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘600å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜ä»‹ç»ã€é‡è¦æ€§è¯´æ˜ã€ç ”ç©¶ç©ºç™½åˆ°ç ”ç©¶é—®é¢˜çš„æ¨å¯¼
        4. é€‚å½“å¼•ç”¨å·²æ”¶é›†çš„æ–‡çŒ®ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        5. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        6. **ä¸è¦åœ¨å¼•è¨€éƒ¨åˆ†åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨**ï¼Œåªåœ¨æ­£æ–‡ä¸­ä½¿ç”¨å¼•ç”¨æ ‡è®°
        """
        
        logging.info("ğŸ“ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦å¼•è¨€éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=introduction_prompt)])
        
        # åªä¿å­˜å¼•è¨€æ­£æ–‡ï¼Œä¸åŒ…å«å‚è€ƒæ–‡çŒ®
        state["introduction"] = response.content
        logging.info("âœ… å¼•è¨€éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def write_literature_review_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶ã€ç†è®ºæˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•[1,2]ï¼Œä½†åœ¨å¯è§£é‡Šæ€§æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜[3]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2,3] çš„æ ¼å¼
        6. åœ¨è®ºè¿°ä¸åŒè§‚ç‚¹æˆ–ç ”ç©¶å‘ç°æ—¶ï¼Œè¦æ˜ç¡®æ ‡æ³¨æ¥æº
        7. å¯¹äºé‡è¦çš„ç†è®ºæ¡†æ¶æˆ–æ–¹æ³•è®ºï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å¼•è¨€éƒ¨åˆ†çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†é˜…è¯»å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼Œç†è§£å…¶ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜å’Œè¯†åˆ«çš„ç ”ç©¶ç©ºç™½
        2. æ–‡çŒ®ç»¼è¿°åº”è¯¥æ·±åŒ–å’Œæ‹“å±•å¼•è¨€ä¸­ç®€è¦æåŠçš„ç ”ç©¶é¢†åŸŸ
        3. é¿å…é‡å¤å¼•è¨€ä¸­å·²ç»è¯¦ç»†é˜è¿°çš„èƒŒæ™¯ä¿¡æ¯
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°ç ”ç©¶é—®é¢˜"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„..."ç­‰
        5. ç¡®ä¿æ–‡çŒ®ç»¼è¿°çš„ç»“è®ºè‡ªç„¶è¿‡æ¸¡åˆ°å¯¹æ‹Ÿè®®ç ”ç©¶çš„å¿…è¦æ€§è®ºè¯
        6. å¯¹å¼•è¨€ä¸­æåŠçš„å…³é”®æ¦‚å¿µå’Œç†è®ºè¿›è¡Œæ›´æ·±å…¥çš„æ–‡çŒ®åˆ†æ
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„LITERATURE_REVIEW_PROMPT
        literature_review_prompt = f"""
        {LITERATURE_REVIEW_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘800å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒæŒ‰ä¸»é¢˜ç»„ç»‡æ–‡çŒ®ï¼Œä¸è¦é€ç¯‡è®ºæ–‡ä»‹ç»
        4. é‡ç‚¹å…³æ³¨ç ”ç©¶è¶‹åŠ¿ã€ä¸»è¦è§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•å’Œå­˜åœ¨çš„äº‰è®®
        5. è¯†åˆ«ç ”ç©¶ç©ºç™½å’Œä¸è¶³ï¼Œä¸ºåç»­ç ”ç©¶æä¾›ä¾æ®
        6. å¿…é¡»åŒ…å«é€‚å½“çš„æ–‡çŒ®å¼•ç”¨ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        7. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        8. é¿å…ç®€å•ç½—åˆ—ï¼Œè¦è¿›è¡Œåˆ†æå’Œç»¼åˆ
        9. **ä¸å¼•è¨€éƒ¨åˆ†ä¿æŒè¿è´¯æ€§**ï¼Œé¿å…é‡å¤å†…å®¹ï¼Œæ·±åŒ–å¼•è¨€ä¸­çš„ç ”ç©¶é—®é¢˜
        10. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€è¿æ¥å¼•è¨€éƒ¨åˆ†çš„å†…å®¹
        """
        
        logging.info("ğŸ“š æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=literature_review_prompt)])
        
        # æ³¨æ„ï¼šæ–‡çŒ®ç»¼è¿°ä¸é‡å¤æ·»åŠ å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œå› ä¸ºå¼•è¨€å·²ç»åŒ…å«äº†å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        state["literature_review"] = response.content
        logging.info("âœ… æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def write_research_design_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æ–¹æ³•ã€ç†è®ºæ¡†æ¶æˆ–æŠ€æœ¯æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæœ¬ç ”ç©¶å°†é‡‡ç”¨æ··åˆæ–¹æ³•ç ”ç©¶è®¾è®¡[5]ï¼Œç»“åˆå®šé‡åˆ†æå’Œå®šæ€§è®¿è°ˆ[8,12]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨å·²æä¾›çš„æ–‡çŒ®
        5. åœ¨æè¿°æ–¹æ³•è®ºä¾æ®æ—¶è¦æ˜ç¡®æ ‡æ³¨æ¥æº
        6. å¯¹äºé‡è¦çš„åˆ†æå·¥å…·å’ŒæŠ€æœ¯æ¡†æ¶ï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å‰æ–‡çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†åˆ†æå¼•è¨€éƒ¨åˆ†æå‡ºçš„å…·ä½“ç ”ç©¶é—®é¢˜ï¼Œç¡®ä¿ç ”ç©¶è®¾è®¡èƒ½å¤Ÿå›ç­”è¿™äº›é—®é¢˜
        2. åŸºäºæ–‡çŒ®ç»¼è¿°ä¸­è¯†åˆ«çš„æ–¹æ³•è®ºè¶‹åŠ¿å’Œç ”ç©¶ç©ºç™½ï¼Œé€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•
        3. æ‰¿æ¥æ–‡çŒ®ç»¼è¿°ä¸­æåˆ°çš„ç†è®ºæ¡†æ¶å’Œåˆ†ææ–¹æ³•ï¼Œè¯´æ˜å¦‚ä½•åœ¨æœ¬ç ”ç©¶ä¸­åº”ç”¨æˆ–æ”¹è¿›
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°æ–‡çŒ®åˆ†æ"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜"ã€"å€Ÿé‰´æ–‡çŒ®ç»¼è¿°ä¸­çš„..."ç­‰
        5. ç¡®ä¿ç ”ç©¶è®¾è®¡çš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½ä¸å‰æ–‡å»ºç«‹çš„ç ”ç©¶èƒŒæ™¯å’Œç†è®ºåŸºç¡€ç›¸å‘¼åº”
        6. æ˜ç¡®è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©çš„æ–¹æ³•é€‚åˆè§£å†³å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„PROJECT_DESIGN_PROMPT
        research_design_prompt = f"""
        {PROJECT_DESIGN_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ï¼š**
        {literature_review_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘800å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«æ•°æ®æ¥æºã€ç ”ç©¶æ–¹æ³•ã€åˆ†æç­–ç•¥ã€å·¥ä½œæµç¨‹ç­‰
        4. æ˜ç¡®å›åº”å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜
        5. åŸºäºæ–‡çŒ®ç»¼è¿°ä¸­çš„æ–¹æ³•è®ºåˆ†æï¼Œé€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•
        6. å¿…é¡»åŒ…å«é€‚å½“çš„æ–‡çŒ®å¼•ç”¨ï¼Œä½¿ç”¨ç»Ÿä¸€ç¼–å·ç³»ç»Ÿ
        7. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        8. **ä¸å¼•è¨€å’Œæ–‡çŒ®ç»¼è¿°ä¿æŒé€»è¾‘è¿è´¯æ€§**
        9. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€è¿æ¥å‰æ–‡å†…å®¹
        10. è¯´æ˜ç ”ç©¶è®¾è®¡çš„å¯è¡Œæ€§å’Œå±€é™æ€§
        """
        
        logging.info("ğŸ”¬ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç ”ç©¶è®¾è®¡éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=research_design_prompt)])
        
        state["research_design"] = response.content
        logging.info("âœ… ç ”ç©¶è®¾è®¡éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def generate_final_references_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_section = self.generate_reference_section(state)
        
        # å°†å‚è€ƒæ–‡çŒ®ä½œä¸ºç‹¬ç«‹éƒ¨åˆ†ä¿å­˜
        state["final_references"] = reference_section
        logging.info("âœ… å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def should_continue(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–è¿›å…¥å†™ä½œé˜¶æ®µ"""
        current_step = state.get("current_step", 0)
        execution_plan = state.get("execution_plan", [])
        execution_memory = state.get("execution_memory", [])
        max_iterations = state.get("max_iterations", 10)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if len(execution_memory) >= max_iterations:
            logging.info("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "write_introduction"
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ­¥éª¤è¦æ‰§è¡Œ
        if current_step < len(execution_plan):
            return "execute_step"
        
        # æ£€æŸ¥æ˜¯å¦æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        
        logging.info(f"å½“å‰æ”¶é›†æƒ…å†µ: {len(arxiv_papers)} ç¯‡è®ºæ–‡, {len(web_results)} æ¡ç½‘ç»œç»“æœ")
        
        # å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ
        if len(arxiv_papers) >= 3 or len(web_results) >= 3:
            logging.info("å·²æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "write_introduction"
        
        # æ£€æŸ¥æœ€è¿‘çš„æ‰§è¡Œç»“æœ
        recent_results = execution_memory[-3:] if len(execution_memory) >= 3 else execution_memory
        successful_results = [r for r in recent_results if r.get("success", False)]
        
        # å¦‚æœæœ€è¿‘çš„ç»“æœéƒ½ä¸æˆåŠŸï¼Œé‡æ–°è§„åˆ’
        if len(successful_results) < len(recent_results) * 0.3:
            logging.info("æœ€è¿‘æ‰§è¡Œç»“æœä¸ç†æƒ³ï¼Œé‡æ–°è§„åˆ’...")
            state["current_step"] = 0
            return "plan_analysis"
        
        # å¦‚æœæ‰§è¡Œäº†ä¸€è½®ä½†ä¿¡æ¯ä¸è¶³ï¼Œç»§ç»­è§„åˆ’
        if len(arxiv_papers) < 3 and len(web_results) < 3:
            logging.info("ä¿¡æ¯æ”¶é›†ä¸è¶³ï¼Œç»§ç»­è§„åˆ’...")
            state["current_step"] = 0
            return "plan_analysis"
        
        # é»˜è®¤è¿›å…¥å†™ä½œé˜¶æ®µ
        return "write_introduction"
    
    
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("create_master_plan", self.create_master_plan_node)
        workflow.add_node("plan_analysis", self.plan_analysis_node)
        workflow.add_node("execute_step", self.execute_step_node)
        workflow.add_node("write_introduction", self.write_introduction_node)
        workflow.add_node("write_literature_review", self.write_literature_review_node)
        workflow.add_node("write_research_design", self.write_research_design_node)
        workflow.add_node("generate_final_references", self.generate_final_references_node)
        
        # å®šä¹‰æµç¨‹
        workflow.set_entry_point("create_master_plan")
        workflow.add_edge("create_master_plan", "plan_analysis")
        
        # æ¡ä»¶è¾¹ï¼šæ ¹æ®æ‰§è¡Œæƒ…å†µå†³å®šä¸‹ä¸€æ­¥
        workflow.add_conditional_edges(
            "plan_analysis",
            lambda state: "execute_step",  # ç”Ÿæˆè®¡åˆ’åæ‰§è¡Œæ­¥éª¤
            {"execute_step": "execute_step"}
        )
        
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue,  # æ ¹æ®æ‰§è¡Œç»“æœå†³å®šä¸‹ä¸€æ­¥
            {
                "execute_step": "execute_step",  # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
                "plan_analysis": "plan_analysis",  # é‡æ–°è§„åˆ’
                "write_introduction": "write_introduction" 
            }
        )
        
        workflow.add_edge("write_introduction", "write_literature_review")
        workflow.add_edge("write_literature_review", "write_research_design")
        workflow.add_edge("write_research_design", "generate_final_references")
        workflow.add_edge("generate_final_references", END)
        
        return workflow.compile()
    
    def generate_proposal(self, research_field: str) -> Dict[str, Any]:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦"""
        initial_state = ProposalState(
            research_field=research_field,
            query="",
            arxiv_papers=[],
            web_search_results=[],
            background="",
            objectives="",
            methodology="",
            timeline="",
            expected_outcomes="",
            final_proposal="",
            messages=[],
            research_plan="",
            available_tools=[],
            execution_plan=[],
            execution_memory=[],
            current_step=0,
            max_iterations=10,
            introduction="",
            literature_review="",
            research_design="",
            timeline_plan="",
            expected_results="",
            reference_list=[],  # åˆå§‹åŒ–ç»Ÿä¸€å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            ref_counter=1,      # åˆå§‹åŒ–å‚è€ƒæ–‡çŒ®è®¡æ•°å™¨
            final_references="" # æ·»åŠ æœ€ç»ˆå‚è€ƒæ–‡çŒ®å­—æ®µ
        )
        
        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶é—®é¢˜: '{research_field}'")
        result = self.workflow.invoke(initial_state)
        return result


"""
TODO: å·²å®Œæˆç®€å•çš„æœç´¢åŠŸèƒ½ç­‰å†…å®¹
ä¸‹ä¸€æ­¥ï¼šç”ŸæˆæŠ¥å‘Šç›¸å…³
"""

if __name__ == "__main__":
    agent = ProposalAgent()
    research_question = "äººå·¥æ™ºèƒ½åœ¨æŠ‘éƒç—‡é¢†åŸŸçš„åº”ç”¨"
    result = agent.generate_proposal(research_question)
    print("\n" + "="*60)
    # print("è®¡åˆ’:")
    # print(result["research_plan"])
    print("\n" + "="*60)
    print(f"æ‰§è¡Œå†å²: {len(result['execution_memory'])} ä¸ªæ­¥éª¤")
    for memory in result["execution_memory"]:
        print(f"- {memory['description']}: {'æˆåŠŸ' if memory['success'] else 'å¤±è´¥'}")
    print("\n" + "="*60)
    print(f"æ”¶é›†åˆ°çš„è®ºæ–‡: {len(result['arxiv_papers'])} ç¯‡")
    print(f"ç½‘ç»œæœç´¢ç»“æœ: {len(result['web_search_results'])} æ¡")
    print(f"ç»Ÿä¸€å‚è€ƒæ–‡çŒ®: {len(result['reference_list'])} æ¡")
    print("\n" + "="*60)
    print("å¼•è¨€éƒ¨åˆ†:")
    print(result["introduction"])
    print("\n" + "="*60)
    print("æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†:")
    print(result["literature_review"])
    print("\n" + "="*60)
    print("ç ”ç©¶è®¾è®¡éƒ¨åˆ†:")
    print(result["research_design"])
    print("\n" + "="*60)
    print("å‚è€ƒæ–‡çŒ®éƒ¨åˆ†:")
    print(result["final_references"])