import arxiv
from langchain_community.tools import TavilySearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging

"""
APIçš„é…ç½®â€”â€”[TODO]åŒæ­¥åˆ°ç½‘ä¸Šå‰è®°å¾—ä¿®æ”¹ï¼
"""
base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
DASHSCOPE_API_KEY = "sk-eafdf8e1d0fb4717a883c87788e76182"

Tavily_API_KEY = "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"


class ProposalState(TypedDict):
    """å®šä¹‰Proposalç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŠ¶æ€"""
    research_field: str
    query: str
    arxiv_papers: List[Dict]
    web_search_results: List[Dict]
    background: str
    objectives: str
    methodology: str
    timeline: str
    expected_outcomes: str
    final_proposal: str
    messages: List[Any]
    research_plan: str



@tool
def search_arxiv_papers_tool(query: str, max_results: int = 5) -> List[Dict]:
    """æœç´¢å¹¶ä¸‹è½½ArXivè®ºæ–‡çš„å·¥å…·
    
    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ç¯‡
    
    Returns:
        åŒ…å«è®ºæ–‡ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
    """
    try:
        client = arxiv.Client()
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate
        )
        
        papers_dir = "./Papers"
        if not os.path.exists(papers_dir):
            os.makedirs(papers_dir)
        
        papers = []
        for paper in client.results(search):
            paper_info = {
                "title": paper.title,
                "authors": [author.name for author in paper.authors],
                "summary": paper.summary[:300] + "...",  # æˆªæ–­æ‘˜è¦
                "published": paper.published.strftime("%Y-%m-%d"),
                "pdf_url": paper.pdf_url,
                "categories": paper.categories,
                "arxiv_id": paper.entry_id.split('/')[-1]
            }
            
            try:
                # ä¸‹è½½PDF
                safe_title = "".join(c for c in paper.title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                safe_title = safe_title[:50]
                filename = f"{paper_info['arxiv_id']}_{safe_title}.pdf"
                
                paper.download_pdf(dirpath=papers_dir, filename=filename)
                paper_info["local_pdf_path"] = os.path.join(papers_dir, filename)
                
            except Exception as e:
                paper_info["local_pdf_path"] = None
                
            papers.append(paper_info)
        
        return papers
    
    except Exception as e:
        return [{"error": f"ArXivæœç´¢å¤±è´¥: {str(e)}"}]
    

# å®šä¹‰ç½‘ç»œæœç´¢å·¥å…·
@tool
def search_web_content_tool(query: str) -> List[Dict]:
    """ä½¿ç”¨Tavilyæœç´¢ç½‘ç»œå†…å®¹çš„å·¥å…·
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    try:
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY
        tavily_tool = TavilySearchResults(
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=True
        )
        
        results = tavily_tool.invoke({"query": query})
        return results
    
    except Exception as e:
        return [{"error": f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}"}]
    

class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key= DASHSCOPE_API_KEY,
            model="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0
        )
        
        # è®¾ç½®Tavily APIå¯†é’¥
        os.environ["TAVILY_API_KEY"] = Tavily_API_KEY

        # åˆå§‹åŒ–å·¥å…·
        self.arxiv_client = arxiv.Client()
        self.tavily_tool = TavilySearchResults(
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_raw_content=True
        )
        
        self.papers_dir = "./Papers"
        if not os.path.exists(self.papers_dir):
            os.makedirs(self.papers_dir)
        # æ„å»ºå·¥ä½œæµå›¾
        self.workflow = self._build_workflow()
    
    def search_arxiv_papers(self, query: str, max_results: int = 10) -> List[Dict]:
        """æœç´¢å¹¶ä¸‹è½½ArXivè®ºæ–‡"""
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate
        )
        

        papers = []
        for paper in self.arxiv_client.results(search):
            paper_info = {
                "title": paper.title,
                "authors": [author.name for author in paper.authors],
                "summary": paper.summary,
                "published": paper.published.strftime("%Y-%m-%d"),
                "pdf_url": paper.pdf_url,
                "categories": paper.categories,
                "arxiv_id": paper.entry_id.split('/')[-1]  # æå–arxiv ID
            }
            try:
                # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶åï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
                safe_title = "".join(c for c in paper.title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                safe_title = safe_title[:50]  # é™åˆ¶æ–‡ä»¶åé•¿åº¦
                filename = f"{paper_info['arxiv_id']}_{safe_title}.pdf"
                
                paper.download_pdf(dirpath=self.papers_dir, filename=filename)
                paper_info["local_pdf_path"] = os.path.join(self.papers_dir, filename)
                logging.info(f"å·²ä¸‹è½½è®ºæ–‡: {paper.title}")

            except Exception as e:
                logging.error(f"ä¸‹è½½è®ºæ–‡å¤±è´¥ {paper.title}: {e}")
                paper_info["local_pdf_path"] = None
            
            papers.append(paper_info)

        return papers
    
    def search_web_content(self, query: str) -> List[Dict]:
        """ä½¿ç”¨Tavilyæœç´¢ç½‘ç»œå†…å®¹"""
        try:
            results = self.tavily_tool.invoke({"query": query})
            return results
        except Exception as e:
            logging.error(f"Web search error: {e}")
            return []

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“ç ”ç©¶è®¡åˆ’(ä¸åŒäºProposal)"""
        research_field = state["research_field"]

        master_planning_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç§‘ç ”ä¸“å®¶å’Œé¡¹ç›®è§„åˆ’å¸ˆã€‚ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªç ”ç©¶é—®é¢˜æˆ–é¢†åŸŸï¼š"{research_field}"

        è¯·ä½ åˆ¶å®šä¸€ä¸ªå…¨é¢çš„ç ”ç©¶è®¡åˆ’ï¼Œè¿™ä¸ªè®¡åˆ’åº”è¯¥åŒ…æ‹¬ï¼š

        1. **é—®é¢˜ç†è§£ä¸åˆ†æ**
        - å¯¹ç ”ç©¶é—®é¢˜çš„æ·±å…¥ç†è§£
        - é—®é¢˜çš„é‡è¦æ€§å’Œç ”ç©¶ä»·å€¼
        - é¢„æœŸçš„ç ”ç©¶éš¾ç‚¹å’ŒæŒ‘æˆ˜

        2. **æ–‡çŒ®è°ƒç ”è®¡åˆ’**
        - éœ€è¦æ£€ç´¢å“ªäº›å…³é”®è¯
        - é‡ç‚¹å…³æ³¨å“ªäº›ç ”ç©¶æ–¹å‘
        - éœ€è¦æŸ¥æ‰¾å“ªäº›ç±»å‹çš„æ–‡çŒ®ï¼ˆç†è®ºã€å®éªŒã€ç»¼è¿°ç­‰ï¼‰
        - æ–‡çŒ®æ£€ç´¢çš„ä¼˜å…ˆçº§

        3. **ç ”ç©¶ç›®æ ‡è®¾å®š**
        - æ€»ä½“ç ”ç©¶ç›®æ ‡
        - åˆ†è§£çš„å­ç›®æ ‡
        - å„ç›®æ ‡çš„ä¼˜å…ˆçº§

        4. **æŠ€æœ¯è·¯çº¿è§„åˆ’**
        - é‡‡ç”¨ä»€ä¹ˆç ”ç©¶æ–¹æ³•
        - æŠ€æœ¯å®ç°æ€è·¯
        - å®éªŒè®¾è®¡æ–¹æ¡ˆ

        5. **å·¥ä½œå®‰æ’**
        - å„é˜¶æ®µçš„å·¥ä½œå†…å®¹
        - æ—¶é—´åˆ†é…
        - é‡Œç¨‹ç¢‘è®¾å®š

        6. **é¢„æœŸæˆæœ**
        - æœŸæœ›è¾¾åˆ°çš„ç›®æ ‡
        - å¯äº¤ä»˜çš„æˆæœ

        è¯·åŸºäº"{research_field}"è¿™ä¸ªç ”ç©¶é—®é¢˜ï¼Œåˆ¶å®šä¸€ä¸ªè¯¦ç»†ã€å¯è¡Œçš„ç ”ç©¶è®¡åˆ’ã€‚
        è®¡åˆ’è¦å…·æœ‰æŒ‡å¯¼æ€§ï¼Œåç»­çš„æ‰€æœ‰å·¥ä½œéƒ½å°†åŸºäºè¿™ä¸ªè®¡åˆ’æ¥æ‰§è¡Œã€‚
        """
        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field}' åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
        response = self.llm.invoke([HumanMessage(content=master_planning_prompt)])
        
        state["research_plan"] = response.content
        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")

        return state
    
    def literature_research_node(self, state: ProposalState) -> ProposalState:
        """åŸºäºç ”ç©¶è®¡åˆ’è¿›è¡Œæ–‡çŒ®æ£€ç´¢"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        
        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        search_strategy_prompt = f"""
        åŸºäºä»¥ä¸‹ç ”ç©¶è®¡åˆ’ï¼Œç¡®å®šæ–‡çŒ®æ£€ç´¢çš„å…³é”®è¯å’Œç­–ç•¥ï¼š

        ç ”ç©¶è®¡åˆ’ï¼š
        {research_plan}

        è¯·åˆ†æå¹¶æå–ï¼š
        1. ä¸»è¦æ£€ç´¢å…³é”®è¯ï¼ˆ3-5ä¸ªï¼‰
        2. æ¬¡è¦æ£€ç´¢å…³é”®è¯ï¼ˆ2-3ä¸ªï¼‰
        3. æ£€ç´¢çš„é‡ç‚¹æ–¹å‘

        åªè¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
        æ ¼å¼ï¼šä¸»è¦å…³é”®è¯1,ä¸»è¦å…³é”®è¯2,æ¬¡è¦å…³é”®è¯1,æ¬¡è¦å…³é”®è¯2
        """
        
        print("ğŸ” åŸºäºç ”ç©¶è®¡åˆ’ç¡®å®šæ£€ç´¢ç­–ç•¥...")
        strategy_response = self.llm.invoke([HumanMessage(content=search_strategy_prompt)])
        keywords = strategy_response.content.strip()
        
        print(f"ğŸ“š å¼€å§‹æ£€ç´¢æ–‡çŒ®ï¼Œå…³é”®è¯ï¼š{keywords}")
        
        # ä½¿ç”¨æå–çš„å…³é”®è¯è¿›è¡Œæ£€ç´¢
        search_queries = [research_field] + [kw.strip() for kw in keywords.split(',')][:3]
        
        all_papers = []
        for query in search_queries:
            papers = self.search_arxiv_papers(query, max_results=5)
            all_papers.extend(papers)
        
        # å»é‡ï¼ˆåŸºäºtitleï¼‰
        seen_titles = set()
        unique_papers = []
        for paper in all_papers:
            if paper['title'] not in seen_titles:
                seen_titles.add(paper['title'])
                unique_papers.append(paper)
        
        # æœç´¢ç½‘ç»œå†…å®¹
        web_results = self.search_web_content(f"{research_field} research recent developments")
        
        state["arxiv_papers"] = unique_papers[:10]  # é™åˆ¶æ•°é‡
        state["web_search_results"] = web_results
        state["query"] = research_field
        
        print(f"ğŸ“– æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(unique_papers)} ç¯‡è®ºæ–‡")
        
        return state
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("create_master_plan", self.create_master_plan_node)      # ç¬¬ä¸€æ­¥ï¼šåˆ¶å®šè®¡åˆ’
        workflow.add_node("literature_research", self.literature_research_node)   # ç¬¬äºŒæ­¥ï¼šåŸºäºè®¡åˆ’æ£€ç´¢æ–‡çŒ®
        # åç»­å¯ä»¥æ·»åŠ å…¶ä»–èŠ‚ç‚¹...
        
        # å®šä¹‰æµç¨‹
        workflow.set_entry_point("create_master_plan")                           # ä»åˆ¶å®šè®¡åˆ’å¼€å§‹
        workflow.add_edge("create_master_plan", "literature_research")           # è®¡åˆ’ â†’ æ–‡çŒ®æ£€ç´¢
        workflow.add_edge("literature_research", END)                            # æš‚æ—¶ç»“æŸï¼Œåç»­å¯ä»¥æ·»åŠ æ›´å¤šèŠ‚ç‚¹
        
        return workflow.compile()
    