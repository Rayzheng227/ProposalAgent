"""
Agentç”Ÿæˆè¿‡ç¨‹ä¸­çš„å›¾ç›¸å…³ï¼šèŠ‚ç‚¹
"""
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging
from backend.src.agent.prompts import * # ç¡®ä¿ CLARIFICATION_QUESTION_PROMPT ä»è¿™é‡Œå¯¼å…¥
import fitz
from dotenv import load_dotenv
from .tools import search_arxiv_papers_tool,search_crossref_papers_tool,search_web_content_tool,summarize_pdf
from .state import ProposalState


load_dotenv()
TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")
DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY")
base_url = os.environ.get("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key= DASHSCOPE_API_KEY,
            model="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0
        )
        
        # è®¾ç½®Tavily APIå¯†é’¥
        # os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

        self.tools = [search_arxiv_papers_tool, search_web_content_tool, search_crossref_papers_tool, summarize_pdf]
        self.tools_description = self.load_tools_description()
        self.agent_with_tools = create_react_agent(self.llm, self.tools)
        self.workflow = self._build_workflow() # _build_workflow is called here

    
    def load_tools_description(self) -> List[Dict]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·¥å…·æè¿°"""
        current_script_dir = os.path.dirname(os.path.abspath(__file__))
        tools_json_path = os.path.join(current_script_dir, 'tools.json')
        try:
            with open(tools_json_path, 'r', encoding='utf-8') as f:
                tools_description = json.load(f)
            return tools_description
        except FileNotFoundError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        except json.JSONDecodeError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        

    def get_tools_info_text(self) -> str:
        """å°†å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if not self.tools_description:
            return "æš‚æ— å¯ç”¨å·¥å…·ä¿¡æ¯"
        
        tools_text = "å¯ç”¨å·¥å…·åˆ—è¡¨:\n\n"
        for tool_info in self.tools_description:
            func_info = tool_info.get("function", {})
            name = func_info.get("name", "æœªçŸ¥å·¥å…·")
            description = func_info.get("description", "æ— æè¿°")
            
            tools_text += f"ğŸ”§ **{name}**\n"
            tools_text += f"   æè¿°: {description}\n"
            
            # æ·»åŠ å‚æ•°ä¿¡æ¯
            params = func_info.get("parameters", {}).get("properties", {})
            if params:
                tools_text += f"   å‚æ•°:\n"
                for param_name, param_info in params.items():
                    param_desc = param_info.get("description", "æ— æè¿°")
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    required = param_name in func_info.get("parameters", {}).get("required", [])
                    required_text = "å¿…éœ€" if required else "å¯é€‰"
                    tools_text += f"     - {param_name} ({param_type}, {required_text}): {param_desc}\n"
            
            tools_text += "\n"
        
        return tools_text
    

    def clarify_research_focus_node(self, state: ProposalState) -> ProposalState:
        """æ ¹æ®ç ”ç©¶é¢†åŸŸç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œæˆ–å¤„ç†ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯"""
        research_field = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        existing_questions = state.get("clarification_questions", [])

        if user_clarifications:
            logging.info(f"ğŸ” ç”¨æˆ·å·²æä¾›ç ”ç©¶æ–¹å‘çš„æ¾„æ¸…ä¿¡æ¯: {user_clarifications[:200]}...")
            # ç”¨æˆ·å·²æä¾›æ¾„æ¸…ï¼Œæ— éœ€å†ç”Ÿæˆé—®é¢˜
            state["clarification_questions"] = [] # æ¸…ç©ºæ—§é—®é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
            return state
        
        if existing_questions:
            logging.info("ğŸ“ å·²å­˜åœ¨æ¾„æ¸…é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·å›åº”ã€‚")
            # å¦‚æœå·²æœ‰é—®é¢˜ä½†æ— ç”¨æˆ·å›åº”ï¼Œåˆ™ä¸é‡å¤ç”Ÿæˆ
            return state

        logging.info(f"ğŸ¤” æ­£åœ¨ä¸ºç ”ç©¶é¢†åŸŸ '{research_field}' ç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜...")
        
        prompt = CLARIFICATION_QUESTION_PROMPT.format(research_field=research_field)
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        generated_questions_text = response.content.strip()
        questions = [q.strip() for q in generated_questions_text.split('\n') if q.strip()]
        
        if questions:
            state["clarification_questions"] = questions
            logging.info("âœ… æˆåŠŸç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜ï¼š")
            for i, q in enumerate(questions):
                logging.info(f"  {i+1}. {q}")
            logging.info("ğŸ“¢ è¯·ç”¨æˆ·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜æä¾›å›åº”ï¼Œå¹¶åœ¨ä¸‹æ¬¡è¯·æ±‚æ—¶é€šè¿‡ 'user_clarifications' å­—æ®µä¼ å…¥ã€‚")
        else:
            logging.warning("âš ï¸ æœªèƒ½ä»LLMå“åº”ä¸­è§£æå‡ºæ¾„æ¸…æ€§é—®é¢˜ã€‚")
            state["clarification_questions"] = []
            
        return state

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“çš„è§„åˆ’(ä¸åŒäºProposal)"""
        research_field_original = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        tools_info = self.get_tools_info_text()

        clarification_text_for_prompt = ""
        if user_clarifications:
            clarification_text_for_prompt = (
                f"\n\né‡è¦å‚è€ƒï¼šç”¨æˆ·ä¸ºè¿›ä¸€æ­¥èšç„¦ç ”ç©¶æ–¹å‘ï¼Œæä¾›äº†ä»¥ä¸‹æ¾„æ¸…ä¿¡æ¯ã€‚åœ¨åˆ¶å®šè®¡åˆ’æ—¶ï¼Œè¯·åŠ¡å¿…ä»”ç»†è€ƒè™‘è¿™äº›å†…å®¹ï¼š\n"
                f"{user_clarifications}\n"
            )
            logging.info("ğŸ“ æ­£åœ¨ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯æ¥æŒ‡å¯¼æ€»ä½“è§„åˆ’ã€‚")

        # ä¿®æ”¹ master_plan_instruction æç¤ºå­—ç¬¦ä¸²
        # ç›®æ ‡æ’å…¥ä½ç½®ï¼šåœ¨ "Research Field: {research_field}" è¡Œä¹‹å
        # ä»¥åŠ "Available Tools:" ä¹‹å‰
        
        base_prompt_template = master_plan_instruction # ä» prompts.py å¯¼å…¥

        lines = base_prompt_template.splitlines()
        new_lines = []
        inserted = False
        for line in lines:
            new_lines.append(line)
            if "{research_field}" in line and clarification_text_for_prompt:
                # åœ¨åŒ…å« {research_field} çš„è¡Œä¹‹åæ’å…¥æ¾„æ¸…ä¿¡æ¯
                new_lines.append(clarification_text_for_prompt)
                inserted = True
        
        if not inserted and clarification_text_for_prompt: # åå¤‡ï¼šå¦‚æœå ä½ç¬¦æœªæ‰¾åˆ°ï¼Œåˆ™è¿½åŠ 
            new_lines.append(clarification_text_for_prompt)
            
        modified_master_plan_prompt_template = "\n".join(new_lines)
        
        master_planning_prompt = modified_master_plan_prompt_template.format(
            research_field=research_field_original, # æ­¤å¤„ä½¿ç”¨åŸå§‹ç ”ç©¶é¢†åŸŸ
            tools_info=tools_info
        )

        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field_original}' (å·²è€ƒè™‘ç”¨æˆ·æ¾„æ¸…) åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
        response = self.llm.invoke([HumanMessage(content=master_planning_prompt)])
        
        state["research_plan"] = response.content
        state["available_tools"] = self.tools_description
        state["execution_memory"] = []
        state["current_step"] = 0
        state["max_iterations"] = 10 # å¯ä»¥è€ƒè™‘è°ƒæ•´ï¼Œå› ä¸ºæ¾„æ¸…æ­¥éª¤å¯èƒ½æ¶ˆè€—ä¸€æ¬¡è¿­ä»£çš„æ„å›¾

        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")
        logging.info(f"ç ”ç©¶è®¡åˆ’å†…å®¹ (éƒ¨åˆ†): {state['research_plan'][:300]}...")

        return state
    
    # Ensure this method is correctly indented as part of the ProposalAgent class
    def _decide_after_clarification(self, state: ProposalState) -> str:
        """Determines the next step after the clarification node."""
        if state.get("clarification_questions") and not state.get("user_clarifications"):
            logging.info("â“ Clarification questions generated. Waiting for user input.")
            return "end_for_user_input" 
        logging.info("âœ… No clarification needed or clarifications provided. Proceeding to master plan.")
        return "proceed_to_master_plan"


    def plan_analysis_node(self, state: ProposalState) -> ProposalState:
        """è§£æç ”ç©¶è®¡åˆ’,ç”Ÿæˆå¯æ‰§è¡Œæ­¥éª¤"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        tools_info = self.get_tools_info_text()
        execution_memory = state.get("execution_memory", [])


        memory_text = ""
        if execution_memory:
            memory_text = "\n\næ‰§è¡Œå†å²:\n"
            for step in execution_memory:
                description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
                result = step.get('result', 'æ— ç»“æœ')
                success = step.get('success', False)
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                memory_text += f"- {description}: {status} - {result[:100]}...\n"

        
        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        plan_analysis_prompt = EXECUTION_PLAN_PROMPT.format(
            research_field=research_field,
            research_plan=research_plan,
            tools_info=tools_info,
            memory_text=memory_text
        )
        logging.info("ğŸ” Agentæ­£åœ¨åˆ†æè®¡åˆ’å¹¶ç”Ÿæˆæ‰§è¡Œæ­¥éª¤...")
        response = self.llm.invoke([HumanMessage(content=plan_analysis_prompt)])
        # logging.info("ç”Ÿæˆè®¡åˆ’", response.content)
        try:
            # è§£æJSONå“åº”
            response_text = response.content.strip()
           # å¦‚æœå“åº”åŒ…å«```jsonï¼Œåˆ™æå–JSONéƒ¨åˆ†
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            elif "```" in response_text:
                start = response_text.find("```") + 3
                end = response_text.find("```", start)
                if end != -1:
                    response_text = response_text[start:end].strip()
            
            plan_data = json.loads(response_text)
            state["execution_plan"] = plan_data.get("steps", [])
        except json.JSONDecodeError:
            logging.error("æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’JSONï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
            logging.error(f"åŸå§‹å“åº”: {response.content[:500]}...")
            # é»˜è®¤æ‰§è¡Œè®¡åˆ’
            state["execution_plan"] = [
                {
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {"query": research_field, "max_results": 5},
                    "description": f"æœç´¢ArXivä¸Šå…³äº{research_field}çš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }
            ]
        
        logging.info(f"âœ… ç”Ÿæˆäº† {len(state['execution_plan'])} ä¸ªæ‰§è¡Œæ­¥éª¤")

        return state
    

    def execute_step_node(self, state: ProposalState) -> ProposalState:
        """æ‰§è¡Œå½“å‰æ­¥éª¤"""
        execution_plan = state.get("execution_plan", [])
        current_step = state.get("current_step", 0)
        execution_memory = state.get("execution_memory", [])
        
        if current_step >= len(execution_plan):
            logging.info("æ‰€æœ‰æ­¥éª¤å·²æ‰§è¡Œå®Œæˆ")
            return state
        
        current_action = execution_plan[current_step]
        action_name = current_action.get("action")
        parameters = current_action.get("parameters", {})
        description = current_action.get("description", "")
        
        logging.info(f"ğŸš€ æ‰§è¡Œæ­¥éª¤ {current_step + 1}: {description}")
        
        # æ‰§è¡Œå¯¹åº”çš„å·¥å…·
        result = None
        try:
            if action_name == "search_arxiv_papers":
                result = search_arxiv_papers_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["arxiv_papers"].extend(result)
                    
            elif action_name == "search_web_content":
                result = search_web_content_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["web_search_results"].extend(result)
                    
            elif action_name == "search_crossref_papers":
                result = search_crossref_papers_tool.invoke(parameters)
                # å°†ç»“æœä¿å­˜åˆ°çŠ¶æ€ä¸­
                if isinstance(result, list) and len(result) > 0:
                    state["web_search_results"].extend(result)
                    
            elif action_name == "summarize_pdf":
                # æ”¹è¿›PDFæ‘˜è¦çš„è·¯å¾„å¤„ç†
                pdf_path = parameters.get("path", "")
                
                # å¦‚æœæ²¡æœ‰æŒ‡å®šå…·ä½“è·¯å¾„ï¼Œå°è¯•æ‰¾åˆ°å·²ä¸‹è½½çš„PDF
                if not pdf_path or not os.path.exists(pdf_path):
                    # æŸ¥æ‰¾å·²ä¸‹è½½çš„PDFæ–‡ä»¶
                    available_pdfs = []
                    for paper in state.get("arxiv_papers", []):
                        if paper.get("local_pdf_path") and os.path.exists(paper["local_pdf_path"]):
                            available_pdfs.append(paper["local_pdf_path"])
                    
                    if available_pdfs:
                        pdf_path = available_pdfs[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„PDF
                        logging.info(f"ğŸ“„ ä½¿ç”¨å¯ç”¨çš„PDFæ–‡ä»¶: {pdf_path}")
                    else:
                        logging.warning("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„PDFæ–‡ä»¶è¿›è¡Œæ‘˜è¦")
                        result = {"error": "æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„PDFæ–‡ä»¶"}
                
                if pdf_path and os.path.exists(pdf_path):
                    result = summarize_pdf.invoke({"path": pdf_path})
                    # PDFæ‘˜è¦ç»“æœå¯ä»¥å­˜å‚¨åˆ°æ‰§è¡Œè®°å½•ä¸­ï¼Œæˆ–è€…æ·»åŠ åˆ°è®ºæ–‡ä¿¡æ¯ä¸­
                    if result and "error" not in result:
                        # å°†æ‘˜è¦æ·»åŠ åˆ°å¯¹åº”çš„è®ºæ–‡ä¿¡æ¯ä¸­
                        for paper in state["arxiv_papers"]:
                            if paper.get("local_pdf_path") == pdf_path:
                                paper["detailed_summary"] = result["summary"]
                                break
            
            # æ¯æ¬¡æ”¶é›†åˆ°æ–°æ•°æ®åï¼Œç«‹å³æ›´æ–°å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            state = self.add_references_from_data(state)
            
            # è®°å½•æ‰§è¡Œç»“æœ
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": str(result)[:200] if result else "æ— ç»“æœ",
                "success": result is not None and (not isinstance(result, list) or len(result) > 0)
            })
            
        except Exception as e:
            logging.error(f"æ‰§è¡Œæ­¥éª¤å¤±è´¥: {e}")
            execution_memory.append({
                "step_id": current_step + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False
            })
        
        state["execution_memory"] = execution_memory
        state["current_step"] = current_step + 1
        
        return state
    
    def add_references_from_data(self, state: ProposalState) -> ProposalState:
        """ä»æ”¶é›†çš„æ•°æ®ä¸­æå–å¹¶æ·»åŠ å‚è€ƒæ–‡çŒ®"""
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        reference_list = state.get("reference_list", [])
        ref_counter = state.get("ref_counter", 1)
        
        # å¤„ç†ArXivè®ºæ–‡
        for paper in arxiv_papers:
            if "error" not in paper:
                # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
                paper_title = paper.get('title', 'Unknown')
                existing_ref = next((ref for ref in reference_list if ref.get('title') == paper_title), None)
                
                if not existing_ref:
                    reference_list.append({
                        "id": ref_counter,
                        "type": "ArXiv",
                        "title": paper_title,
                        "authors": paper.get('authors', []),
                        "published": paper.get('published', 'Unknown'),
                        "arxiv_id": paper.get('arxiv_id', ''),
                        "categories": paper.get('categories', []),
                        "summary": paper.get('detailed_summary', paper.get('summary', ''))  # ä¼˜å…ˆä½¿ç”¨è¯¦ç»†æ‘˜è¦
                    })
                    ref_counter += 1
        
        # å¤„ç†ç½‘ç»œæœç´¢ç»“æœå’ŒCrossRefç»“æœ
        for result in web_results:
            if "error" not in result:
                result_title = result.get('title', result.get('url', 'Unknown'))
                existing_ref = next((ref for ref in reference_list if ref.get('title') == result_title), None)
                
                if not existing_ref:
                    # åŒºåˆ†CrossRefå’Œæ™®é€šWebç»“æœ
                    if result.get('doi'):  # CrossRefç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "CrossRef",
                            "title": result_title,
                            "authors": result.get('authors', []),
                            "doi": result.get('doi', ''),
                            "journal": result.get('journal', ''),
                            "published": result.get('published', ''),
                            "url": result.get('url', '')
                        })
                    else:  # æ™®é€šWebç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "Web",
                            "title": result_title,
                            "url": result.get('url', ''),
                            "content_preview": result.get('content', result.get('snippet', 'No content'))[:200]
                        })
                    ref_counter += 1
        
        state["reference_list"] = reference_list
        state["ref_counter"] = ref_counter
        
        return state
    
    def get_literature_summary_with_refs(self, state: ProposalState) -> str:
        """è·å–å¸¦æœ‰ç»Ÿä¸€ç¼–å·çš„æ–‡çŒ®æ‘˜è¦"""
        reference_list = state.get("reference_list", [])
        
        literature_summary = ""
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        arxiv_refs = [ref for ref in reference_list if ref.get("type") == "ArXiv"]
        web_refs = [ref for ref in reference_list if ref.get("type") == "Web"]
        
        if arxiv_refs:
            literature_summary += "\n\n**ç›¸å…³ArXivè®ºæ–‡ï¼š**\n"
            for ref in arxiv_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   ä½œè€…: {', '.join(ref['authors'])}\n"
                literature_summary += f"   å‘è¡¨æ—¶é—´: {ref['published']}\n"
                literature_summary += f"   æ‘˜è¦: {ref['summary']}\n"
                literature_summary += f"   åˆ†ç±»: {', '.join(ref['categories'])}\n\n"
        
        if web_refs:
            literature_summary += "\n**ç›¸å…³ç½‘ç»œä¿¡æ¯ï¼š**\n"
            for ref in web_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   æ¥æº: {ref['url']}\n"
                literature_summary += f"   å†…å®¹æ‘˜è¦: {ref['content_preview']}...\n\n"
        
        return literature_summary
    
    def generate_reference_section(self, state: ProposalState) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_list = state.get("reference_list", [])
        
        if not reference_list:
            return ""
        
        ref_text = "\n\n## å‚è€ƒæ–‡çŒ®\n\n"
        
        for ref in reference_list:
            if ref["type"] == "ArXiv":
                # ArXivè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                categories_str = ", ".join(ref["categories"]) if ref["categories"] else ""
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. arXiv:{ref['arxiv_id']} ({ref['published']})"
                if categories_str:
                    ref_text += f". Categories: {categories_str}"
                ref_text += "\n\n"
            elif ref["type"] == "CrossRef":
                # CrossRefè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. {ref['journal']} ({ref['published']}). DOI: {ref['doi']}\n\n"
            elif ref["type"] == "Web":
                # ç½‘ç»œèµ„æºæ ¼å¼
                ref_text += f"[{ref['id']}] {ref['title']}. è®¿é—®æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}. URL: {ref['url']}\n\n"
        
        return ref_text

    def write_introduction_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„å¼•è¨€éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›[1]ï¼Œç‰¹åˆ«æ˜¯åœ¨å½±åƒè¯†åˆ«é¢†åŸŸ[2]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2] çš„æ ¼å¼
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„instruction
        introduction_prompt = f"""
        {proposal_introduction_instruction}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        {citation_instruction}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„å¼•è¨€éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘600å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜ä»‹ç»ã€é‡è¦æ€§è¯´æ˜ã€ç ”ç©¶ç©ºç™½åˆ°ç ”ç©¶é—®é¢˜çš„æ¨å¯¼
        4. é€‚å½“å¼•ç”¨å·²æ”¶é›†çš„æ–‡çŒ®ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        5. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        6. **ä¸è¦åœ¨å¼•è¨€éƒ¨åˆ†åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨**ï¼Œåªåœ¨æ­£æ–‡ä¸­ä½¿ç”¨å¼•ç”¨æ ‡è®°
        7. ä½¿ç”¨`# å¼•è¨€`ä½œä¸ºå¼€å¤´
        """
        
        logging.info("ğŸ“ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦å¼•è¨€éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=introduction_prompt)])
        
        # åªä¿å­˜å¼•è¨€æ­£æ–‡ï¼Œä¸åŒ…å«å‚è€ƒæ–‡çŒ®
        state["introduction"] = response.content
        logging.info("âœ… å¼•è¨€éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def write_literature_review_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶ã€ç†è®ºæˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•[1,2]ï¼Œä½†åœ¨å¯è§£é‡Šæ€§æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜[3]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2,3] çš„æ ¼å¼
        6. åœ¨è®ºè¿°ä¸åŒè§‚ç‚¹æˆ–ç ”ç©¶å‘ç°æ—¶ï¼Œè¦æ˜ç¡®æ ‡æ³¨æ¥æº
        7. å¯¹äºé‡è¦çš„ç†è®ºæ¡†æ¶æˆ–æ–¹æ³•è®ºï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å¼•è¨€éƒ¨åˆ†çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†é˜…è¯»å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼Œç†è§£å…¶ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜å’Œè¯†åˆ«çš„ç ”ç©¶ç©ºç™½
        2. æ–‡çŒ®ç»¼è¿°åº”è¯¥æ·±åŒ–å’Œæ‹“å±•å¼•è¨€ä¸­ç®€è¦æåŠçš„ç ”ç©¶é¢†åŸŸ
        3. é¿å…é‡å¤å¼•è¨€ä¸­å·²ç»è¯¦ç»†é˜è¿°çš„èƒŒæ™¯ä¿¡æ¯
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°ç ”ç©¶é—®é¢˜"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„..."ç­‰
        5. ç¡®ä¿æ–‡çŒ®ç»¼è¿°çš„ç»“è®ºè‡ªç„¶è¿‡æ¸¡åˆ°å¯¹æ‹Ÿè®®ç ”ç©¶çš„å¿…è¦æ€§è®ºè¯
        6. å¯¹å¼•è¨€ä¸­æåŠçš„å…³é”®æ¦‚å¿µå’Œç†è®ºè¿›è¡Œæ›´æ·±å…¥çš„æ–‡çŒ®åˆ†æ
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„LITERATURE_REVIEW_PROMPT
        literature_review_prompt = f"""
        {LITERATURE_REVIEW_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘800å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒæŒ‰ä¸»é¢˜ç»„ç»‡æ–‡çŒ®ï¼Œä¸è¦é€ç¯‡è®ºæ–‡ä»‹ç»
        4. é‡ç‚¹å…³æ³¨ç ”ç©¶è¶‹åŠ¿ã€ä¸»è¦è§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•å’Œå­˜åœ¨çš„äº‰è®®
        5. è¯†åˆ«ç ”ç©¶ç©ºç™½å’Œä¸è¶³ï¼Œä¸ºåç»­ç ”ç©¶æä¾›ä¾æ®
        6. å¿…é¡»åŒ…å«é€‚å½“çš„æ–‡çŒ®å¼•ç”¨ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        7. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        8. é¿å…ç®€å•ç½—åˆ—ï¼Œè¦è¿›è¡Œåˆ†æå’Œç»¼åˆ
        9. **ä¸å¼•è¨€éƒ¨åˆ†ä¿æŒè¿è´¯æ€§**ï¼Œé¿å…é‡å¤å†…å®¹ï¼Œæ·±åŒ–å¼•è¨€ä¸­çš„ç ”ç©¶é—®é¢˜
        10. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€è¿æ¥å¼•è¨€éƒ¨åˆ†çš„å†…å®¹
        """
        
        logging.info("ğŸ“š æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=literature_review_prompt)])
        
        # æ³¨æ„ï¼šæ–‡çŒ®ç»¼è¿°ä¸é‡å¤æ·»åŠ å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œå› ä¸ºå¼•è¨€å·²ç»åŒ…å«äº†å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        state["literature_review"] = response.content
        logging.info("âœ… æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def write_research_design_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)
        
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æ–¹æ³•ã€ç†è®ºæ¡†æ¶æˆ–æŠ€æœ¯æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæœ¬ç ”ç©¶å°†é‡‡ç”¨æ··åˆæ–¹æ³•ç ”ç©¶è®¾è®¡[5]ï¼Œç»“åˆå®šé‡åˆ†æå’Œå®šæ€§è®¿è°ˆ[8,12]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨å·²æä¾›çš„æ–‡çŒ®
        5. åœ¨æè¿°æ–¹æ³•è®ºä¾æ®æ—¶è¦æ˜ç¡®æ ‡æ³¨æ¥æº
        6. å¯¹äºé‡è¦çš„åˆ†æå·¥å…·å’ŒæŠ€æœ¯æ¡†æ¶ï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å‰æ–‡çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†åˆ†æå¼•è¨€éƒ¨åˆ†æå‡ºçš„å…·ä½“ç ”ç©¶é—®é¢˜ï¼Œç¡®ä¿ç ”ç©¶è®¾è®¡èƒ½å¤Ÿå›ç­”è¿™äº›é—®é¢˜
        2. åŸºäºæ–‡çŒ®ç»¼è¿°ä¸­è¯†åˆ«çš„æ–¹æ³•è®ºè¶‹åŠ¿å’Œç ”ç©¶ç©ºç™½ï¼Œé€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•
        3. æ‰¿æ¥æ–‡çŒ®ç»¼è¿°ä¸­æåˆ°çš„ç†è®ºæ¡†æ¶å’Œåˆ†ææ–¹æ³•ï¼Œè¯´æ˜å¦‚ä½•åœ¨æœ¬ç ”ç©¶ä¸­åº”ç”¨æˆ–æ”¹è¿›
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°æ–‡çŒ®åˆ†æ"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜"ã€"å€Ÿé‰´æ–‡çŒ®ç»¼è¿°ä¸­çš„..."ç­‰
        5. ç¡®ä¿ç ”ç©¶è®¾è®¡çš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½ä¸å‰æ–‡å»ºç«‹çš„ç ”ç©¶èƒŒæ™¯å’Œç†è®ºåŸºç¡€ç›¸å‘¼åº”
        6. æ˜ç¡®è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©çš„æ–¹æ³•é€‚åˆè§£å†³å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜
        """
        
        # ä½¿ç”¨prompts.pyä¸­çš„PROJECT_DESIGN_PROMPT
        research_design_prompt = f"""
        {PROJECT_DESIGN_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’æ¦‚è¦ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ï¼š**
        {literature_review_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼ˆç”¨äºå¯èƒ½çš„å¼•ç”¨ï¼‰ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸ºâ€œ{research_field}â€è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†ã€‚
        é‡ç‚¹å…³æ³¨ç ”ç©¶æ•°æ®ã€æ–¹æ³•ã€å·¥ä½œæµç¨‹å’Œå±€é™æ€§ã€‚
        å¿…é¡»**ä½¿ç”¨ä¸­æ–‡æ’°å†™**
        **ä¸è¦åŒ…å«æ—¶é—´å®‰æ’æˆ–é¢„æœŸæˆæœæ€»ç»“ï¼Œè¿™äº›å°†åœ¨ç»“è®ºéƒ¨åˆ†ç»Ÿä¸€é˜è¿°ã€‚**
        """
        
        logging.info("ğŸ”¬ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç ”ç©¶è®¾è®¡éƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=research_design_prompt)])
        
        state["research_design"] = response.content
        logging.info("âœ… ç ”ç©¶è®¾è®¡éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state


    def write_conclusion_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç»“è®ºéƒ¨åˆ†"""
        research_field = state["research_field"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")
        research_design_content = state.get("research_design", "")
        
        conclusion_prompt_text = f"""
        {CONCLUSION_PROMPT.format(research_field=research_field)}

        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}

        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç ”ç©¶é—®é¢˜å’ŒèƒŒæ™¯ï¼‰ï¼š**
        {introduction_content[:1000]}... 

        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç†è®ºæ¡†æ¶ï¼‰ï¼š**
        {literature_review_content[:1000]}...

        **å·²å®Œæˆçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾æ–¹æ³•å’Œæµç¨‹ï¼‰ï¼š**
        {research_design_content[:1000]}...

        è¯·åŸºäºä»¥ä¸Šæä¾›çš„å¼•è¨€ã€æ–‡çŒ®ç»¼è¿°å’Œç ”ç©¶è®¾è®¡å†…å®¹ï¼Œæ’°å†™ä¸€ä¸ªè¿è´¯çš„ç»“è®ºéƒ¨åˆ†ã€‚
        ç»“è®ºåº”åŒ…å«æ—¶é—´è½´ã€é¢„æœŸæˆæœå’Œæœ€ç»ˆæ€»ç»“ã€‚
        ç¡®ä¿ç»“è®ºä¸å‰é¢ç« èŠ‚æå‡ºçš„ç ”ç©¶é—®é¢˜ã€æ–¹æ³•è®ºå’Œç›®æ ‡ä¿æŒä¸€è‡´ã€‚
        å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**æ’°å†™
        """
        
        logging.info("ğŸ“œ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç»“è®ºéƒ¨åˆ†...")
        response = self.llm.invoke([HumanMessage(content=conclusion_prompt_text)])
        
        state["conclusion"] = response.content
        logging.info("âœ… ç»“è®ºéƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state


    def generate_final_references_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_section = self.generate_reference_section(state)
        
        # å°†å‚è€ƒæ–‡çŒ®ä½œä¸ºç‹¬ç«‹éƒ¨åˆ†ä¿å­˜
        state["final_references"] = reference_section
        logging.info("âœ… å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
        
        return state

    def generate_final_report_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„Markdownç ”ç©¶è®¡åˆ’ä¹¦æŠ¥å‘Š"""
        logging.info("ğŸ“„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆçš„ç ”ç©¶è®¡åˆ’ä¹¦MarkdownæŠ¥å‘Š...")
        
        research_field = state.get("research_field", "æœªçŸ¥é¢†åŸŸ")
        introduction = state.get("introduction", "æ— å¼•è¨€å†…å®¹")
        literature_review = state.get("literature_review", "æ— æ–‡çŒ®ç»¼è¿°å†…å®¹")
        research_design = state.get("research_design", "æ— ç ”ç©¶è®¾è®¡å†…å®¹")
        conclusion = state.get("conclusion", "æ— ç»“è®ºå†…å®¹")
        final_references = state.get("final_references", "æ— å‚è€ƒæ–‡çŒ®")
        
        research_plan = state.get("research_plan", "æ— åˆå§‹ç ”ç©¶è®¡åˆ’")
        execution_memory = state.get("execution_memory", [])
        
        # åˆ›å»ºoutputæ–‡ä»¶å¤¹
        output_dir = "./output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        # ç”¨uuidæ›¿æ¢æ—¶é—´æˆ³
        uuid = state["proposal_id"]
        #timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_research_field = "".join(c for c in research_field if c.isalnum() or c in (' ', '-', '_')).rstrip().replace(' ', '_')[:30]
        report_filename = f"Research_Proposal_{safe_research_field}_{uuid}.md"
        report_filepath = os.path.join(output_dir, report_filename)
        
        # æ„å»ºMarkdownå†…å®¹
        report_content = f"# ç ”ç©¶è®¡åˆ’ä¹¦ï¼š{research_field}\n\n"
        
        # report_content += "## 1. å¼•è¨€\n\n"
        report_content += f"{introduction}\n\n"
        
        # report_content += "## 2. æ–‡çŒ®ç»¼è¿°\n\n"
        report_content += f"{literature_review}\n\n"
        
        # report_content += "## 3. ç ”ç©¶è®¾è®¡ä¸æ–¹æ³•\n\n"
        report_content += f"{research_design}\n\n"
        
        # report_content += "## 4. ç»“è®ºä¸å±•æœ›\n\n" # ç»“è®ºéƒ¨åˆ†å·²åŒ…å«æ—¶é—´è½´å’Œé¢„æœŸæˆæœ
        report_content += f"{conclusion}\n\n"
        
        report_content += f"{final_references}\n\n" # å‚è€ƒæ–‡çŒ®éƒ¨åˆ†è‡ªå¸¦ "## å‚è€ƒæ–‡çŒ®" æ ‡é¢˜
        
        report_content += "---\n"
        report_content += "## é™„å½•ï¼šè¿‡ç¨‹èµ„æ–™\n\n"
        
        report_content += "### A.1 åˆå§‹ç ”ç©¶è®¡åˆ’\n\n"
        report_content += "```markdown\n"
        report_content += f"{research_plan}\n"
        report_content += "```\n\n"
        
        report_content += "### A.2 æ‰§è¡Œæ­¥éª¤è®°å½•\n\n"
        if execution_memory:
            for i, step_memory in enumerate(execution_memory):
                action = step_memory.get("action", "æœªçŸ¥åŠ¨ä½œ")
                desc = step_memory.get("description", "æ— æè¿°")
                res = step_memory.get("result", "æ— ç»“æœ")
                success_status = "æˆåŠŸ" if step_memory.get("success") else "å¤±è´¥"
                report_content += f"**æ­¥éª¤ {i+1}: {desc}** ({action})\n"
                report_content += f"- çŠ¶æ€: {success_status}\n"
                report_content += f"- ç»“æœæ‘˜è¦: {str(res)[:150]}...\n\n"
        else:
            report_content += "æ— æ‰§è¡Œè®°å½•ã€‚\n\n"
            
        report_content += "### A.3 æ”¶é›†çš„æ–‡çŒ®ä¸ä¿¡æ¯æ‘˜è¦\n\n"
        report_content += self.get_literature_summary_with_refs(state) + "\n\n"

        try:
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
            logging.info(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")
            state["final_report_markdown"] = report_content
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜æœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            state["final_report_markdown"] = "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"
            
        return state

    def should_continue(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–è¿›å…¥å†™ä½œé˜¶æ®µ"""
        # æ–°å¢ï¼šå¦‚æœåˆšç”Ÿæˆäº†æ¾„æ¸…é—®é¢˜ä¸”ç”¨æˆ·å°šæœªå›åº”ï¼Œåˆ™åº”æç¤ºç”¨æˆ·å›åº”
        if state.get("clarification_questions") and not state.get("user_clarifications"):
            # åœ¨å®è·µä¸­ï¼Œå›¾åº”è¯¥åœ¨æ­¤å¤„æš‚åœæˆ–ç»“æŸï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥ã€‚
            # å¯¹äºå½“å‰å•æ¬¡è°ƒç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…è®¸å…¶ç»§ç»­ï¼Œä½†æ€»ä½“è§„åˆ’ä¼šå—å½±å“ã€‚
            # æˆ–è€…ï¼Œå¯ä»¥è®¾è®¡ä¸€ä¸ªç‰¹æ®Šçš„ç»“æŸçŠ¶æ€ï¼Œæç¤ºéœ€è¦ç”¨æˆ·è¾“å…¥ã€‚
            # ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬è®©å®ƒç»§ç»­ï¼Œä½†æ€»ä½“è§„åˆ’å¯èƒ½ä¸å¤Ÿèšç„¦ã€‚
            # ä¸€ä¸ªæ›´å¥½çš„æ–¹æ³•æ˜¯ï¼Œå¦‚æœclarification_questionså­˜åœ¨ï¼Œåˆ™åœ¨æ­¤å¤„è¿”å›ä¸€ä¸ªç‰¹æ®Šä¿¡å·
            # è®©è°ƒç”¨è€…çŸ¥é“éœ€è¦ç”¨æˆ·è¾“å…¥ã€‚ä½†å½“å‰langgraphçš„should_continueé€šå¸¸ç”¨äºå·¥å…·æ‰§è¡Œå¾ªç¯ã€‚
            # logging.info("â³ ç­‰å¾…ç”¨æˆ·å¯¹æ¾„æ¸…é—®é¢˜çš„å›åº”ã€‚ç»§ç»­å½“å‰æµç¨‹ï¼Œä½†å»ºè®®æä¾›æ¾„æ¸…ä»¥è·å¾—æ›´ä½³ç»“æœã€‚")
            # å¦‚æœæ¾„æ¸…é—®é¢˜å·²ç”Ÿæˆä½†ç”¨æˆ·æœªæä¾›æ¾„æ¸…ï¼Œåˆ™ä¸åº”ç›´æ¥è¿›å…¥å·¥å…·æ‰§è¡Œæˆ–å†™ä½œ
            # ç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™é‡Œåº”è¯¥æœ‰ä¸€ä¸ªåˆ†æ”¯é€»è¾‘ï¼Œå¦‚æœæ¾„æ¸…é—®é¢˜å­˜åœ¨ä¸”æ— ç­”æ¡ˆï¼Œåˆ™å›¾åº”è¯¥ç»“æŸå¹¶è¿”å›é—®é¢˜
            # ä½†ç”±äº `should_continue` ä¸»è¦æ§åˆ¶å·¥å…·æ‰§è¡Œå¾ªç¯ï¼Œæˆ‘ä»¬å°†å…è®¸å®ƒè¿›å…¥plan_analysis
            # plan_analysis å’Œ master_plan ä¼šåŸºäºæœ‰æ— æ¾„æ¸…ä¿¡æ¯æ¥è°ƒæ•´è¡Œä¸º
            pass


        current_step = state.get("current_step", 0)
        execution_plan = state.get("execution_plan", [])
        execution_memory = state.get("execution_memory", [])
        max_iterations = state.get("max_iterations", 10)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if len(execution_memory) >= max_iterations:
            logging.info(f"è¾¾åˆ°æœ€å¤§å·¥å…·æ‰§è¡Œæ¬¡æ•° ({max_iterations})ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ") # æ›´æ–°æ—¥å¿—æ¶ˆæ¯
            return "write_introduction"
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ­¥éª¤è¦æ‰§è¡Œ
        if current_step < len(execution_plan):
            return "execute_step"
        
        # æ£€æŸ¥æ˜¯å¦æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        
        logging.info(f"å½“å‰æ”¶é›†æƒ…å†µ: {len(arxiv_papers)} ç¯‡è®ºæ–‡, {len(web_results)} æ¡ç½‘ç»œç»“æœ")
        
        # å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ
        if len(arxiv_papers) >= 3 or len(web_results) >= 3:
            logging.info("å·²æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "write_introduction"
        
        # æ£€æŸ¥æœ€è¿‘çš„æ‰§è¡Œç»“æœ
        recent_results = execution_memory[-3:] if len(execution_memory) >= 3 else execution_memory
        successful_results = [r for r in recent_results if r.get("success", False)]
        
        # å¦‚æœæœ€è¿‘çš„ç»“æœéƒ½ä¸æˆåŠŸï¼Œé‡æ–°è§„åˆ’
        if len(successful_results) < len(recent_results) * 0.3:
            logging.info("æœ€è¿‘æ‰§è¡Œç»“æœä¸ç†æƒ³ï¼Œé‡æ–°è§„åˆ’...")
            state["current_step"] = 0
            return "plan_analysis"
        
        # å¦‚æœæ‰§è¡Œäº†ä¸€è½®ä½†ä¿¡æ¯ä¸è¶³ï¼Œç»§ç»­è§„åˆ’
        if len(arxiv_papers) < 3 and len(web_results) < 3:
            logging.info("ä¿¡æ¯æ”¶é›†ä¸è¶³ï¼Œç»§ç»­è§„åˆ’...")
            state["current_step"] = 0
            return "plan_analysis"
        
        # é»˜è®¤è¿›å…¥å†™ä½œé˜¶æ®µ
        return "write_introduction"
    
    
    

    def _build_workflow(self) -> CompiledStateGraph:

        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("clarify_research_focus", self.clarify_research_focus_node) 
        workflow.add_node("create_master_plan", self.create_master_plan_node)
        workflow.add_node("plan_analysis", self.plan_analysis_node)
        workflow.add_node("execute_step", self.execute_step_node)
        workflow.add_node("write_introduction", self.write_introduction_node)
        workflow.add_node("write_literature_review", self.write_literature_review_node)
        workflow.add_node("write_research_design", self.write_research_design_node)
        workflow.add_node("write_conclusion", self.write_conclusion_node) 
        workflow.add_node("generate_final_references", self.generate_final_references_node)
        workflow.add_node("generate_final_report", self.generate_final_report_node) 
        
        # å®šä¹‰æµç¨‹
        workflow.set_entry_point("clarify_research_focus") 
        
        # Conditional edge after clarification
        workflow.add_conditional_edges(
            "clarify_research_focus",
            self._decide_after_clarification, # This is where the method is called
            {
                "end_for_user_input": END, 
                "proceed_to_master_plan": "create_master_plan"
            }
        )
        
        workflow.add_edge("create_master_plan", "plan_analysis")
        
        # æ¡ä»¶è¾¹ï¼šæ ¹æ®æ‰§è¡Œæƒ…å†µå†³å®šä¸‹ä¸€æ­¥
        workflow.add_conditional_edges(
            "plan_analysis",
            lambda state: "execute_step",  
            {"execute_step": "execute_step"}
        )
        
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue,  
            {
                "execute_step": "execute_step",  
                "plan_analysis": "plan_analysis",  
                "write_introduction": "write_introduction" 
            }
        )
        
        workflow.add_edge("write_introduction", "write_literature_review")
        workflow.add_edge("write_literature_review", "write_research_design")
        workflow.add_edge("write_research_design", "write_conclusion") 
        workflow.add_edge("write_conclusion", "generate_final_references") 
        workflow.add_edge("generate_final_references", "generate_final_report") 
        workflow.add_edge("generate_final_report", END) 
        
        return workflow.compile() 
    


    def generate_proposal(self, research_field: str, proposal_id: str, user_clarifications: str = "") -> Dict[str, Any]:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦"""
        initial_state = ProposalState(
            research_field=research_field,
            user_clarifications=user_clarifications, # æ–°å¢ï¼šæ¥æ”¶ç”¨æˆ·æ¾„æ¸…
            clarification_questions=[], # æ–°å¢ï¼šåˆå§‹åŒ–æ¾„æ¸…é—®é¢˜åˆ—è¡¨
            query="",
            arxiv_papers=[],
            web_search_results=[],
            background="",
            objectives="",
            methodology="",
            timeline="",
            expected_outcomes="",
            final_proposal="",
            messages=[],
            research_plan="",
            available_tools=[],
            execution_plan=[],
            execution_memory=[],
            current_step=0,
            max_iterations=10,
            introduction="",
            literature_review="",
            research_design="",
            timeline_plan="",
            expected_results="",
            reference_list=[],  # åˆå§‹åŒ–ç»Ÿä¸€å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            ref_counter=1,      # åˆå§‹åŒ–å‚è€ƒæ–‡çŒ®è®¡æ•°å™¨
            final_references="", 
            conclusion="",       
            final_report_markdown="" # åˆå§‹åŒ–æœ€ç»ˆæŠ¥å‘Šå­—æ®µ

        )
        initial_state["proposal_id"] = proposal_id
        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶é—®é¢˜: '{research_field}'")
        result = self.workflow.invoke(initial_state)
        return result