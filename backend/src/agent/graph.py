"""
Agentç”Ÿæˆè¿‡ç¨‹ä¸­çš„å›¾ç›¸å…³ï¼šèŠ‚ç‚¹
"""
import time
from pathlib import Path

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any, Tuple
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging
from .prompts import *  # ç¡®ä¿ CLARIFICATION_QUESTION_PROMPT ä»è¿™é‡Œå¯¼å…¥
import fitz
from dotenv import load_dotenv
from .tools import search_arxiv_papers_tool, search_crossref_papers_tool, search_web_content_tool, summarize_pdf, generate_gantt_chart_tool, search_google_scholar_site_tool
from .state import ProposalState
from ..utils.queue_util import QueueUtil
from ..utils.stream_mes_util import StreamUtil
from ..entity.stream_mes import StreamMes, StreamClarifyMes, StreamAnswerMes
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

load_dotenv()
TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")
DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY")
base_url = os.environ.get("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)


class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key=DASHSCOPE_API_KEY,
            model="qwen-plus-latest",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0,
            streaming=True,  # ç»Ÿä¸€ä¸ºæµå¼è¾“å‡º
        )

        # è®¾ç½®Tavily APIå¯†é’¥
        # os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

        self.tools = [search_arxiv_papers_tool, search_web_content_tool, search_crossref_papers_tool, summarize_pdf, generate_gantt_chart_tool, search_google_scholar_site_tool]
        self.tools_description = self.load_tools_description()
        self.agent_with_tools = create_react_agent(self.llm, self.tools)
        
        # å…ˆç¼–è¯‘å·¥ä½œæµï¼Œååˆå§‹åŒ–å¯èƒ½æœ‰é—®é¢˜çš„ç»„ä»¶
        print("å…ˆç¼–è¯‘å·¥ä½œæµ...")
        self.workflow = self._build_workflow()
        
        print("å†åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        # åˆå§‹åŒ–é•¿æœŸè®°å¿†
        self.embedding_function = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        self.long_term_memory = Chroma(
            collection_name="proposal_agent_memory",
            embedding_function=self.embedding_function,
            persist_directory="./chroma_db"  # æŒä¹…åŒ–å­˜å‚¨è·¯å¾„
        )

        # self.workflow = self._build_workflow()

    def load_tools_description(self) -> List[Dict]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·¥å…·æè¿°"""
        current_script_dir = os.path.dirname(os.path.abspath(__file__))
        tools_json_path = os.path.join(current_script_dir, 'tools.json')
        try:
            with open(tools_json_path, 'r', encoding='utf-8') as f:
                tools_description = json.load(f)
            return tools_description
        except FileNotFoundError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        except json.JSONDecodeError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []

    def get_tools_info_text(self) -> str:
        """å°†å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if not self.tools_description:
            return "æš‚æ— å¯ç”¨å·¥å…·ä¿¡æ¯"

        tools_text = "å¯ç”¨å·¥å…·åˆ—è¡¨:\n\n"
        for tool_info in self.tools_description:
            func_info = tool_info.get("function", {})
            name = func_info.get("name", "æœªçŸ¥å·¥å…·")
            description = func_info.get("description", "æ— æè¿°")

            tools_text += f"ğŸ”§ **{name}**\n"
            tools_text += f"   æè¿°: {description}\n"

            # æ·»åŠ å‚æ•°ä¿¡æ¯
            params = func_info.get("parameters", {}).get("properties", {})
            if params:
                tools_text += f"   å‚æ•°:\n"
                for param_name, param_info in params.items():
                    param_desc = param_info.get("description", "æ— æè¿°")
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    required = param_name in func_info.get("parameters", {}).get("required", [])
                    required_text = "å¿…éœ€" if required else "å¯é€‰"
                    tools_text += f"     - {param_name} ({param_type}, {required_text}): {param_desc}\n"

            tools_text += "\n"

        return tools_text

    def clarify_research_focus_node(self, state: ProposalState) -> ProposalState:
        """æ ¹æ®ç ”ç©¶é¢†åŸŸç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œæˆ–å¤„ç†ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯"""
        research_field = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        existing_questions = state.get("clarification_questions", [])
        revision_guidance = state.get("revision_guidance", "")

        # å¦‚æœæœ‰ä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡ç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼ˆæ”¹è¿›æµç¨‹ä¸­ä¸éœ€è¦æ¾„æ¸…ï¼‰
        if revision_guidance:
            logging.info(f"ğŸ“ æ£€æµ‹åˆ°ä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡æ¾„æ¸…é—®é¢˜ç”Ÿæˆæ­¥éª¤")
            state["clarification_questions"] = []
            return state

        # åŸæœ‰é€»è¾‘ä¿æŒä¸å˜
        if user_clarifications:
            logging.info(f"ğŸ” ç”¨æˆ·å·²æä¾›ç ”ç©¶æ–¹å‘çš„æ¾„æ¸…ä¿¡æ¯: {user_clarifications[:200]}...")
            # ç”¨æˆ·å·²æä¾›æ¾„æ¸…ï¼Œæ— éœ€å†ç”Ÿæˆé—®é¢˜
            state["clarification_questions"] = []  # æ¸…ç©ºæ—§é—®é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
            return state

        if existing_questions:
            logging.info("ğŸ“ å·²å­˜åœ¨æ¾„æ¸…é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·å›åº”ã€‚")
            # å¦‚æœå·²æœ‰é—®é¢˜ä½†æ— ç”¨æˆ·å›åº”ï¼Œåˆ™ä¸é‡å¤ç”Ÿæˆ
            return state

        # ç”Ÿæˆæ–°çš„æ¾„æ¸…é—®é¢˜
        logging.info(f"ğŸ¤” æ­£åœ¨ä¸ºç ”ç©¶é¢†åŸŸ '{research_field}' ç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜...")

        prompt = CLARIFICATION_QUESTION_PROMPT.format(research_field=research_field)
        full_content = StreamUtil.transfer_stream_clarify_mes(
            stream_res=self.llm.stream([HumanMessage(prompt)]),
            proposal_id=state["proposal_id"]
        )
        questions = [q.strip() for q in full_content.split('\n') if q.strip()]

        if questions:
            state["clarification_questions"] = questions
            logging.info("âœ… æˆåŠŸç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜ï¼š")
            for i, q in enumerate(questions):
                logging.info(f"  {i + 1}. {q}")
            logging.info("ğŸ“¢ è¯·ç”¨æˆ·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜æä¾›å›åº”ï¼Œå¹¶åœ¨ä¸‹æ¬¡è¯·æ±‚æ—¶é€šè¿‡ 'user_clarifications' å­—æ®µä¼ å…¥ã€‚")
        else:
            logging.warning("âš ï¸ æœªèƒ½ä»LLMå“åº”ä¸­è§£æå‡ºæ¾„æ¸…æ€§é—®é¢˜ã€‚")
            state["clarification_questions"] = []

        # ç­‰å¾…ç”¨æˆ·è¾“å…¥æœ€å¤š60ç§’
        wait_seconds = 60
        logging.info(f"â³ å¼€å§‹ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œæœ€é•¿ {wait_seconds} ç§’...")

        for i in range(wait_seconds):
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·è¾“å…¥
            user_clarification = QueueUtil.get_clarification(state["proposal_id"])
            if user_clarification:
                state["user_clarifications"] = user_clarification
                logging.info(f"âœ… åœ¨ç­‰å¾… {i + 1} ç§’åæ£€æµ‹åˆ°ç”¨æˆ·è¾“å…¥ï¼Œç«‹å³è¿”å›")
                return state
            # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(1)

        logging.info(f"â° å·²ç­‰å¾… {wait_seconds} ç§’ï¼Œæœªæ”¶åˆ°ç”¨æˆ·è¾“å…¥")
        return state

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“çš„è§„åˆ’"""
        state["global_step_num"] += 1
        start_time = time.time()

        research_field_original = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        revision_guidance = state.get("revision_guidance", "")  # è·å–ä¿®è®¢æŒ‡å¯¼
        tools_info = self.get_tools_info_text()

        # --- ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ ---
        logging.info(f"ğŸ” æ­£åœ¨ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¸ '{research_field_original}' ç›¸å…³çš„ä¿¡æ¯...")
        try:
            retrieved_docs = self.long_term_memory.similarity_search(research_field_original, k=2)  # æ£€ç´¢æœ€ç›¸å…³çš„2ä¸ª
        except Exception as e:
            logging.warning(f"âš ï¸ ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¿¡æ¯å¤±è´¥: {e}")
            retrieved_docs = []

        retrieved_knowledge_text = ""
        if retrieved_docs:
            logging.info(f"âœ… ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ° {len(retrieved_docs)} æ¡ç›¸å…³è®°å½•ã€‚")
            retrieved_knowledge_text += "\n\n### ä¾›å‚è€ƒçš„å†å²ç ”ç©¶é¡¹ç›®æ‘˜è¦\n"
            retrieved_knowledge_text += "è¿™æ˜¯è¿‡å»å®Œæˆçš„ç±»ä¼¼ç ”ç©¶é¡¹ç›®ï¼Œä½ å¯ä»¥å€Ÿé‰´å®ƒä»¬çš„æ€è·¯å’Œç»“è®ºï¼Œä½†ä¸è¦ç…§æ¬ã€‚\n"
            for i, doc in enumerate(retrieved_docs):
                retrieved_knowledge_text += f"\n--- ç›¸å…³å†å²é¡¹ç›® {i + 1} ---\n"
                retrieved_knowledge_text += doc.page_content
                retrieved_knowledge_text += "\n--------------------------\n"        # ------------------------------------

        # æ„å»ºæç¤ºæ–‡æœ¬
        prompt_additions = []
        
        if user_clarifications:
            clarification_text = (
                f"\n\né‡è¦å‚è€ƒï¼šç”¨æˆ·ä¸ºè¿›ä¸€æ­¥èšç„¦ç ”ç©¶æ–¹å‘ï¼Œæä¾›äº†ä»¥ä¸‹æ¾„æ¸…ä¿¡æ¯ã€‚åœ¨åˆ¶å®šè®¡åˆ’æ—¶ï¼Œè¯·åŠ¡å¿…ä»”ç»†è€ƒè™‘è¿™äº›å†…å®¹ï¼š\n"
                f"{user_clarifications}\n"
            )
            prompt_additions.append(clarification_text)
            logging.info("ğŸ“ ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯æ¥æŒ‡å¯¼æ€»ä½“è§„åˆ’ã€‚")
            logging.info(f"ğŸ“ æ¾„æ¸…ä¿¡æ¯é•¿åº¦: {len(user_clarifications)} å­—ç¬¦")
        else:
            logging.info("ğŸ“ æ— ç”¨æˆ·æ¾„æ¸…ä¿¡æ¯")

        if revision_guidance:
            logging.info("ğŸ“ æ£€æµ‹åˆ°ä¿®è®¢æŒ‡å¯¼ï¼Œå¼€å§‹å¤„ç†...")            # æå–ä¿®è®¢æŒ‡å—çš„æ‘˜è¦éƒ¨åˆ†
            revision_summary = ""
            lines = revision_guidance.split("\n")
            in_key_issues = False
            count = 0

            for line in lines:
                if "éœ€è¦æ”¹è¿›çš„å…³é”®é—®é¢˜" in line:
                    in_key_issues = True
                    revision_summary += line + "\n"
                    continue

                if in_key_issues and line.strip() and not line.startswith("##"):
                    revision_summary += line + "\n"
                    count += 1

                if count > 5 or (in_key_issues and line.startswith("##")):
                    in_key_issues = False

            if not revision_summary:
                # å¦‚æœæ²¡æœ‰æå–åˆ°å…³é”®é—®é¢˜ï¼Œä½¿ç”¨å‰500ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
                revision_summary = revision_guidance[:500] + "...(æ›´å¤šè¯¦ç»†ä¿®è®¢å»ºè®®)"

            revision_text = (
                f"\n\nä¿®è®¢æŒ‡å¯¼ï¼šè¯·æ ¹æ®ä»¥ä¸‹ä¿®è®¢å»ºè®®è°ƒæ•´ç ”ç©¶è®¡åˆ’ï¼Œä¿ç•™åŸè®¡åˆ’çš„ä¼˜åŠ¿å¹¶æ”¹è¿›ä¸è¶³ï¼š\n"
                f"{revision_summary}\n"
            )
            prompt_additions.append(revision_text)
            logging.info("ğŸ“ ä½¿ç”¨è¯„å®¡åé¦ˆçš„ä¿®è®¢æŒ‡å¯¼æ¥æ”¹è¿›è®¡åˆ’ã€‚")
        else:
            logging.info("ğŸ“ æ— ä¿®è®¢æŒ‡å¯¼")

        # æ„å»ºå®Œæ•´æç¤º
        logging.info("ğŸ”§ å¼€å§‹æ„å»ºæç¤ºæ¨¡æ¿...")
        try:
            base_prompt_template = master_plan_instruction  # ä» prompts.py å¯¼å…¥
            logging.info(f"âœ… æˆåŠŸè·å–åŸºç¡€æç¤ºæ¨¡æ¿ï¼Œé•¿åº¦: {len(base_prompt_template)} å­—ç¬¦")
        except NameError as e:
            logging.error(f"âŒ master_plan_instruction æœªå®šä¹‰: {e}")
            # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é»˜è®¤æ¨¡æ¿
            base_prompt_template = """
            è¯·ä¸ºä»¥ä¸‹ç ”ç©¶é¢†åŸŸåˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’ï¼š

            ç ”ç©¶é¢†åŸŸï¼š{research_field}

            å¯ç”¨å·¥å…·ï¼š
            {tools_info}

            è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å«ç ”ç©¶ç›®æ ‡ã€æ–¹æ³•è®ºå’Œé¢„æœŸæˆæœçš„è¯¦ç»†è®¡åˆ’ã€‚
            """
            logging.info("âœ… ä½¿ç”¨é»˜è®¤æç¤ºæ¨¡æ¿")
        except Exception as e:
            logging.error(f"âŒ è·å–æç¤ºæ¨¡æ¿æ—¶å‡ºé”™: {e}")
            return state
            
        lines = base_prompt_template.splitlines()
        new_lines = []
        inserted = False
        for line in lines:
            new_lines.append(line)
            if "{research_field}" in line and prompt_additions:
                # åœ¨åŒ…å« {research_field} çš„è¡Œä¹‹åæ’å…¥æç¤ºä¿¡æ¯
                new_lines.extend(prompt_additions)
                inserted = True

        if not inserted and prompt_additions:  # åå¤‡ï¼šå¦‚æœå ä½ç¬¦æœªæ‰¾åˆ°ï¼Œåˆ™è¿½åŠ 
            new_lines.extend(prompt_additions)
            
        modified_master_plan_prompt_template = "\n".join(new_lines)
        
        master_planning_prompt = modified_master_plan_prompt_template.format(
            research_field=research_field_original,  # æ­¤å¤„ä½¿ç”¨åŸå§‹ç ”ç©¶é¢†åŸŸ
            tools_info=tools_info
        )
        
        # å°†æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯æ•´åˆåˆ°æœ€ç»ˆçš„æç¤ºä¸­
        final_prompt = (
            f"{master_planning_prompt}\n"
            f"{retrieved_knowledge_text}"
        )
        
        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field_original}' (å·²è€ƒè™‘ç”¨æˆ·æ¾„æ¸…å’Œå†å²çŸ¥è¯†) åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
          # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logging.info(f"ğŸ“‹ æœ€ç»ˆæç¤ºé•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        logging.info(f"ğŸ“‹ æç¤ºå‰500å­—ç¬¦: {final_prompt[:500]}...")
        
        try:
            logging.info("ğŸ”„ å¼€å§‹è°ƒç”¨LLM stream...")
            
            # é¦–å…ˆå°è¯•ä¸€ä¸ªç®€å•çš„æµ‹è¯•è°ƒç”¨
            test_response = self.llm.invoke([HumanMessage("è¯·å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ")])
            logging.info(f"âœ… LLM æµ‹è¯•è°ƒç”¨æˆåŠŸ: {test_response.content}")
            
            # ç„¶åè¿›è¡Œå®é™…çš„streamè°ƒç”¨
            stream_response = self.llm.stream([HumanMessage(final_prompt)])
            logging.info("âœ… LLM stream åˆ›å»ºæˆåŠŸï¼Œå¼€å§‹å¤„ç†å“åº”...")
            
            full_content = StreamUtil.transfer_stream_answer_mes(
                stream_res=stream_response,
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="ç”Ÿæˆè®¡åˆ’"
            )
            logging.info(f"âœ… LLM å“åº”å¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
            
        except Exception as e:
            logging.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            # è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„ç ”ç©¶è®¡åˆ’ä»¥é¿å…ç³»ç»Ÿå®Œå…¨å¡æ­»
            full_content = f"ç”±äºæŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•å®Œæˆè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’ç”Ÿæˆã€‚ç ”ç©¶ä¸»é¢˜ï¼š{research_field_original}"

        state["research_plan"] = full_content
        # response = self.llm.invoke([HumanMessage(content=final_prompt)])

        # state["research_plan"] = response.content
        state["available_tools"] = self.tools_description
        state["execution_memory"] = []
        state["history_summary"] = ""  # é‡ç½®å†å²æ‘˜è¦
        state["current_step"] = 0
        state["max_iterations"] = 10

        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")
        logging.info(f"ç ”ç©¶è®¡åˆ’å†…å®¹ (éƒ¨åˆ†): {state['research_plan'][:300]}...")

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )

        return state

    # Ensure this method is correctly indented as part of the ProposalAgent class
    # def _decide_after_clarification(self, state: ProposalState) -> str:
    #     """ç¡®å®šæ¾„æ¸…èŠ‚ç‚¹åçš„ä¸‹ä¸€æ­¥ã€‚"""
    #     revision_guidance = state.get("revision_guidance", "")
    #
    #     # å¦‚æœæœ‰ä¿®è®¢æŒ‡å¯¼ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€æ­¥
    #     if revision_guidance:
    #         logging.info("âœ… æ£€æµ‹åˆ°ä¿®è®¢æŒ‡å¯¼ï¼Œç›´æ¥è¿›å…¥è®¡åˆ’ç”Ÿæˆé˜¶æ®µã€‚")
    #         return "proceed_to_master_plan"
    #
    #     # åŸæœ‰é€»è¾‘
    #     if state.get("clarification_questions") and not state.get("user_clarifications"):
    #         logging.info("â“ Clarification questions generated. Waiting for user input.")
    #         return "end_for_user_input"
    #     logging.info("âœ… No clarification needed or clarifications provided. Proceeding to master plan.")
    #     return "proceed_to_master_plan"

    def plan_analysis_node(self, state: ProposalState) -> ProposalState:
        """è§£æç ”ç©¶è®¡åˆ’,ç”Ÿæˆå¯æ‰§è¡Œæ­¥éª¤"""
        state["global_step_num"] += 1
        start_time = time.time()

        research_field = state["research_field"]
        research_plan = state["research_plan"]
        tools_info = self.get_tools_info_text()
        history_summary = state.get("history_summary", "")

        memory_text = ""
        if history_summary:
            memory_text = f"\n\næ‰§è¡Œå†å²æ‘˜è¦:\n{history_summary}\n"
            logging.info("ğŸ§  å·²ä½¿ç”¨å†å²æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡ã€‚")
        else:
            # åªæœ‰åœ¨æ²¡æœ‰æ‘˜è¦æ—¶ï¼Œæ‰ä½¿ç”¨å®Œæ•´çš„æ‰§è¡Œå†å²
            execution_memory = state.get("execution_memory", [])
            if execution_memory:
                memory_text = "\n\nå®Œæ•´æ‰§è¡Œå†å²:\n"
                for step in execution_memory:
                    description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
                    result = step.get('result', 'æ— ç»“æœ')
                    success = step.get('success', False)
                    status = "æˆåŠŸ" if success else "å¤±è´¥"
                    memory_text += f"- {description}: {status} - {result[:100]}...\n"

        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        plan_analysis_prompt = EXECUTION_PLAN_PROMPT.format(
            research_field=research_field,
            research_plan=research_plan,
            tools_info=tools_info,
            memory_text=memory_text
        )
        logging.info("ğŸ” Agentæ­£åœ¨åˆ†æè®¡åˆ’å¹¶ç”Ÿæˆæ‰§è¡Œæ­¥éª¤...")
        full_content = StreamUtil.transfer_stream_answer_mes(
            stream_res=self.llm.stream([HumanMessage(plan_analysis_prompt)]),
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="åˆ¶å®šæ­¥éª¤"
        )
        # logging.info("ç”Ÿæˆè®¡åˆ’", response.content)
        try:
            # è§£æJSONå“åº”
            full_content = full_content.strip()
            # å¦‚æœå“åº”åŒ…å«```jsonï¼Œåˆ™æå–JSONéƒ¨åˆ†
            if "```json" in full_content:
                start = full_content.find("```json") + 7
                end = full_content.find("```", start)
                if end != -1:
                    full_content = full_content[start:end].strip()
            elif "```" in full_content:
                start = full_content.find("```") + 3
                end = full_content.find("```", start)
                if end != -1:
                    full_content = full_content[start:end].strip()

            plan_data = json.loads(full_content)
            state["execution_plan"] = plan_data.get("steps", [])
        except json.JSONDecodeError:
            logging.error("æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’JSONï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
            logging.error(f"åŸå§‹å“åº”: {full_content}...")
            # é»˜è®¤æ‰§è¡Œè®¡åˆ’
            state["execution_plan"] = [
                {
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {"query": research_field, "max_results": 5},
                    "description": f"æœç´¢ArXivä¸Šå…³äº{research_field}çš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }
            ]

        logging.info(f"âœ… ç”Ÿæˆäº† {len(state['execution_plan'])} ä¸ªæ‰§è¡Œæ­¥éª¤")

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return state

    def execute_step_node(self, state: ProposalState) -> ProposalState:
        """æ‰§è¡Œå½“å‰æ­¥éª¤"""
        execution_plan = state.get("execution_plan", [])
        current_step_index = state.get("current_step", 0)

        if current_step_index >= len(execution_plan):
            logging.info("æ‰€æœ‰è®¡åˆ’å†…æ­¥éª¤å·²æ‰§è¡Œå®Œæˆï¼Œæ— éœ€è¿›ä¸€æ­¥æ“ä½œã€‚")
            # This case should ideally be caught by should_continue, but as a safeguard:
            return state

        # ä½¿ç”¨ç´¢å¼•è·å–å½“å‰æ­¥éª¤ï¼Œä¸ä¿®æ”¹åŸå§‹åˆ—è¡¨
        current_action = execution_plan[current_step_index]
        action_name = current_action.get("action")
        parameters = current_action.get("parameters", {})
        description = current_action.get("description", "")

        logging.info(f"ğŸš€ æ‰§è¡Œæ­¥éª¤ {current_step_index + 1}/{len(execution_plan)}: {description}")

        result = None
        memory_entry = {}
        try:
            # æ ¹æ®action_nameè°ƒç”¨ç›¸åº”çš„å·¥å…·
            tool_to_call = {
                "search_arxiv_papers": search_arxiv_papers_tool,
                "search_web_content": search_web_content_tool,
                "search_crossref_papers": search_crossref_papers_tool,
                "summarize_pdf": summarize_pdf,
                "search_google_scholar_site": search_google_scholar_site_tool,
            }.get(action_name)

            if tool_to_call:
                result = tool_to_call.invoke(parameters)
                # ç‰¹å®šäºå·¥å…·çš„çŠ¶æ€æ›´æ–°
                if action_name == "search_arxiv_papers":
                    state["arxiv_papers"].extend(result or [])
                elif action_name in ["search_web_content", "search_crossref_papers", "search_google_scholar_site"]:
                    state["web_search_results"].extend(result or [])
                elif action_name == "summarize_pdf" and result and "summary" in result:
                    for paper in state["arxiv_papers"]:
                        if paper.get("local_pdf_path") == parameters.get("path"):
                            paper["detailed_summary"] = result["summary"]
                            break
            else:
                result = f"æœªçŸ¥æˆ–ä¸æ”¯æŒçš„ action: {action_name}"
                raise ValueError(result)

            # æ¯æ¬¡æˆåŠŸè·å–æ•°æ®åæ›´æ–°å‚è€ƒæ–‡çŒ®
            state = self.add_references_from_data(state)

            memory_entry = {
                "step_id": current_step_index + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": str(result)[:500] if result else "æ— ç»“æœ",
                "success": True,
            }

        except Exception as e:
            logging.error(f"æ‰§è¡Œæ­¥éª¤ '{description}' å¤±è´¥: {e}")
            memory_entry = {
                "step_id": current_step_index + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False,
            }

        # æ›´æ–°æ‰§è¡Œå†å²å’Œæ­¥æ•°è®¡æ•°å™¨
        state["execution_memory"].append(memory_entry)
        state["current_step"] = current_step_index + 1

        logging.info(f"âœ… æ­¥éª¤ {state['current_step']}/{len(execution_plan)} æ‰§è¡Œå®Œæˆ: {action_name}")
        return state

    def add_references_from_data(self, state: ProposalState) -> ProposalState:
        """ä»æ”¶é›†çš„æ•°æ®ä¸­æå–å¹¶æ·»åŠ å‚è€ƒæ–‡çŒ®"""
        state["global_step_num"] += 1
        start_time = time.time()

        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        reference_list = state.get("reference_list", [])
        ref_counter = state.get("ref_counter", 1)

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="å‚è€ƒæ–‡çŒ®å¤„ç†",
            content=f"\nå¼€å§‹å¤„ç†~~"
        ))

        # å¤„ç†ArXivè®ºæ–‡
        for paper in arxiv_papers:
            if "error" not in paper:
                # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
                paper_title = paper.get('title', 'Unknown')
                existing_ref = next((ref for ref in reference_list if ref.get('title') == paper_title), None)

                if not existing_ref:
                    reference_list.append({
                        "id": ref_counter,
                        "type": "ArXiv",
                        "title": paper_title,
                        "authors": paper.get('authors', []),
                        "published": paper.get('published', 'Unknown'),
                        "arxiv_id": paper.get('arxiv_id', ''),
                        "categories": paper.get('categories', []),
                        "summary": paper.get('detailed_summary', paper.get('summary', ''))  # ä¼˜å…ˆä½¿ç”¨è¯¦ç»†æ‘˜è¦
                    })
                    ref_counter += 1

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content=f"\nâœ… æˆåŠŸå¤„ç†Arxivè®ºæ–‡ï¼Œå…± {len(arxiv_papers)} ç¯‡",
        ))

        # å¤„ç†ç½‘ç»œæœç´¢ç»“æœå’ŒCrossRefç»“æœ
        for result in web_results:
            if "error" not in result:
                result_title = result.get('title', result.get('url', 'Unknown'))
                existing_ref = next((ref for ref in reference_list if ref.get('title') == result_title), None)

                if not existing_ref:
                    # åŒºåˆ†CrossRefå’Œæ™®é€šWebç»“æœ
                    if result.get('doi'):  # CrossRefç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "CrossRef",
                            "title": result_title,
                            "authors": result.get('authors', []),
                            "doi": result.get('doi', ''),
                            "journal": result.get('journal', ''),
                            "published": result.get('published', ''),
                            "url": result.get('url', '')
                        })
                    else:  # æ™®é€šWebç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "Web",
                            "title": result_title,
                            "url": result.get('url', ''),
                            "content_preview": result.get('content', result.get('snippet', 'No content'))[:200]
                        })
                    ref_counter += 1

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content=f"\nâœ… æˆåŠŸå¤„ç†ç½‘ç»œç»“æœå’ŒCrossRefè®ºæ–‡ï¼Œå…± {len(web_results)} ç¯‡",
        ))

        state["reference_list"] = reference_list
        state["ref_counter"] = ref_counter

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return state

    def get_literature_summary_with_refs(self, state: ProposalState) -> str:
        """è·å–å¸¦æœ‰ç»Ÿä¸€ç¼–å·çš„æ–‡çŒ®æ‘˜è¦"""
        state["global_step_num"] += 1
        start_time = time.time()

        reference_list = state.get("reference_list", [])
        literature_summary = ""

        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        arxiv_refs = [ref for ref in reference_list if ref.get("type") == "ArXiv"]
        web_refs = [ref for ref in reference_list if ref.get("type") == "Web"]

        if arxiv_refs:
            literature_summary += "\n\n**ç›¸å…³Arxivè®ºæ–‡ï¼š**\n"
            for ref in arxiv_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   ä½œè€…: {', '.join(ref['authors'])}\n"
                literature_summary += f"   å‘è¡¨æ—¶é—´: {ref['published']}\n"
                literature_summary += f"   æ‘˜è¦: {ref['summary']}\n"
                literature_summary += f"   åˆ†ç±»: {', '.join(ref['categories'])}\n\n"
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="å¼•ç”¨ç¼–å·å¤„ç†",
                content=f"\nâœ… æˆåŠŸç”ŸæˆArxivè®ºæ–‡å¼•ç”¨ç¼–å·ï¼Œå…± {len(arxiv_refs)} ç¯‡",
            ))

        if web_refs:
            literature_summary += "\n**ç›¸å…³ç½‘ç»œä¿¡æ¯ï¼š**\n"
            for ref in web_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   æ¥æº: {ref['url']}\n"
                literature_summary += f"   å†…å®¹æ‘˜è¦: {ref['content_preview']}...\n\n"

            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content=f"\nâœ… æˆåŠŸç”Ÿæˆç½‘ç»œèµ„æºå’ŒCrossRefè®ºæ–‡å¼•ç”¨ç¼–å·ï¼Œå…± {len(web_refs)} ç¯‡",
            ))

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return literature_summary

    def generate_reference_section(self, state: ProposalState) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        state["global_step_num"] += 1
        start_time = time.time()

        reference_list = state.get("reference_list", [])

        if not reference_list:
            return ""

        ref_text = "\n\n## å‚è€ƒæ–‡çŒ®\n\n"

        for ref in reference_list:
            if ref["type"] == "ArXiv":
                # ArXivè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                categories_str = ", ".join(ref["categories"]) if ref["categories"] else ""
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. arXiv:{ref['arxiv_id']} ({ref['published']})"
                if categories_str:
                    ref_text += f". Categories: {categories_str}"
                ref_text += "\n\n"
            elif ref["type"] == "CrossRef":
                # CrossRefè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. {ref['journal']} ({ref['published']}). DOI: {ref['doi']}\n\n"
            elif ref["type"] == "Web":
                # ç½‘ç»œèµ„æºæ ¼å¼
                ref_text += f"[{ref['id']}] {ref['title']}. è®¿é—®æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}. URL: {ref['url']}\n\n"

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="æ ¼å¼åŒ–æ–‡çŒ®",
            content=f"\nâœ… æˆåŠŸç”Ÿæˆæ ¼å¼åŒ–æ ¼å¼åŒ–åçš„å‚è€ƒæ–‡çŒ®ï¼Œå…± {len(reference_list)} ç¯‡",
        ))
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return ref_text

    def write_introduction_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„å¼•è¨€éƒ¨åˆ†"""

        research_field = state["research_field"]
        research_plan = state["research_plan"]
        revision_guidance = state.get("revision_guidance", "")  # è·å–ä¿®è®¢æŒ‡å¯¼

        rank_reference_list = self.rerank_with_llm(state)
        # å…ˆè¿›è¡Œé‡æ’åºï¼Œä½†ä¸é‡æ–°åˆ†é…ID
        # rank_reference_list = self.rerank_with_llm(state["research_field"], state["refe)
        # é‡æ’åºåé‡æ–°åˆ†é…ç»Ÿä¸€çš„ID
        for i, ref in enumerate(rank_reference_list, 1):
            ref["id"] = i

        state["reference_list"] = rank_reference_list
        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)

        state["global_step_num"] += 1
        start_time = time.time()

        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›[1]ï¼Œç‰¹åˆ«æ˜¯åœ¨å½±åƒè¯†åˆ«é¢†åŸŸ[2]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2] çš„æ ¼å¼
        6. ä½ æ‰€å¼•ç”¨çš„å†…å®¹å¿…é¡»çœŸå®æ¥è‡ªæ–‡çŒ®åˆ—è¡¨
        """
        # æ„å»ºæç¤ºï¼Œå¦‚æœæœ‰ä¿®è®¢æŒ‡å¯¼åˆ™åŒ…å«
        revision_instruction = ""
        if revision_guidance:
            revision_instruction = f"""
        
        **ä¿®è®¢æŒ‡å¯¼ï¼ˆè¯·ç‰¹åˆ«æ³¨æ„ï¼‰ï¼š**
        {revision_guidance}
        
        è¯·æ ¹æ®ä¸Šè¿°ä¿®è®¢æŒ‡å¯¼å¯¹å¼•è¨€éƒ¨åˆ†è¿›è¡Œé’ˆå¯¹æ€§æ”¹è¿›ã€‚
        """

        # ä½¿ç”¨prompts.pyä¸­çš„instruction
        introduction_prompt = f"""
        {proposal_introduction_instruction}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        {citation_instruction}
        
        **çœŸå®çš„æ–‡çŒ®åˆ—è¡¨**
        {state["reference_list"]}
        
        {revision_instruction}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„å¼•è¨€éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘600å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜ä»‹ç»ã€é‡è¦æ€§è¯´æ˜ã€ç ”ç©¶ç©ºç™½åˆ°ç ”ç©¶é—®é¢˜çš„æ¨å¯¼
        4. é€‚å½“å¼•ç”¨å·²æ”¶é›†çš„æ–‡çŒ®ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        5. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        6. **ä¸è¦åœ¨å¼•è¨€éƒ¨åˆ†åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨**ï¼Œåªåœ¨æ­£æ–‡ä¸­ä½¿ç”¨å¼•ç”¨æ ‡è®°
        7. ä½¿ç”¨`# å¼•è¨€`ä½œä¸ºå¼€å¤´
        """

        logging.info("ğŸ“ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦å¼•è¨€éƒ¨åˆ†...")
        full_content = StreamUtil.transfer_stream_answer_mes(
            stream_res=self.llm.stream([HumanMessage(introduction_prompt)]),
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="ç”Ÿæˆå¼•è¨€"
        )
        # åªä¿å­˜å¼•è¨€æ­£æ–‡ï¼Œä¸åŒ…å«å‚è€ƒæ–‡çŒ®
        state["introduction"] = full_content
        logging.info("âœ… å¼•è¨€éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return state

    def write_literature_review_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)

        state["global_step_num"] += 1
        start_time = time.time()
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶ã€ç†è®ºæˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•[1,2]ï¼Œä½†åœ¨å¯è§£é‡Šæ€§æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜[3]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2,3] çš„æ ¼å¼
        6. åœ¨è®ºè¿°ä¸åŒè§‚ç‚¹æˆ–ç ”ç©¶å‘ç°æ—¶ï¼Œè¦æ˜ç¡®æ ‡æ³¨æ¥æº
        7. å¯¹äºé‡è¦çš„ç†è®ºæ¡†æ¶æˆ–æ–¹æ³•è®ºï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        8. ä½ æ‰€å¼•ç”¨çš„å†…å®¹å¿…é¡»çœŸå®æ¥è‡ªæ–‡çŒ®åˆ—è¡¨
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å¼•è¨€éƒ¨åˆ†çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†é˜…è¯»å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼Œç†è§£å…¶ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜å’Œè¯†åˆ«çš„ç ”ç©¶ç©ºç™½
        2. æ–‡çŒ®ç»¼è¿°åº”è¯¥æ·±åŒ–å’Œæ‹“å±•å¼•è¨€ä¸­ç®€è¦æåŠçš„ç ”ç©¶é¢†åŸŸ
        3. é¿å…é‡å¤å¼•è¨€ä¸­å·²ç»è¯¦ç»†é˜è¿°çš„èƒŒæ™¯ä¿¡æ¯
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°ç ”ç©¶é—®é¢˜"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„..."ç­‰
        5. ç¡®ä¿æ–‡çŒ®ç»¼è¿°çš„ç»“è®ºè‡ªç„¶è¿‡æ¸¡åˆ°å¯¹æ‹Ÿè®®ç ”ç©¶çš„å¿…è¦æ€§è®ºè¯
        6. å¯¹å¼•è¨€ä¸­æåŠçš„å…³é”®æ¦‚å¿µå’Œç†è®ºè¿›è¡Œæ›´æ·±å…¥çš„æ–‡çŒ®åˆ†æ
        """

        # ä½¿ç”¨prompts.pyä¸­çš„LITERATURE_REVIEW_PROMPT
        literature_review_prompt = f"""
        {LITERATURE_REVIEW_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        **çœŸå®çš„æ–‡çŒ®åˆ—è¡¨**
        {state["reference_list"]}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘800å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒæŒ‰ä¸»é¢˜ç»„ç»‡æ–‡çŒ®ï¼Œä¸è¦é€ç¯‡è®ºæ–‡ä»‹ç»
        4. é‡ç‚¹å…³æ³¨ç ”ç©¶è¶‹åŠ¿ã€ä¸»è¦è§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•å’Œå­˜åœ¨çš„äº‰è®®
        5. è¯†åˆ«ç ”ç©¶ç©ºç™½å’Œä¸è¶³ï¼Œä¸ºåç»­ç ”ç©¶æä¾›ä¾æ®
        6. å¿…é¡»åŒ…å«é€‚å½“çš„æ–‡çŒ®å¼•ç”¨ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        7. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        8. é¿å…ç®€å•ç½—åˆ—ï¼Œè¦è¿›è¡Œåˆ†æå’Œç»¼åˆ
        9. **ä¸å¼•è¨€éƒ¨åˆ†ä¿æŒè¿è´¯æ€§**ï¼Œé¿å…é‡å¤å†…å®¹ï¼Œæ·±åŒ–å¼•è¨€ä¸­çš„ç ”ç©¶é—®é¢˜
        10. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€è¿æ¥å¼•è¨€éƒ¨åˆ†çš„å†…å®¹
        """

        logging.info("ğŸ“š æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†...")
        full_content = StreamUtil.transfer_stream_answer_mes(
            stream_res=self.llm.stream([HumanMessage(literature_review_prompt)]),
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="ç”Ÿæˆç»¼è¿°"
        )
        # æ³¨æ„ï¼šæ–‡çŒ®ç»¼è¿°ä¸é‡å¤æ·»åŠ å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œå› ä¸ºå¼•è¨€å·²ç»åŒ…å«äº†å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        state["literature_review"] = full_content
        logging.info("âœ… æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return state

    def write_research_design_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state)

        state["global_step_num"] += 1
        start_time = time.time()
        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æ–¹æ³•ã€ç†è®ºæ¡†æ¶æˆ–æŠ€æœ¯æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæœ¬ç ”ç©¶å°†é‡‡ç”¨æ··åˆæ–¹æ³•ç ”ç©¶è®¾è®¡[5]ï¼Œç»“åˆå®šé‡åˆ†æå’Œå®šæ€§è®¿è°ˆ[8,12]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨å·²æä¾›çš„æ–‡çŒ®
        5. åœ¨æè¿°æ–¹æ³•è®ºä¾æ®æ—¶è¦æ˜ç¡®æ ‡æ³¨æ¥æº
        6. å¯¹äºé‡è¦çš„åˆ†æå·¥å…·å’ŒæŠ€æœ¯æ¡†æ¶ï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        7. ä½ æ‰€å¼•ç”¨çš„å†…å®¹å¿…é¡»çœŸå®æ¥è‡ªæ–‡çŒ®åˆ—è¡¨
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å‰æ–‡çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†åˆ†æå¼•è¨€éƒ¨åˆ†æå‡ºçš„å…·ä½“ç ”ç©¶é—®é¢˜ï¼Œç¡®ä¿ç ”ç©¶è®¾è®¡èƒ½å¤Ÿå›ç­”è¿™äº›é—®é¢˜
        2. åŸºäºæ–‡çŒ®ç»¼è¿°ä¸­è¯†åˆ«çš„æ–¹æ³•è®ºè¶‹åŠ¿å’Œç ”ç©¶ç©ºç™½ï¼Œé€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•
        3. æ‰¿æ¥æ–‡çŒ®ç»¼è¿°ä¸­æåˆ°çš„ç†è®ºæ¡†æ¶å’Œåˆ†ææ–¹æ³•ï¼Œè¯´æ˜å¦‚ä½•åœ¨æœ¬ç ”ç©¶ä¸­åº”ç”¨æˆ–æ”¹è¿›
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°æ–‡çŒ®åˆ†æ"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜"ã€"å€Ÿé‰´æ–‡çŒ®ç»¼è¿°ä¸­çš„..."ç­‰
        5. ç¡®ä¿ç ”ç©¶è®¾è®¡çš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½ä¸å‰æ–‡å»ºç«‹çš„ç ”ç©¶èƒŒæ™¯å’Œç†è®ºåŸºç¡€ç›¸å‘¼åº”
        6. æ˜ç¡®è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©çš„æ–¹æ³•é€‚åˆè§£å†³å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜
        """

        # ä½¿ç”¨prompts.pyä¸­çš„PROJECT_DESIGN_PROMPT
        research_design_prompt = f"""
        {PROJECT_DESIGN_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’æ¦‚è¦ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ï¼š**
        {literature_review_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼ˆç”¨äºå¯èƒ½çš„å¼•ç”¨ï¼‰ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        **çœŸå®çš„æ–‡çŒ®åˆ—è¡¨**
        {state["reference_list"]}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†ã€‚
        é‡ç‚¹å…³æ³¨ç ”ç©¶æ•°æ®ã€æ–¹æ³•ã€å·¥ä½œæµç¨‹å’Œå±€é™æ€§ã€‚
        å¿…é¡»**ä½¿ç”¨ä¸­æ–‡æ’°å†™**
        **ä¸è¦åŒ…å«æ—¶é—´å®‰æ’æˆ–é¢„æœŸæˆæœæ€»ç»“ï¼Œè¿™äº›å°†åœ¨ç»“è®ºéƒ¨åˆ†ç»Ÿä¸€é˜è¿°ã€‚**
        """

        logging.info("ğŸ”¬ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç ”ç©¶è®¾è®¡éƒ¨åˆ†...")
        try:
            full_content = StreamUtil.transfer_stream_answer_mes(
                stream_res=self.llm.stream([HumanMessage(research_design_prompt)]),
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="ç”Ÿæˆç ”ç©¶"
            )
            state["research_design"] = full_content
            logging.info("âœ… ç ”ç©¶è®¾è®¡éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
            logging.info(f"ç ”ç©¶è®¾è®¡å†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
        except Exception as e:
            logging.error(f"âŒ ç ”ç©¶è®¾è®¡ç”Ÿæˆå¤±è´¥: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            state["research_design"] = f"ç ”ç©¶è®¾è®¡ç”Ÿæˆå¤±è´¥: {str(e)}"

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œç¡®è®¤æ–¹æ³•å®Œæˆå¹¶å‡†å¤‡è¿›å…¥ä¸‹ä¸€èŠ‚ç‚¹
        logging.info("ğŸ”„ write_research_design_node å®Œæˆï¼Œå‡†å¤‡è¿›å…¥ write_conclusion_node")
        return state

    def write_conclusion_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç»“è®ºéƒ¨åˆ†"""
        logging.info("ğŸ”„ è¿›å…¥ write_conclusion_node")
        state["global_step_num"] += 1
        start_time = time.time()

        research_field = state["research_field"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")
        research_design_content = state.get("research_design", "")

        # ä¸ºç»“è®ºéƒ¨åˆ†ä¹Ÿæ·»åŠ æ–‡çŒ®å¼•ç”¨èƒ½åŠ›
        literature_summary = self.get_literature_summary_with_refs(state)
        
        # ç»“è®ºéƒ¨åˆ†çš„å¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼ˆç»“è®ºéƒ¨åˆ†ï¼‰ï¼š**
        1. åœ¨æ€»ç»“ç ”ç©¶æ„ä¹‰æˆ–é¢„æœŸè´¡çŒ®æ—¶ï¼Œå¯ä»¥é€‚å½“å¼•ç”¨ç›¸å…³æ–‡çŒ®æ¥æ”¯æ’‘è§‚ç‚¹
        2. å¼•ç”¨æ ‡è®°å¯¹åº”æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        3. ä¾‹å¦‚ï¼šæœ¬ç ”ç©¶çš„é¢„æœŸæˆæœå°†ä¸ºè¯¥é¢†åŸŸæä¾›æ–°çš„ç†è®ºæ¡†æ¶[1,3]ï¼Œå¹¶æœ‰æœ›åœ¨å®é™…åº”ç”¨ä¸­äº§ç”Ÿé‡è¦å½±å“[5]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨å·²æä¾›çš„æ–‡çŒ®
        5. ä½ æ‰€å¼•ç”¨çš„å†…å®¹å¿…é¡»çœŸå®æ¥è‡ªæ–‡çŒ®åˆ—è¡¨
        """

        conclusion_prompt_text = f"""
        {CONCLUSION_PROMPT.format(research_field=research_field)}

        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}

        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç ”ç©¶é—®é¢˜å’ŒèƒŒæ™¯ï¼‰ï¼š**
        {introduction_content[:1000]}... 

        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç†è®ºæ¡†æ¶ï¼‰ï¼š**
        {literature_review_content[:1000]}...

        **å·²å®Œæˆçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾æ–¹æ³•å’Œæµç¨‹ï¼‰ï¼š**
        {research_design_content[:1000]}...
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼ˆç”¨äºå¯èƒ½çš„å¼•ç”¨ï¼‰ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        **çœŸå®çš„æ–‡çŒ®åˆ—è¡¨**
        {state["reference_list"]}

        è¯·åŸºäºä»¥ä¸Šæä¾›çš„å¼•è¨€ã€æ–‡çŒ®ç»¼è¿°å’Œç ”ç©¶è®¾è®¡å†…å®¹ï¼Œæ’°å†™ä¸€ä¸ªè¿è´¯çš„ç»“è®ºéƒ¨åˆ†ã€‚
        ç»“è®ºåº”åŒ…å«æ—¶é—´è½´ã€é¢„æœŸæˆæœå’Œæœ€ç»ˆæ€»ç»“ã€‚
        ç¡®ä¿ç»“è®ºä¸å‰é¢ç« èŠ‚æå‡ºçš„ç ”ç©¶é—®é¢˜ã€æ–¹æ³•è®ºå’Œç›®æ ‡ä¿æŒä¸€è‡´ã€‚
        å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**æ’°å†™
        """

        logging.info("ğŸ“œ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç»“è®ºéƒ¨åˆ†...")
        try:
            full_content = StreamUtil.transfer_stream_answer_mes(
                stream_res=self.llm.stream([HumanMessage(conclusion_prompt_text)]),
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="ç”Ÿæˆç»“è®º"
            )
            state["conclusion"] = full_content
            logging.info("âœ… ç»“è®ºéƒ¨åˆ†ç”Ÿæˆå®Œæˆ")
            logging.info(f"ç»“è®ºå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
        except Exception as e:
            logging.error(f"âŒ ç»“è®ºéƒ¨åˆ†ç”Ÿæˆå¤±è´¥: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            state["conclusion"] = f"ç»“è®ºéƒ¨åˆ†ç”Ÿæˆå¤±è´¥: {str(e)}"
            # å³ä½¿ç»“è®ºç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿç»§ç»­åç»­æµç¨‹
            full_content = state["conclusion"]

        # ç”Ÿæˆç”˜ç‰¹å›¾
        logging.info("ğŸ“Š æ­£åœ¨ç”Ÿæˆé¡¹ç›®ç”˜ç‰¹å›¾...")
        logging.info(f"ä¼ å…¥ç”˜ç‰¹å›¾å·¥å…·çš„ç ”ç©¶é¢†åŸŸ: {research_field}")
        logging.info(f"ä¼ å…¥ç”˜ç‰¹å›¾å·¥å…·çš„ç»“è®ºå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
        
        # åˆå§‹åŒ–ç”˜ç‰¹å›¾å­—æ®µï¼Œç¡®ä¿çŠ¶æ€ä¸­å­˜åœ¨
        if "gantt_chart" not in state:
            state["gantt_chart"] = ""
            logging.info("ğŸ”§ åˆå§‹åŒ–ç”˜ç‰¹å›¾å­—æ®µ")
        
        try:
            gantt_result = generate_gantt_chart_tool.invoke({
                "timeline_content": full_content,
                "research_field": research_field
            })
            
            logging.info(f"ç”˜ç‰¹å›¾å·¥å…·è¿”å›çŠ¶æ€: {gantt_result.get('status')}")
            logging.info(f"ç”˜ç‰¹å›¾å·¥å…·è¿”å›æ¶ˆæ¯: {gantt_result.get('message')}")
            
            if gantt_result.get("status") == "success":
                gantt_chart_content = gantt_result.get("gantt_chart", "")
                # å¼ºåˆ¶è®¾ç½®ç”˜ç‰¹å›¾å†…å®¹å¹¶éªŒè¯
                state["gantt_chart"] = gantt_chart_content
                
                # ç«‹å³éªŒè¯è®¾ç½®æ˜¯å¦æˆåŠŸ
                verification_content = state.get("gantt_chart", "")
                logging.info(f"âœ… ç”˜ç‰¹å›¾è®¾ç½®å®Œæˆï¼ŒéªŒè¯é•¿åº¦: {len(verification_content)} å­—ç¬¦")
                
                if gantt_chart_content and len(gantt_chart_content) > 0:
                    logging.info(f"ç”˜ç‰¹å›¾å†…å®¹é¢„è§ˆ: {gantt_chart_content[:200]}...")
                    QueueUtil.push_mes(StreamMes(state["proposal_id"], 7, "\nâœ… é¡¹ç›®ç”˜ç‰¹å›¾ç”Ÿæˆå®Œæˆ"))
                else:
                    logging.warning("âš ï¸ ç”˜ç‰¹å›¾ç”ŸæˆæˆåŠŸä½†å†…å®¹ä¸ºç©º")
                    QueueUtil.push_mes(StreamMes(state["proposal_id"], 7, "\nâš ï¸ ç”˜ç‰¹å›¾ç”ŸæˆæˆåŠŸä½†å†…å®¹ä¸ºç©º"))
            else:
                state["gantt_chart"] = ""
                error_msg = gantt_result.get('message', 'æœªçŸ¥é”™è¯¯')
                logging.warning(f"âš ï¸ ç”˜ç‰¹å›¾ç”Ÿæˆå¤±è´¥: {error_msg}")
                QueueUtil.push_mes(StreamMes(state["proposal_id"], 7, f"\nâš ï¸ ç”˜ç‰¹å›¾ç”Ÿæˆå¤±è´¥: {error_msg}"))
                
        except Exception as e:
            state["gantt_chart"] = ""
            logging.error(f"âŒ ç”˜ç‰¹å›¾ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            QueueUtil.push_mes(StreamMes(state["proposal_id"], 7, f"\nâŒ ç”˜ç‰¹å›¾ç”Ÿæˆå¼‚å¸¸: {str(e)}"))

        # æœ€ç»ˆéªŒè¯å¹¶ç¡®ä¿çŠ¶æ€ä¼ é€’
        final_gantt_chart = state.get("gantt_chart", "")
        logging.info(f"ç»“è®ºèŠ‚ç‚¹ç»“æŸæ—¶ï¼Œstateä¸­çš„gantt_charté•¿åº¦: {len(final_gantt_chart)} å­—ç¬¦")
        
        # å¼ºåˆ¶ç¡®ä¿ç”˜ç‰¹å›¾åœ¨çŠ¶æ€ä¸­ä¸ä¼šä¸¢å¤±
        if final_gantt_chart and len(final_gantt_chart) > 0:
            logging.info(f"stateä¸­çš„gantt_chartå†…å®¹é¢„è§ˆ: {final_gantt_chart[:200]}...")
            # é¢å¤–ä¿æŠ¤ï¼šå°†ç”˜ç‰¹å›¾ä¹Ÿå­˜å‚¨åœ¨å¦ä¸€ä¸ªå­—æ®µä½œä¸ºå¤‡ä»½
            state["gantt_chart_backup"] = final_gantt_chart
            logging.info("ğŸ”’ å·²åˆ›å»ºç”˜ç‰¹å›¾å¤‡ä»½")
        else:
            logging.warning("âš ï¸ stateä¸­çš„gantt_chartä¸ºç©º")
            state["gantt_chart"] = ""
            state["gantt_chart_backup"] = ""

        return state

    def generate_final_references_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""

        reference_section = self.generate_reference_section(state)

        # å°†å‚è€ƒæ–‡çŒ®ä½œä¸ºç‹¬ç«‹éƒ¨åˆ†ä¿å­˜
        state["final_references"] = reference_section
        logging.info("âœ… å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        # æ£€æŸ¥å¹¶æ¢å¤ç”˜ç‰¹å›¾çŠ¶æ€
        gantt_chart = state.get("gantt_chart", "")
        gantt_backup = state.get("gantt_chart_backup", "")
        
        logging.info(f"å‚è€ƒæ–‡çŒ®èŠ‚ç‚¹ä¸­çš„ç”˜ç‰¹å›¾é•¿åº¦: {len(gantt_chart)} å­—ç¬¦")
        logging.info(f"å‚è€ƒæ–‡çŒ®èŠ‚ç‚¹ä¸­çš„ç”˜ç‰¹å›¾å¤‡ä»½é•¿åº¦: {len(gantt_backup)} å­—ç¬¦")
        
        # å¦‚æœä¸»ç”˜ç‰¹å›¾ä¸¢å¤±ä½†å¤‡ä»½å­˜åœ¨ï¼Œåˆ™æ¢å¤
        if not gantt_chart and gantt_backup:
            state["gantt_chart"] = gantt_backup
            logging.warning("âš ï¸ ä¸»ç”˜ç‰¹å›¾ä¸¢å¤±ï¼Œå·²ä»å¤‡ä»½æ¢å¤")
            gantt_chart = gantt_backup
        
        if gantt_chart:
            logging.info(f"å‚è€ƒæ–‡çŒ®èŠ‚ç‚¹ä¸­çš„ç”˜ç‰¹å›¾é¢„è§ˆ: {gantt_chart[:200]}...")
        else:
            logging.warning("âš ï¸ å‚è€ƒæ–‡çŒ®èŠ‚ç‚¹ä¸­ç”˜ç‰¹å›¾ä¸ºç©º")

        return state

    def generate_final_report_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„Markdownç ”ç©¶è®¡åˆ’ä¹¦æŠ¥å‘Š"""
        logging.info("ğŸ“„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆçš„ç ”ç©¶è®¡åˆ’ä¹¦MarkdownæŠ¥å‘Š...")

        research_field = state.get("research_field", "æœªçŸ¥é¢†åŸŸ")
        introduction = state.get("introduction", "æ— å¼•è¨€å†…å®¹")
        literature_review = state.get("literature_review", "æ— æ–‡çŒ®ç»¼è¿°å†…å®¹")
        research_design = state.get("research_design", "æ— ç ”ç©¶è®¾è®¡å†…å®¹")
        conclusion = state.get("conclusion", "æ— ç»“è®ºå†…å®¹")
        final_references = state.get("final_references", "æ— å‚è€ƒæ–‡çŒ®")
        gantt_chart = state.get("gantt_chart", "")  # è·å–ç”˜ç‰¹å›¾

        # æ£€æŸ¥å¹¶æ¢å¤ç”˜ç‰¹å›¾ - ä½¿ç”¨å¤šé‡æ£€æŸ¥å’Œæ¢å¤æœºåˆ¶
        gantt_chart = state.get("gantt_chart", "")
        gantt_backup = state.get("gantt_chart_backup", "")
        
        # å¢å¼ºè°ƒè¯•ä¿¡æ¯
        logging.info(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šæ—¶ï¼Œè·å–åˆ°çš„gantt_charté•¿åº¦: {len(gantt_chart)} å­—ç¬¦")
        logging.info(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šæ—¶ï¼Œè·å–åˆ°çš„gantt_chart_backupé•¿åº¦: {len(gantt_backup)} å­—ç¬¦")
        
        # å°è¯•ä»å¤‡ä»½æ¢å¤ç”˜ç‰¹å›¾
        if not gantt_chart and gantt_backup:
            gantt_chart = gantt_backup
            state["gantt_chart"] = gantt_backup
            logging.warning("âš ï¸ æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆæ—¶ä¸»ç”˜ç‰¹å›¾ä¸ºç©ºï¼Œå·²ä»å¤‡ä»½æ¢å¤")

        # åˆ›å»ºoutputæ–‡ä»¶å¤¹
        output_dir = Path(__file__).parent.parent.parent.parent / "output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ç”¨uuidæ›¿æ¢æ—¶é—´æˆ³
        proposal_id = state["proposal_id"]
        report_filename = f"Research_Proposal_{proposal_id}.md"
        references_filename = f"References_{proposal_id}.json"
        report_filepath = os.path.join(output_dir, report_filename)
        references_filepath = os.path.join(output_dir, references_filename)        # æ„å»ºMarkdownå†…å®¹ï¼Œå¦‚æœæ˜¯æ”¹è¿›ç‰ˆæœ¬åˆ™æ·»åŠ æ ‡è¯†
        revision_guidance = state.get("revision_guidance", "")
        improvement_attempt = state.get("improvement_attempt", 0)
        
        if revision_guidance and improvement_attempt > 0:
            report_content = f"# ç ”ç©¶è®¡åˆ’ä¹¦ï¼š{research_field}ï¼ˆæ”¹è¿›ç‰ˆ v{improvement_attempt}ï¼‰\n\n"
            report_content += "## æ”¹è¿›è¯´æ˜\n\n"
            report_content += f"æœ¬ç‰ˆæœ¬åŸºäºè¯„å®¡æ„è§è¿›è¡Œäº†é’ˆå¯¹æ€§æ”¹è¿›ï¼Œæ”¹è¿›è½®æ¬¡ï¼šç¬¬{improvement_attempt}è½®\n\n"
        else:
            report_content = f"# ç ”ç©¶è®¡åˆ’ä¹¦ï¼š{research_field}\n\n"

        # report_content += "## 1. å¼•è¨€\n\n"
        report_content += f"{introduction}\n\n"
        report_content += f"{literature_review}\n\n"
        report_content += f"{research_design}\n\n"
        report_content += f"{conclusion}\n\n"

        # æ·»åŠ ç”˜ç‰¹å›¾éƒ¨åˆ† - ä½¿ç”¨æ¢å¤åçš„ç”˜ç‰¹å›¾
        final_gantt_chart = gantt_chart if gantt_chart else gantt_backup
        if final_gantt_chart and final_gantt_chart.strip():
            report_content += "## é¡¹ç›®æ—¶é—´è§„åˆ’ç”˜ç‰¹å›¾\n\n"
            report_content += f"```mermaid\n{final_gantt_chart}\n```\n\n"
            logging.info("âœ… ç”˜ç‰¹å›¾å·²æ·»åŠ åˆ°æœ€ç»ˆæŠ¥å‘Š")
        else:
            logging.warning("âš ï¸ ç”˜ç‰¹å›¾ä¸ºç©ºæˆ–æ— æ•ˆï¼Œæœªæ·»åŠ åˆ°æŠ¥å‘Šä¸­")

        report_content += f"{final_references}\n\n"  # å‚è€ƒæ–‡çŒ®éƒ¨åˆ†è‡ªå¸¦ "## å‚è€ƒæ–‡çŒ®" æ ‡é¢˜

        state["global_step_num"] += 1
        start_time = time.time()

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š",
            content="\næ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”ç©¶è®¡åˆ’æŠ¥å‘Š~~",
        ))
        try:
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
            logging.info(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")

            # ä¿å­˜å‚è€ƒæ–‡çŒ®åˆ—è¡¨ä¸ºJSONæ–‡ä»¶
            try:
                with open(references_filepath, 'w', encoding='utf-8') as ref_file:
                    json.dump(state["reference_list"], ref_file, ensure_ascii=False, indent=2)
                logging.info(f"âœ… å‚è€ƒæ–‡çŒ®åˆ—è¡¨å·²ä¿å­˜åˆ°: {references_filepath}")
            except Exception as ref_e:
                logging.error(f"âŒ ä¿å­˜å‚è€ƒæ–‡çŒ®åˆ—è¡¨å¤±è´¥: {ref_e}")

            state["final_report_markdown"] = report_content
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time)
            ))
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜æœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            state["final_report_markdown"] = "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content="\n\nâŒ å¤„ç†å¤±è´¥ï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time)
            ))

        return state

    def review_proposal_node(self, state: ProposalState) -> ProposalState:
        """å¯¹ç”Ÿæˆçš„ç ”ç©¶è®¡åˆ’ä¹¦è¿›è¡Œè¯„å®¡"""
        state["global_step_num"] += 1
        start_time = time.time()
        
        # æå–éœ€è¦è¯„å®¡çš„å†…å®¹
        report_content = state.get("final_report_markdown", "")
        if not report_content or report_content == "æŠ¥å‘Šç”Ÿæˆå¤±è´¥":
            logging.warning("âš ï¸ æ²¡æœ‰å¯è¯„å®¡çš„å†…å®¹ï¼Œè·³è¿‡è¯„å®¡æ­¥éª¤")
            state["review_result"] = {"success": False, "error": "æ²¡æœ‰å¯è¯„å®¡çš„å†…å®¹"}
            return state
        
        research_field = state.get("research_field", "")
        
        logging.info("ğŸ” å¼€å§‹è¯„å®¡ç ”ç©¶è®¡åˆ’ä¹¦...")
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="è¯„å®¡è®¡åˆ’ä¹¦",
            content="\næ­£åœ¨è¯„å®¡ç ”ç©¶è®¡åˆ’ä¹¦..."
        ))
        
        # åˆå§‹åŒ–ReviewerAgentå¹¶è¿›è¡Œè¯„å®¡
        try:
            from src.reviewer.reviewer import ReviewerAgent
            reviewer = ReviewerAgent()
            review_result = reviewer.review_proposal(report_content, research_field)
            
            if review_result.get("success"):
                # è¯„å®¡æˆåŠŸï¼Œä¿å­˜è¯„å®¡ç»“æœ
                state["review_result"] = review_result
                logging.info(f"ğŸ” è¯„å®¡æˆåŠŸï¼Œæ­£åœ¨ä¿å­˜è¯„å®¡ç»“æœåˆ°çŠ¶æ€ä¸­...")
                logging.info(f"ğŸ” ä¿å­˜çš„review_result keys: {list(review_result.keys())}")
                
                scores = review_result.get("llm_scores", {})
                overall_score = scores.get("æ€»ä½“è¯„åˆ†", 0)
                logging.info(f"ğŸ” ä»review_resultä¸­æå–çš„æ€»ä½“è¯„åˆ†: {overall_score}")
                
                score_message = f"\nâœ… è¯„å®¡å®Œæˆï¼Œæ€»ä½“è¯„åˆ†ï¼š{overall_score}/10"
                for criterion, score in scores.items():
                    if criterion != "æ€»ä½“è¯„åˆ†":
                        score_message += f"\n- {criterion}: {score}/10"
                        
                QueueUtil.push_mes(StreamAnswerMes(
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="",
                    content=score_message
                ))
                
                # è®°å½•ä¸»è¦ä¼˜ç¼ºç‚¹
                strengths = review_result.get("strengths", [])
                weaknesses = review_result.get("weaknesses", [])
                
                if strengths:
                    strength_text = "\n\n**ä¸»è¦ä¼˜åŠ¿**:\n" + "\n".join([f"- {s}" for s in strengths[:3]])
                    QueueUtil.push_mes(StreamAnswerMes(
                        proposal_id=state["proposal_id"],
                        step=state["global_step_num"],
                        title="",
                        content=strength_text
                    ))
                    
                if weaknesses:
                    weakness_text = "\n\n**ä¸»è¦ä¸è¶³**:\n" + "\n".join([f"- {w}" for w in weaknesses[:3]])
                    QueueUtil.push_mes(StreamAnswerMes(
                        proposal_id=state["proposal_id"],
                        step=state["global_step_num"],
                        title="",
                        content=weakness_text
                    ))
                
                # ä¿å­˜è¯„å®¡ç»“æœåˆ°æ–‡ä»¶
                try:
                    # åˆ›å»ºreviewsç›®å½•
                    reviews_dir = Path(__file__).parent.parent.parent.parent / "output" / "reviews"
                    if not os.path.exists(reviews_dir):
                        os.makedirs(reviews_dir)
                    
                    # ç”Ÿæˆè¯„å®¡ç»“æœæ–‡ä»¶å
                    proposal_id = state["proposal_id"]
                    review_filename = f"Review_{proposal_id}.json"
                    review_filepath = os.path.join(reviews_dir, review_filename)
                    
                    # ä¿å­˜è¯„å®¡ç»“æœä¸ºJSONæ–‡ä»¶
                    with open(review_filepath, 'w', encoding='utf-8') as review_file:
                        json.dump(review_result, review_file, ensure_ascii=False, indent=2)
                    
                    logging.info(f"âœ… è¯„å®¡ç»“æœå·²ä¿å­˜åˆ°: {review_filepath}")
                    QueueUtil.push_mes(StreamAnswerMes(
                        proposal_id=state["proposal_id"],
                        step=state["global_step_num"],
                        title="",
                        content=f"\nğŸ“„ è¯„å®¡ç»“æœå·²ä¿å­˜åˆ°: {review_filepath}"
                    ))
                except Exception as save_e:
                    logging.error(f"âŒ ä¿å­˜è¯„å®¡ç»“æœå¤±è´¥: {save_e}")
                    QueueUtil.push_mes(StreamAnswerMes(
                        proposal_id=state["proposal_id"],
                        step=state["global_step_num"],
                        title="",
                        content=f"\nâš ï¸ è¯„å®¡ç»“æœä¿å­˜å¤±è´¥: {save_e}"
                    ))
            else:                # è¯„å®¡å¤±è´¥
                error_msg = review_result.get("error", "æœªçŸ¥é”™è¯¯")
                logging.error(f"âŒ è¯„å®¡å¤±è´¥: {error_msg}")
                state["review_result"] = review_result
                QueueUtil.push_mes(StreamAnswerMes(
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="",
                    content=f"\nâŒ è¯„å®¡å¤±è´¥: {error_msg}"
                ))
    
        except Exception as e:
            logging.error(f"âŒ è¯„å®¡è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            state["review_result"] = {"success": False, "error": str(e)}
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content=f"\nâŒ è¯„å®¡è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            ))
    
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time)
        ))
        
        # è°ƒè¯•ï¼šç¡®è®¤è¯„å®¡ç»“æœæ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°çŠ¶æ€ä¸­
        saved_review_result = state.get("review_result", {})
        logging.info(f"ğŸ” è¯„å®¡èŠ‚ç‚¹ç»“æŸæ—¶ï¼ŒçŠ¶æ€ä¸­çš„review_resultå­˜åœ¨: {saved_review_result.get('success', False)}")
        if saved_review_result.get("success"):
            saved_scores = saved_review_result.get("llm_scores", {})
            saved_overall = saved_scores.get("æ€»ä½“è¯„åˆ†", 0)
            logging.info(f"ğŸ” è¯„å®¡èŠ‚ç‚¹ç»“æŸæ—¶ï¼Œä¿å­˜çš„æ€»ä½“è¯„åˆ†: {saved_overall}")
        else:
            logging.warning("âš ï¸ è¯„å®¡èŠ‚ç‚¹ç»“æŸæ—¶ï¼ŒçŠ¶æ€ä¸­æ²¡æœ‰æœ‰æ•ˆçš„è¯„å®¡ç»“æœ")
        
        return state

    def should_continue(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–è¿›å…¥å†™ä½œé˜¶æ®µ"""

        # 1. é¦–å…ˆæ£€æŸ¥æ¾„æ¸…é—®é¢˜çŠ¶æ€ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        if state.get("clarification_questions") and not state.get("user_clarifications"):
            # å¦‚æœæœ‰æ¾„æ¸…é—®é¢˜ä½†ç”¨æˆ·æœªå›åº”ï¼Œç»§ç»­æ‰§è¡Œä½†å¯èƒ½æ•ˆæœä¸ä½³
            logging.info("â³ æ£€æµ‹åˆ°æœªå›åº”çš„æ¾„æ¸…é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œæµç¨‹")
            pass

        # 2. è·å–åŸºæœ¬çŠ¶æ€ä¿¡æ¯
        current_step_index = state.get("current_step", 0)
        execution_plan = state.get("execution_plan", [])
        execution_memory = state.get("execution_memory", [])
        max_iterations = state.get("max_iterations", 10)
        max_steps = len(execution_plan)

        # 3. æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆå®‰å…¨ä¸Šé™ï¼‰
        if len(execution_memory) >= max_iterations:
            logging.info(f"ğŸ›‘ è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ¬¡æ•° ({max_iterations})ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"

        # 4. æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¡åˆ’æ­¥éª¤éƒ½å·²å®Œæˆ
        if current_step_index >= max_steps:
            logging.info("âœ… æ‰€æœ‰è®¡åˆ’å†…æ­¥éª¤å·²æ‰§è¡Œå®Œæˆï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"

        # 5. æ¯æ‰§è¡Œ1æ­¥åè¿›è¡Œå†å²æ‘˜è¦ï¼ˆå¯é…ç½®ï¼‰
        summarize_interval = 1  # å¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼
        if current_step_index > 0 and current_step_index % summarize_interval == 0:
            logging.info(f"ğŸ“ æ‰§è¡Œäº† {current_step_index} æ­¥ï¼Œæ­£åœ¨ç”Ÿæˆå†å²æ‘˜è¦...")
            return "summarize"

        # 6. æ£€æŸ¥æ˜¯å¦æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ï¼ˆæå‰ç»“æŸæ¡ä»¶ï¼‰
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])

        if len(arxiv_papers) >= 5 and len(web_results) >= 5:
            logging.info(
                f"ğŸ“š å·²æ”¶é›†å……è¶³ä¿¡æ¯ ({len(arxiv_papers)} ç¯‡è®ºæ–‡, {len(web_results)} æ¡ç½‘ç»œç»“æœ)ï¼Œæå‰è¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"        # 7. æ£€æŸ¥æœ€è¿‘æ‰§è¡Œç»“æœè´¨é‡ï¼ˆæ™ºèƒ½é‡è§„åˆ’ï¼‰
        if len(execution_memory) >= 3:
            recent_results = execution_memory[-3:]
            successful_results = [r for r in recent_results if r.get("success", False)]

            # å¦‚æœæœ€è¿‘3æ­¥ä¸­æˆåŠŸç‡ä½äº30%ï¼Œè€ƒè™‘é‡æ–°è§„åˆ’
            if len(successful_results) < len(recent_results) * 0.3:
                logging.info("âš ï¸ æœ€è¿‘æ‰§è¡ŒæˆåŠŸç‡è¾ƒä½ï¼Œé‡æ–°è§„åˆ’...")
                state["current_step"] = 0  # é‡ç½®æ­¥æ•°è®¡æ•°å™¨
                return "plan_analysis"

        # 8. é»˜è®¤ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
        logging.info(f"ğŸš€ ç»§ç»­æ‰§è¡Œæ­¥éª¤ {current_step_index + 1}/{max_steps}")
        return "continue"

    def should_improve(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦éœ€è¦è¿›è¡Œæ”¹è¿›"""
    
        review_result = state.get("review_result", {})
        logging.info(f"ğŸ” should_improve: æ£€æŸ¥è¯„å®¡ç»“æœ")
        logging.info(f"review_resultç±»å‹: {type(review_result)}")
        logging.info(f"review_result keys: {list(review_result.keys()) if review_result else 'None'}")
        logging.info(f"å®Œæ•´çš„review_result: {review_result}")
        
        # è¯¦ç»†è®°å½•è·å–è¯„åˆ†çš„è¿‡ç¨‹
        llm_scores = review_result.get("llm_scores", {})
        logging.info(f"llm_scoresç±»å‹: {type(llm_scores)}")
        logging.info(f"llm_scores: {llm_scores}")
        
        overall_score = llm_scores.get("æ€»ä½“è¯„åˆ†", 0)
        logging.info(f"è·å–åˆ°çš„æ€»ä½“è¯„åˆ†: {overall_score} (ç±»å‹: {type(overall_score)})")
          # å¦‚æœæ— æ³•è·å–æœ‰æ•ˆçš„è¯„å®¡ç»“æœï¼Œå°è¯•ä»æ–‡ä»¶ä¸­è¯»å–
        if not review_result or not review_result.get("success", False):
            logging.warning("âš ï¸ çŠ¶æ€ä¸­æ— æ³•è·å–æœ‰æ•ˆçš„è¯„å®¡ç»“æœï¼Œå°è¯•ä»æ–‡ä»¶ä¸­è¯»å–")
            
            try:
                # å°è¯•ä»JSONæ–‡ä»¶ä¸­è¯»å–è¯„å®¡ç»“æœ
                proposal_id = state.get("proposal_id", "")
                if proposal_id:
                    reviews_dir = Path(__file__).parent.parent.parent.parent / "output" / "reviews"
                    review_filepath = reviews_dir / f"Review_{proposal_id}.json"
                    
                    if review_filepath.exists():
                        logging.info(f"ğŸ“ å°è¯•ä»æ–‡ä»¶è¯»å–è¯„å®¡ç»“æœ: {review_filepath}")
                        with open(review_filepath, 'r', encoding='utf-8') as f:
                            file_review_result = json.load(f)
                        
                        if file_review_result.get("success", False):
                            logging.info("âœ… æˆåŠŸä»æ–‡ä»¶ä¸­è¯»å–åˆ°æœ‰æ•ˆçš„è¯„å®¡ç»“æœ")
                            review_result = file_review_result
                            # é‡æ–°è·å–è¯„åˆ†ä¿¡æ¯
                            llm_scores = review_result.get("llm_scores", {})
                            overall_score = llm_scores.get("æ€»ä½“è¯„åˆ†", 0)
                            logging.info(f"ğŸ“ ä»æ–‡ä»¶è·å–çš„æ€»ä½“è¯„åˆ†: {overall_score}")
                        else:
                            logging.warning("âš ï¸ æ–‡ä»¶ä¸­çš„è¯„å®¡ç»“æœä¹Ÿæ— æ•ˆ")
                    else:
                        logging.warning(f"âš ï¸ è¯„å®¡ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {review_filepath}")
            except Exception as e:
                logging.error(f"âŒ ä»æ–‡ä»¶è¯»å–è¯„å®¡ç»“æœå¤±è´¥: {e}")
            
            # å¦‚æœä»ç„¶æ— æ³•è·å–æœ‰æ•ˆç»“æœï¼Œå¼ºåˆ¶è¿›è¡Œæ”¹è¿›
            if not review_result or not review_result.get("success", False):
                logging.warning("âš ï¸ æœ€ç»ˆæ— æ³•è·å–æœ‰æ•ˆçš„è¯„å®¡ç»“æœï¼Œå¼ºåˆ¶è¿›è¡Œæ”¹è¿›")
                return "improve"
          # é‡æ–°è·å–è¯„åˆ†ä¿¡æ¯ï¼ˆå¯èƒ½ä»æ–‡ä»¶ä¸­æ›´æ–°äº†review_resultï¼‰
        llm_scores = review_result.get("llm_scores", {})
        logging.info(f"llm_scoresç±»å‹: {type(llm_scores)}")
        logging.info(f"llm_scores: {llm_scores}")
        
        overall_score = llm_scores.get("æ€»ä½“è¯„åˆ†", 0)
        logging.info(f"æœ€ç»ˆè·å–åˆ°çš„æ€»ä½“è¯„åˆ†: {overall_score} (ç±»å‹: {type(overall_score)})")
        
        # å¦‚æœæ— æ³•è·å–è¯„åˆ†ï¼Œå¼ºåˆ¶è¿›è¡Œæ”¹è¿›    
        if overall_score == 0 or not isinstance(overall_score, (int, float)):
            logging.warning(f"âš ï¸ æ— æ³•è·å–æœ‰æ•ˆçš„è¯„å®¡åˆ†æ•° ({overall_score})ï¼Œå¼ºåˆ¶è¿›è¡Œæ”¹è¿›")
            return "improve"
        
        # è®¾ç½®è¯„åˆ†é˜ˆå€¼ï¼Œä½äºæ­¤åˆ†æ•°åˆ™è¿›è¡Œæ”¹è¿›
        improvement_threshold = 8.5
        
        # å¦‚æœå·²ç»å°è¯•æ”¹è¿›ä¸€æ¬¡ï¼Œä¸å†è¿›è¡Œç¬¬äºŒæ¬¡æ”¹è¿›
        if state.get("improvement_attempt", 0) > 0:
            logging.info(f"å·²å°è¯•æ”¹è¿› {state['improvement_attempt']} æ¬¡ï¼Œä¸å†ç»§ç»­æ”¹è¿›")
            return "finalize"
        
        if overall_score < improvement_threshold:
            logging.info(f"è¯„å®¡å¾—åˆ† ({overall_score}) ä½äºé˜ˆå€¼ ({improvement_threshold})ï¼Œå‡†å¤‡è¿›è¡Œæ”¹è¿›")
            return "improve"
        else:
            logging.info(f"è¯„å®¡å¾—åˆ† ({overall_score}) è¾¾åˆ°æˆ–è¶…è¿‡é˜ˆå€¼ ({improvement_threshold})ï¼Œæ— éœ€æ”¹è¿›")
            return "finalize"

    def generate_revision_guidance_node(self, state: ProposalState) -> ProposalState:
        """æ ¹æ®è¯„å®¡ç»“æœç”Ÿæˆä¿®è®¢æŒ‡å¯¼"""
        state["global_step_num"] += 1
        start_time = time.time()
        
        review_result = state.get("review_result", {})
        research_field = state.get("research_field", "")
        
        if not review_result.get("success", False):
            logging.warning("âš ï¸ è¯„å®¡ç»“æœæ— æ•ˆï¼Œæ— æ³•ç”Ÿæˆä¿®è®¢æŒ‡å¯¼")
            state["revision_guidance"] = "æ— æœ‰æ•ˆè¯„å®¡ç»“æœ"
            return state
        
        logging.info("ğŸ“ æ­£åœ¨æ ¹æ®è¯„å®¡ç»“æœç”Ÿæˆä¿®è®¢æŒ‡å¯¼...")
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="ç”Ÿæˆä¿®è®¢æŒ‡å¯¼",
            content="\næ­£åœ¨ç”Ÿæˆä¿®è®¢æŒ‡å¯¼..."
        ))
        
        try:
            # å¯¼å…¥ReviewerAgent
            from src.reviewer.reviewer import ReviewerAgent
            reviewer = ReviewerAgent()
            
            # ä½¿ç”¨ReviewerAgentç”Ÿæˆä¿®è®¢æŒ‡å¯¼
            guidance_result = reviewer.generate_revision_guidance(
                review_result=review_result,
                research_field=research_field
            )
            
            if guidance_result.get("success", False):
                # å°†ä¿®è®¢æŒ‡å¯¼è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                revision_focus = guidance_result.get("revision_focus", "")
                revision_instructions = guidance_result.get("revision_instructions", [])
                
                revision_text = f"# ä¿®è®¢æŒ‡å¯¼\n\n## ä¿®è®¢é‡ç‚¹\n{revision_focus}\n\n## ä¿®è®¢æŒ‡å—\n"
                
                for i, instruction in enumerate(revision_instructions, 1):
                    target = instruction.get("target_section", "å…¨éƒ¨")
                    operation = instruction.get("operation", "ä¿®æ”¹")
                    specific = instruction.get("specific_instruction", "")
                    reason = instruction.get("reasoning", "")
                    
                    revision_text += f"### {i}. {target}éƒ¨åˆ† - {operation}\n"
                    revision_text += f"- å…·ä½“æŒ‡å¯¼: {specific}\n"
                    revision_text += f"- åŸå› : {reason}\n\n"
                
                # ä¿å­˜ä¿®è®¢æŒ‡å¯¼
                state["revision_guidance"] = revision_text
                state["revision_guidance_structured"] = guidance_result
                state["improvement_attempt"] = state.get("improvement_attempt", 0) + 1
                
                QueueUtil.push_mes(StreamAnswerMes(
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="",
                    content=f"\n\nâœ… ä¿®è®¢æŒ‡å¯¼ç”Ÿæˆå®Œæˆ:\n\n{revision_text[:500]}..."
                ))
            else:
                error_msg = guidance_result.get("error", "æœªçŸ¥é”™è¯¯")
                logging.error(f"âŒ ç”Ÿæˆä¿®è®¢æŒ‡å¯¼å¤±è´¥: {error_msg}")
                state["revision_guidance"] = f"ç”Ÿæˆä¿®è®¢æŒ‡å¯¼å¤±è´¥: {error_msg}"
                QueueUtil.push_mes(StreamAnswerMes(
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="",
                    content=f"\nâŒ ç”Ÿæˆä¿®è®¢æŒ‡å¯¼å¤±è´¥: {error_msg}"
                ))
    
        except Exception as e:
            logging.error(f"âŒ ä¿®è®¢æŒ‡å¯¼ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            state["revision_guidance"] = f"ä¿®è®¢æŒ‡å¯¼ç”Ÿæˆå¼‚å¸¸: {str(e)}"
            QueueUtil.push_mes(StreamAnswerMes(                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content=f"\nâŒ ä¿®è®¢æŒ‡å¯¼ç”Ÿæˆå¼‚å¸¸: {str(e)}"
            ))
    
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time)
        ))
        return state

    def apply_improvements_node(self, state: ProposalState) -> ProposalState:
        """æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆæ”¹è¿›åçš„ç ”ç©¶è®¡åˆ’ä¹¦"""
        state["global_step_num"] += 1
        start_time = time.time()
        
        # å¢åŠ æ”¹è¿›å°è¯•æ¬¡æ•°
        state["improvement_attempt"] = state.get("improvement_attempt", 0) + 1
        logging.info(f"ğŸ”„ å¼€å§‹ç¬¬ {state['improvement_attempt']} æ¬¡æ”¹è¿›å°è¯•")
    
        revision_guidance = state.get("revision_guidance", "")
        research_field = state.get("research_field", "")
        user_clarifications = state.get("user_clarifications", "")
        proposal_id = state.get("proposal_id", "")
    
        if not revision_guidance or revision_guidance.startswith("ç”Ÿæˆä¿®è®¢æŒ‡å¯¼å¤±è´¥"):
            logging.warning("âš ï¸ æ— æœ‰æ•ˆä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡æ”¹è¿›æ­¥éª¤")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content="\nâš ï¸ æ— æœ‰æ•ˆä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡æ”¹è¿›æ­¥éª¤"
            ))
            return state
    
        logging.info("ğŸ”„ æ­£åœ¨æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦...")
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="åº”ç”¨æ”¹è¿›",
            content="\næ­£åœ¨æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç ”ç©¶è®¡åˆ’..."
        ))        # ç”Ÿæˆæ–°çš„proposal_idç”¨äºåŒºåˆ†æ”¹è¿›å‰åçš„ç‰ˆæœ¬ï¼ˆä½†æ¶ˆæ¯ä»æ¨é€åˆ°åŸproposal_idï¼‰
        improved_proposal_id = f"{proposal_id}_improved_{state.get('improvement_attempt', 1)}"
    
        # ä¿å­˜åŸå§‹æŠ¥å‘Š
        original_report = state.get("final_report_markdown", "")
        original_report_path = ""
        try:
            # åˆ›å»ºoutputæ–‡ä»¶å¤¹
            output_dir = Path(__file__).parent.parent.parent.parent / "output"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            # ä¿å­˜åŸå§‹æŠ¥å‘Š
            original_filename = f"Research_Proposal_{proposal_id}_original.md"
            original_report_path = os.path.join(output_dir, original_filename)
            
            with open(original_report_path, 'w', encoding='utf-8') as f:
                f.write(original_report)
            
            logging.info(f"âœ… åŸå§‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: {original_report_path}")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜åŸå§‹æŠ¥å‘Šå¤±è´¥: {e}")        # ç›´æ¥åœ¨å½“å‰æµç¨‹ä¸­é‡æ–°ç”Ÿæˆå†…å®¹ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°çš„Agentå®ä¾‹
        try:
            # ä¿å­˜æ”¹è¿›å‰çš„å†…å®¹ä½œä¸ºå¤‡ä»½
            state["original_introduction"] = state.get("introduction", "")
            state["original_literature_review"] = state.get("literature_review", "")
            state["original_research_design"] = state.get("research_design", "")
            state["original_conclusion"] = state.get("conclusion", "")
            state["original_final_report"] = state.get("final_report_markdown", "")
            
            # é‡æ–°ç”Ÿæˆå„ä¸ªéƒ¨åˆ†ï¼ˆåŸºäºä¿®è®¢æŒ‡å¯¼ï¼‰
            logging.info("ğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆå¼•è¨€éƒ¨åˆ†...")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="æ”¹è¿›å¼•è¨€",
                content=f"\nğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆå¼•è¨€éƒ¨åˆ†..."
            ))
            
            # é‡æ–°ç”Ÿæˆå¼•è¨€ï¼ˆå·²è€ƒè™‘ä¿®è®¢æŒ‡å¯¼ï¼‰
            state = self.write_introduction_node(state)
            
            logging.info("ğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆæ–‡çŒ®ç»¼è¿°éƒ¨åˆ†...")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="æ”¹è¿›æ–‡çŒ®ç»¼è¿°",
                content=f"\nğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆæ–‡çŒ®ç»¼è¿°éƒ¨åˆ†..."
            ))
            
            # é‡æ–°ç”Ÿæˆæ–‡çŒ®ç»¼è¿°
            state = self.write_literature_review_node(state)
            
            logging.info("ğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç ”ç©¶è®¾è®¡éƒ¨åˆ†...")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="æ”¹è¿›ç ”ç©¶è®¾è®¡",
                content=f"\nğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç ”ç©¶è®¾è®¡éƒ¨åˆ†..."
            ))
            
            # é‡æ–°ç”Ÿæˆç ”ç©¶è®¾è®¡
            state = self.write_research_design_node(state)
            
            logging.info("ğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç»“è®ºéƒ¨åˆ†...")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="æ”¹è¿›ç»“è®º",
                content=f"\nğŸ”„ æ ¹æ®ä¿®è®¢æŒ‡å¯¼é‡æ–°ç”Ÿæˆç»“è®ºéƒ¨åˆ†..."
            ))
            
            # é‡æ–°ç”Ÿæˆç»“è®º
            state = self.write_conclusion_node(state)
            
            # é‡æ–°ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            logging.info("ğŸ“„ é‡æ–°ç”Ÿæˆæœ€ç»ˆæ”¹è¿›æŠ¥å‘Š...")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š",
                content=f"\nï¿½ é‡æ–°ç”Ÿæˆæœ€ç»ˆæ”¹è¿›æŠ¥å‘Š..."
            ))
            
            state = self.generate_final_references_node(state)
            state = self.generate_final_report_node(state)
            
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content=f"\nâœ… æ”¹è¿›åçš„ç ”ç©¶è®¡åˆ’ä¹¦å·²é‡æ–°ç”Ÿæˆå®Œæˆ"
            ))
            
            # æ˜ç¡®æ ‡è®°æ”¹è¿›æµç¨‹å®Œæˆ
            state["improvement_completed"] = True
            logging.info(f"ğŸ¯ æ”¹è¿›æµç¨‹å·²å®Œæˆï¼Œimprovement_attempt: {state.get('improvement_attempt', 0)}")
            
        except Exception as e:
            logging.error(f"âŒ åº”ç”¨æ”¹è¿›å¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {traceback.format_exc()}")
            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content=f"\nâŒ åº”ç”¨æ”¹è¿›å¼‚å¸¸: {str(e)}"
            ))
            # å³ä½¿å‡ºé”™ä¹Ÿæ ‡è®°å®Œæˆï¼Œé¿å…æ— é™å¾ªç¯
            state["improvement_completed"] = True
        
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time)
        ))
        
        # æœ€ç»ˆç¡®è®¤æ”¹è¿›æµç¨‹å·²ç»“æŸï¼Œå‡†å¤‡è¿›å…¥ä¿å­˜ç¯èŠ‚
        logging.info("ğŸ”š apply_improvements_node å®Œæˆï¼Œå‡†å¤‡è¿›å…¥ save_memory")
        return state

    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)

        # 1. å®šä¹‰æ‰€æœ‰èŠ‚ç‚¹
        workflow.add_node("clarify_focus", self.clarify_research_focus_node)
        workflow.add_node("create_master_plan", self.create_master_plan_node)
        workflow.add_node("plan_analysis", self.plan_analysis_node)
        workflow.add_node("execute_step", self.execute_step_node)
        workflow.add_node("summarize_history", self.summarize_history_node)  # çŸ­æœŸè®°å¿†èŠ‚ç‚¹
        workflow.add_node("add_references", self.add_references_from_data)

        # æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
        workflow.add_node("write_introduction", self.write_introduction_node)
        workflow.add_node("write_literature_review", self.write_literature_review_node)
        workflow.add_node("write_research_design", self.write_research_design_node)
        workflow.add_node("write_conclusion", self.write_conclusion_node)
        workflow.add_node("generate_final_references", self.generate_final_references_node)
        workflow.add_node("generate_final_report", self.generate_final_report_node)
        
        # è¯„å®¡å’Œæ”¹è¿›èŠ‚ç‚¹
        workflow.add_node("review_proposal", self.review_proposal_node)
        workflow.add_node("generate_revision_guidance", self.generate_revision_guidance_node)
        workflow.add_node("apply_improvements", self.apply_improvements_node)
        workflow.add_node("save_memory", self.save_to_long_term_memory_node)  # é•¿æœŸè®°å¿†èŠ‚ç‚¹

        # 2. è®¾ç½®å›¾çš„å…¥å£ç‚¹
        workflow.set_entry_point("clarify_focus")

        # 3. åŸºç¡€æµç¨‹
        workflow.add_edge("clarify_focus", "create_master_plan")
        workflow.add_edge("create_master_plan", "plan_analysis")
        workflow.add_edge("plan_analysis", "execute_step")

        # æ ¸å¿ƒæ‰§è¡Œå¾ªç¯
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue,
            {
                "continue": "execute_step",  # <-- æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥è¿”å›æ‰§è¡Œä¸‹ä¸€æ­¥
                "plan_analysis": "plan_analysis",  # å¦‚æœéœ€è¦é‡æ–°è§„åˆ’
                "summarize": "summarize_history",
                "end_report": "add_references"  # ç»“æŸå¾ªç¯ï¼Œå¼€å§‹æ•´åˆæŠ¥å‘Š

            }
        )

        # çŸ­æœŸè®°å¿†å¾ªç¯
        workflow.add_edge("summarize_history", "execute_step")  # <-- æ ¸å¿ƒä¿®æ”¹ï¼šæ‘˜è¦åè¿”å›æ‰§è¡Œä¸‹ä¸€æ­¥

        # æŠ¥å‘Šç”Ÿæˆæµç¨‹
        workflow.add_edge("add_references", "write_introduction")
        workflow.add_edge("write_introduction", "write_literature_review")
        workflow.add_edge("write_literature_review", "write_research_design")
        workflow.add_edge("write_research_design", "write_conclusion")
        workflow.add_edge("write_conclusion", "generate_final_references")
        workflow.add_edge("generate_final_references", "generate_final_report")
        
        # å…³é”®ä¿®å¤ï¼šç›´æ¥è¿æ¥è¯„å®¡æµç¨‹ï¼Œå»æ‰æœªå®šä¹‰çš„check_improvementsèŠ‚ç‚¹
        workflow.add_edge("generate_final_report", "review_proposal")
        
        # è¯„å®¡åçš„æ¡ä»¶åˆ†æ”¯ï¼šç›´æ¥ä½¿ç”¨should_improveæ–¹æ³•
        workflow.add_conditional_edges(
            "review_proposal",
            self.should_improve,
            {
                "improve": "generate_revision_guidance",  # éœ€è¦æ”¹è¿›
                "finalize": "save_memory"  # æ— éœ€æ”¹è¿›ï¼Œç›´æ¥ä¿å­˜
            }
        )
        
        # æ”¹è¿›æµç¨‹
        workflow.add_edge("generate_revision_guidance", "apply_improvements")
        workflow.add_edge("apply_improvements", "save_memory")  # æ”¹è¿›åä¿å­˜
        workflow.add_edge("save_memory", END)

        # 4. ç¼–è¯‘å›¾
        try:
            compiled_workflow = workflow.compile()
            logging.info("âœ… å·¥ä½œæµç¼–è¯‘æˆåŠŸ")
            return compiled_workflow
        except Exception as e:
            logging.error(f"âŒ å·¥ä½œæµç¼–è¯‘å¤±è´¥: {e}")
            raise e

    def generate_proposal(self, research_field: str, proposal_id: str, user_clarifications: str = "",
                          revision_guidance: str = "") -> Dict[str, Any]:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦"""
        # if not proposal_id:
        #     proposal_id = f"proposal_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        config = {"configurable": {"thread_id": proposal_id}}

        initial_state = {
            "research_field": research_field,
            "user_clarifications": user_clarifications,  # æ–°å¢ï¼šæ¥æ”¶ç”¨æˆ·æ¾„æ¸…
            "revision_guidance": revision_guidance,
            "improvement_attempt": 0,  # è®°å½•æ”¹è¿›æ¬¡æ•°
            "proposal_id": proposal_id,  # æ–°å¢ï¼šå”¯ä¸€æ ‡è¯†ç¬¦
            "clarification_questions": [],  # æ–°å¢ï¼šåˆå§‹åŒ–æ¾„æ¸…é—®é¢˜åˆ—è¡¨
            "query": "",
            "arxiv_papers": [],
            "web_search_results": [],
            "background": "",
            "objectives": "",
            "methodology": "",
            "timeline": "",
            "expected_outcomes": "",
            "final_proposal": "",
            "messages": [],
            "research_plan": "",
            "available_tools": [],
            "execution_plan": [],
            "execution_memory": [],
            "current_step": 0,
            "max_iterations": 10,
            "introduction": "",
            "literature_review": "",
            "research_design": "",
            "timeline_plan": "",
            "expected_results": "",
            "reference_list": [],  # åˆå§‹åŒ–ç»Ÿä¸€å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            "ref_counter": 1,  # åˆå§‹åŒ–å‚è€ƒæ–‡çŒ®è®¡æ•°å™¨
            "final_references": "",
            "conclusion": "",
            "gantt_chart": "",  # ç¡®ä¿ç”˜ç‰¹å›¾å­—æ®µæ­£ç¡®åˆå§‹åŒ–
            "gantt_chart_backup": "",  # æ·»åŠ å¤‡ä»½å­—æ®µ
            "final_report_markdown": "", # åˆå§‹åŒ–æœ€ç»ˆæŠ¥å‘Šå­—æ®µ
            "global_step_num": 0, # åˆå§‹åŒ–å…¨å±€æ­¥éª¤è®¡æ•°å™¨
        }

        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶é—®é¢˜: '{research_field}' (ä»»åŠ¡ID: {proposal_id})")

        result = self.workflow.invoke(initial_state, config=config)
        
        # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦æ­£å¸¸å®Œæˆ
        # å¦‚æœå·²ç»æœ‰æœ€ç»ˆæŠ¥å‘Šï¼Œè¯´æ˜å·¥ä½œæµå·²å®Œæˆï¼Œä¸åº”è¯¥å†è¦æ±‚æ¾„æ¸…
        has_final_report = result.get("final_report_markdown", "")
        improvement_completed = result.get("improvement_completed", False)
        
        # åªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µæ‰è¿”å›æ¾„æ¸…é—®é¢˜ï¼š
        # 1. æ²¡æœ‰ä¿®è®¢æŒ‡å¯¼ï¼ˆä¸æ˜¯æ”¹è¿›æµç¨‹ï¼‰
        # 2. æ²¡æœ‰æœ€ç»ˆæŠ¥å‘Šï¼ˆå·¥ä½œæµæœªå®Œæˆï¼‰
        # 3. æ²¡æœ‰å®Œæˆæ”¹è¿›æµç¨‹
        clarification_questions = result.get("clarification_questions", [])
        if (clarification_questions and 
            not revision_guidance and 
            not has_final_report and 
            not improvement_completed):
            logging.info("ğŸ¤” Agentç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥")
            return {"clarification_questions": clarification_questions}
        
        logging.info("âœ… å·¥ä½œæµå·²å®Œæˆï¼Œè¿”å›æœ€ç»ˆç»“æœ")
        return result

    def summarize_history_node(self, state: ProposalState) -> ProposalState:
        """
        å›é¡¾æ‰§è¡Œå†å²å¹¶ç”Ÿæˆæ‘˜è¦ã€‚
        é‡‡ç”¨å¢é‡å¼æ‘˜è¦ç­–ç•¥ï¼šåŸºäºæ—§çš„æ‘˜è¦å’Œæœ€æ–°çš„ä¸€æ­¥æ¥ç”Ÿæˆæ–°æ‘˜è¦ã€‚
        """
        state["global_step_num"] += 1
        start_time = time.time()

        logging.info("ğŸ§  å¼€å§‹ç”Ÿæˆå¢é‡å¼æ‰§è¡Œå†å²æ‘˜è¦...")

        execution_memory = state.get("execution_memory", [])
        if not execution_memory:
            return state  # å¦‚æœæ²¡æœ‰å†å²ï¼Œåˆ™è·³è¿‡

        old_summary = state.get("history_summary", "")
        latest_step = execution_memory[-1]  # åªå–æœ€æ–°çš„ä¸€æ­¥

        # å°†æœ€æ–°æ­¥éª¤æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
        latest_step_text = (
            f"- æè¿°: {latest_step.get('description', 'N/A')}\n"
            f"- åŠ¨ä½œ: {latest_step.get('action', 'N/A')}\n"
            f"- ç»“æœ: {'æˆåŠŸ' if latest_step.get('success') else 'å¤±è´¥'}\n"
            f"- è¯¦æƒ…: {str(latest_step.get('result', ''))[:200]}..."
        )

        # å¦‚æœæ²¡æœ‰æ—§æ‘˜è¦ï¼ˆè¿™æ˜¯ç¬¬ä¸€æ¬¡æ€»ç»“ï¼‰ï¼Œåˆ™å¯¹ç›®å‰æ‰€æœ‰çš„å†å²è¿›è¡Œæ€»ç»“
        if not old_summary:
            prompt_template = """
            ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©ç†ï¼Œæ­£åœ¨ä¸ºä¸€é¡¹å¤æ‚çš„ç§‘ç ”ä»»åŠ¡æ’°å†™ç¬¬ä¸€ä»½è¿›åº¦æ‘˜è¦ã€‚
            è¯·æ ¹æ®ä»¥ä¸‹åˆ°ç›®å‰ä¸ºæ­¢çš„æ‰€æœ‰æ‰§è¡Œå†å²ï¼Œç”Ÿæˆä¸€æ®µç®€æ´ã€ç²¾ç‚¼çš„æ‘˜è¦ã€‚
            æ‘˜è¦éœ€è¦æ•æ‰åˆ°å…³é”®å‘ç°ã€é‡åˆ°çš„ä¸»è¦éšœç¢æˆ–å¤±è´¥ï¼Œä»¥åŠå°šæœªè§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

            åŸå§‹ç ”ç©¶é—®é¢˜: {research_field}
            
            æ‰§è¡Œå†å²:
            {history}

            è¯·è¾“å‡ºæ‘˜è¦:
            """
            # æ ¼å¼åŒ–å®Œæ•´çš„å†å²è®°å½•
            full_history_text = "\n".join([
                f"- æ­¥éª¤ {i + 1}: {mem.get('description', 'N/A')}, ç»“æœ: {'æˆåŠŸ' if mem.get('success') else 'å¤±è´¥'}, è¯¦æƒ…: {str(mem.get('result', ''))[:150]}..."
                for i, mem in enumerate(execution_memory)
            ])
            prompt = prompt_template.format(
                research_field=state['research_field'],
                history=full_history_text
            )
        else:
            # å¦‚æœæœ‰æ—§æ‘˜è¦ï¼Œåˆ™è¿›è¡Œå¢é‡æ›´æ–°
            prompt_template = """
            ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©ç†ï¼Œæ­£åœ¨å®æ—¶æ›´æ–°ä¸€ä»½ä»»åŠ¡è¿›åº¦æ‘˜è¦ã€‚
            ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€ä¸Šä¸€ç‰ˆçš„æ‘˜è¦ã€‘å’Œã€æœ€æ–°å®Œæˆçš„æ­¥éª¤ã€‘ï¼Œç”Ÿæˆä¸€ä»½ã€æ›´æ–°åçš„æ‘˜è¦ã€‘ã€‚
            è¯·ä¸è¦é‡å¤æ—§æ‘˜è¦å·²æœ‰çš„ä¿¡æ¯ï¼Œé‡ç‚¹åœ¨äºæ•´åˆæ–°ä¿¡æ¯å¹¶æç‚¼å‡ºå½“å‰æœ€å…³é”®çš„å‘ç°ã€éšœç¢å’Œç»“è®ºã€‚

            ã€ä¸Šä¸€ç‰ˆçš„æ‘˜è¦ã€‘:
            {old_summary}

            ã€æœ€æ–°å®Œæˆçš„æ­¥éª¤ã€‘:
            {latest_step}

            è¯·è¾“å‡ºä¸€ä»½ç®€æ´ã€è¿è´¯çš„ã€æ›´æ–°åçš„æ‘˜è¦ã€‘:
            """
            prompt = prompt_template.format(
                old_summary=old_summary,
                latest_step=latest_step_text
            )

        full_content = StreamUtil.transfer_stream_answer_mes(
            stream_res=self.llm.stream([SystemMessage(content=prompt)]),
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="å›é¡¾å†å²å¹¶ç”Ÿæˆæ‘˜è¦"
        )

        state["history_summary"] = full_content
        logging.info(f"âœ… ç”Ÿæˆæ‘˜è¦å®Œæˆ: {full_content}")

        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="",
            content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
        )
        return state

    def save_to_long_term_memory_node(self, state: ProposalState) -> ProposalState:
        """å°†æœ€ç»ˆæŠ¥å‘Šçš„æ ¸å¿ƒæ´å¯Ÿå­˜å…¥é•¿æœŸè®°å¿†"""
        state["global_step_num"] += 1
        start_time = time.time()
        
        logging.info("ğŸ’¾ æ­£åœ¨å°†æœ¬æ¬¡ç ”ç©¶æˆæœå­˜å…¥é•¿æœŸè®°å¿†...")
        
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state["global_step_num"],
            title="ä¿å­˜æˆæœ",
            content="\nğŸ’¾ æ­£åœ¨å°†ç ”ç©¶æˆæœå­˜å…¥çŸ¥è¯†åº“..."
        ))

        proposal_id = state.get("proposal_id")
        if not proposal_id:
            logging.warning("âš ï¸ proposal_id ä¸å­˜åœ¨ï¼Œæ— æ³•å­˜å…¥é•¿æœŸè®°å¿†ã€‚")
            return state

        # ç”Ÿæˆä¸€ä¸ªç”¨äºå­˜å‚¨çš„æ–‡æ¡£
        document_to_store = f"""
        ç ”ç©¶è¯¾é¢˜: {state.get('research_field')}
        ç”¨æˆ·æ¾„æ¸…: {state.get('user_clarifications', 'æ— ')}
        æœ€ç»ˆç ”ç©¶è®¡åˆ’æ‘˜è¦: {state.get('research_plan', '')[:500]}...
        å¼•è¨€æ ¸å¿ƒ: {state.get('introduction', '')[:500]}...
        æ–‡çŒ®ç»¼è¿°è¦ç‚¹: {state.get('literature_review', '')[:500]}...
        æœ€ç»ˆç»“è®º: {state.get('conclusion', '')[:500]}...
        """

        try:
            self.long_term_memory.add_texts(
                texts=[document_to_store],
                metadatas=[{"proposal_id": proposal_id, "timestamp": datetime.now().isoformat()}],
                ids=[proposal_id]  # ä½¿ç”¨ proposal_id ä½œä¸ºå”¯ä¸€æ ‡è¯†
            )
            # ChromaDB in-memory with persist_directory handles saving automatically on updates.
            # self.long_term_memory.persist() # æ˜¾å¼è°ƒç”¨ persist() å¯èƒ½ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¯ä»¥ç¡®ä¿å†™å…¥
            logging.info(f"âœ… æˆåŠŸå°† proposal_id '{proposal_id}' å­˜å…¥é•¿æœŸè®°å¿†ã€‚")
        except Exception as e:
            logging.error(f"âŒ å­˜å…¥é•¿æœŸè®°å¿†å¤±è´¥: {e}")        # å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯ç»™å‰ç«¯
        QueueUtil.push_mes(StreamAnswerMes(
            proposal_id=state["proposal_id"],
            step=state.get("global_step_num", 0),
            title="æµç¨‹å®Œæˆ",
            content=f"\nğŸ‰ ç ”ç©¶è®¡åˆ’ä¹¦ç”Ÿæˆå®Œæˆï¼\n\nğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜\nğŸ“š å‚è€ƒæ–‡çŒ®å·²æ•´ç†\nğŸ’¾ æˆæœå·²å­˜å…¥çŸ¥è¯†åº“\n\nâœ… æ‰€æœ‰æµç¨‹å·²å®Œæˆï¼Œå¯ä»¥ä¸‹è½½ç»“æœæ–‡ä»¶ã€‚\n\nâ±ï¸ æœ¬é˜¶æ®µè€—æ—¶: {time.time() - start_time:.2f}s",
            is_finish=True
        ))
        
        logging.info("ğŸ æ•´ä¸ªæµç¨‹å·²å®Œæˆï¼Œå·²é€šçŸ¥å‰ç«¯")
        return state

    def rerank_with_llm(self, state: ProposalState, relevance_threshold: float = 0.6) -> List[Dict]:
        """
        ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ’åºã€‚

        å‚æ•°:
            research_field (str): ç ”ç©¶é¢†åŸŸ
            reference_list (List[Dict]): åˆå§‹æœç´¢ç»“æœ
            relevance_threshold (float): ç›¸å…³æ€§é˜ˆå€¼æ¯”ä¾‹ï¼Œé»˜è®¤0.6ï¼ˆå³å¹³å‡åˆ†çš„60%ï¼‰

        è¿”å›:
            List[Dict]: é‡æ’åºåçš„ç»“æœï¼ˆä¿ç•™é«˜äºå¹³å‡åˆ†60%çš„æ–‡çŒ®ï¼‰
        """
        state["global_step_num"] += 1
        start_time = time.time()

        research_field = state.get("research_field")
        reference_list = state.get("reference_list")

        if len(reference_list) < 3:
            logging.info(f"å‚è€ƒæ–‡ä»¶å°‘äº3æ¡ä¸è¿›è¡Œé‡æ’åº...")
            return reference_list

        logging.info(f"é‡æ’åº {len(reference_list)} ä¸ªæ–‡ä»¶...")

        scored_results = []  # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜å‚¨è¯„åˆ†åçš„ç»“æœ

        # å®šä¹‰ç³»ç»Ÿæç¤ºç»™LLM
        system_prompt = """You are an expert at evaluating document relevance for search queries.
    Your task is to rate documents on a scale from 0 to 10 based on how well they answer the given query.
    Guidelines:
    - Score 0-2: Document is completely irrelevant
    - Score 3-5: Document has some relevant information but doesn't directly answer the query
    - Score 6-8: Document is relevant and partially answers the query
    - Score 9-10: Document is highly relevant and directly answers the query
    You MUST respond with ONLY a single integer score between 0 and 10. Do not include ANY other text."""

        # éå†æ¯ä¸ªç»“æœ
        for i, reference in enumerate(reference_list):
            # æ¯å¤„ç†5ä¸ªæ–‡æ¡£æ˜¾ç¤ºè¿›åº¦
            if i % 5 == 0:
                logging.info(f"æ­£åœ¨æ’åºç¬¬ {i + 1}/{len(reference_list)} ä¸ªæ–‡ä»¶...")

            response = None  # åˆå§‹åŒ– response å˜é‡

            if reference["type"] == "ArXiv" or reference["type"] == "CrossRef" or reference["type"] == "Google Scholar":
                # å®šä¹‰ç”¨æˆ·æç¤ºç»™LLM
                user_prompt = f"""Query: {research_field}
    Document: {reference.get('summary', '')}
    Rate this document's relevance to the query on a scale from 0 to 10:"""

                # è°ƒç”¨LLMè·å–è¯„åˆ†
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                full_content = StreamUtil.transfer_stream_answer_mes(
                    stream_res=self.llm.stream(messages),
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="å‚è€ƒè®ºæ–‡é‡æ’åº"
                )

            if (reference["type"] == "Web"):
                # å®šä¹‰ç”¨æˆ·æç¤ºç»™LLM
                user_prompt = f"""Query: {research_field}
                        Document: {reference['content_preview']}
                        Rate this document's relevance to the query on a scale from 0 to 10:"""

                # è°ƒç”¨LLMè·å–è¯„åˆ†
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                full_content = StreamUtil.transfer_stream_answer_mes(
                    stream_res=self.llm.stream(messages),
                    proposal_id=state["proposal_id"],
                    step=state["global_step_num"],
                    title="å‚è€ƒç½‘ç»œèµ„æºé‡æ’åº"
                )
                # æå–è¯„åˆ†
            try:
                score = int(full_content)
            except Exception as e:
                logging.error(f"æ–‡ä»¶æ’åºé”™è¯¯ {i}: {e}")
                score = 0  # é»˜è®¤è¯„åˆ† 0

            # å°†è¯„åˆ†å’ŒåŸå§‹ç»“æœä¸€èµ·å­˜å‚¨
            scored_results.append((score, reference))

        # è®¡ç®—å¹³å‡åˆ†
        if scored_results:
            scores = [score for score, _ in scored_results]
            average_score = sum(scores) / len(scores)
            threshold_score = average_score * relevance_threshold

            logging.info(
                f"å¹³å‡è¯„åˆ†: {average_score:.2f}, é˜ˆå€¼: {threshold_score:.2f} (å¹³å‡åˆ†çš„{relevance_threshold * 100}%)")

            # ç­›é€‰é«˜äºé˜ˆå€¼çš„æ–‡çŒ®
            filtered_results = [(score, ref) for score, ref in scored_results if score >= threshold_score]

            if not filtered_results:
                # å¦‚æœæ²¡æœ‰æ–‡çŒ®è¾¾åˆ°é˜ˆå€¼ï¼Œè‡³å°‘ä¿ç•™è¯„åˆ†æœ€é«˜çš„3ä¸ª
                logging.warning("æ²¡æœ‰æ–‡çŒ®è¾¾åˆ°ç›¸å…³æ€§é˜ˆå€¼ï¼Œä¿ç•™è¯„åˆ†æœ€é«˜çš„3ä¸ªæ–‡çŒ®")
                scored_results.sort(reverse=True, key=lambda x: x[0])
                filtered_results = scored_results[:3]
            else:
                # æŒ‰è¯„åˆ†é™åºæ’åº
                filtered_results.sort(reverse=True, key=lambda x: x[0])

            # æå–æ–‡çŒ®ä¿¡æ¯å¹¶é‡æ–°åˆ†é…ID
            final_reference_list = []
            for i, (score, reference) in enumerate(filtered_results, 1):
                reference_copy = reference.copy()  # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                reference_copy["relevance_score"] = score  # æ·»åŠ ç›¸å…³æ€§è¯„åˆ†
                final_reference_list.append(reference_copy)

            logging.info(f"ç­›é€‰åä¿ç•™ {len(final_reference_list)} ä¸ªç›¸å…³æ–‡çŒ®")
            for i, ref in enumerate(final_reference_list[:5]):  # æ˜¾ç¤ºå‰5ä¸ªçš„è¯„åˆ†
                logging.info(
                    f"  æ–‡çŒ® {i + 1}: {ref.get('title', 'Unknown')[:50]}... (è¯„åˆ†: {ref.get('relevance_score', 0)})")

            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
            )

            return final_reference_list
        else:
            logging.warning("æ²¡æœ‰è¯„åˆ†ç»“æœï¼Œè¿”å›åŸå§‹åˆ—è¡¨")

            QueueUtil.push_mes(StreamAnswerMes(
                proposal_id=state["proposal_id"],
                step=state["global_step_num"],
                title="",
                content="\n\nâœ… å¤„ç†å®Œæˆï¼Œå…±è€—æ—¶ %.2fs" % (time.time() - start_time))
            )
            return reference_list

    def execute_action(self, action_name: str, action_input: Dict[str, Any], state: ProposalState) -> Tuple[Dict[str, Any], ProposalState]:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        try:
            # è·å–å¯¹åº”çš„å·¥å…·å‡½æ•°
            tool_func = {
                "search_arxiv_papers": search_arxiv_papers_tool,
                "search_web_content": search_web_content_tool,
                "search_crossref_papers": search_crossref_papers_tool,
                "summarize_pdf": summarize_pdf,
                "generate_gantt_chart": generate_gantt_chart_tool,
                "search_google_scholar": search_google_scholar_site_tool,  # ä¿®æ”¹å·¥å…·åç§°
            }.get(action_name)

            if not tool_func:
                raise ValueError(f"æœªçŸ¥æˆ–ä¸æ”¯æŒçš„ action: {action_name}")

            # æ‰§è¡Œå·¥å…·å‡½æ•°
            result = tool_func(**action_input)

            # æ›´æ–°çŠ¶æ€
            if action_name == "search_arxiv_papers":
                state["arxiv_papers"].extend(result or [])
            elif action_name in ["search_web_content", "search_crossref_papers", "search_google_scholar"]:  # æ›´æ–°å·¥å…·åç§°
                state["web_search_results"].extend(result or [])
            elif action_name == "summarize_pdf" and result and "summary" in result:
                state["pdf_summaries"].append(result)
            elif action_name == "generate_gantt_chart" and result:
                state["gantt_chart"] = result
                state["gantt_chart_backup"] = result  # ä¿å­˜å¤‡ä»½

            return result, state

        except Exception as e:
            logging.error(f"æ‰§è¡ŒåŠ¨ä½œ {action_name} å¤±è´¥: {str(e)}")
            return {"error": str(e)}, state
