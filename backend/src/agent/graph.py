"""
Agentç”Ÿæˆè¿‡ç¨‹ä¸­çš„å›¾ç›¸å…³ï¼šèŠ‚ç‚¹
"""
import time

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
import json
import os
from datetime import datetime
import logging
from backend.src.agent.prompts import * # ç¡®ä¿ CLARIFICATION_QUESTION_PROMPT ä»è¿™é‡Œå¯¼å…¥
import fitz
from dotenv import load_dotenv
from .tools import search_arxiv_papers_tool, search_crossref_papers_tool, search_web_content_tool, summarize_pdf
from .state import ProposalState
from backend.src.utils.queue_util import QueueUtil
from backend.src.utils.stream_mes_util import stream_mes_2_full_content
from ..entity.stream_mes import StreamMes
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings


load_dotenv()
TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY")
DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY")
base_url = os.environ.get("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)


class ProposalAgent:
    def __init__(self):
        """åˆå§‹åŒ–ProposalAgent"""
        self.llm = ChatOpenAI(
            api_key=DASHSCOPE_API_KEY,
            model="qwen-plus",
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0,
            streaming=True,  # ç»Ÿä¸€ä¸ºæµå¼è¾“å‡º
        )

        # è®¾ç½®Tavily APIå¯†é’¥
        # os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

        self.tools = [search_arxiv_papers_tool, search_web_content_tool, search_crossref_papers_tool, summarize_pdf]
        self.tools_description = self.load_tools_description()
        self.agent_with_tools = create_react_agent(self.llm, self.tools)
        
        # åˆå§‹åŒ–é•¿æœŸè®°å¿†
        self.embedding_function = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        self.long_term_memory = Chroma(
            collection_name="proposal_agent_memory",
            embedding_function=self.embedding_function,
            persist_directory="./chroma_db" # æŒä¹…åŒ–å­˜å‚¨è·¯å¾„
        )
        
        self.workflow = self._build_workflow()

    def load_tools_description(self) -> List[Dict]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·¥å…·æè¿°"""
        current_script_dir = os.path.dirname(os.path.abspath(__file__))
        tools_json_path = os.path.join(current_script_dir, 'tools.json')
        try:
            with open(tools_json_path, 'r', encoding='utf-8') as f:
                tools_description = json.load(f)
            return tools_description
        except FileNotFoundError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []
        except json.JSONDecodeError:
            print("è­¦å‘Š: tools.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æè¿°")
            return []

    def get_tools_info_text(self) -> str:
        """å°†å·¥å…·ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if not self.tools_description:
            return "æš‚æ— å¯ç”¨å·¥å…·ä¿¡æ¯"

        tools_text = "å¯ç”¨å·¥å…·åˆ—è¡¨:\n\n"
        for tool_info in self.tools_description:
            func_info = tool_info.get("function", {})
            name = func_info.get("name", "æœªçŸ¥å·¥å…·")
            description = func_info.get("description", "æ— æè¿°")

            tools_text += f"ğŸ”§ **{name}**\n"
            tools_text += f"   æè¿°: {description}\n"

            # æ·»åŠ å‚æ•°ä¿¡æ¯
            params = func_info.get("parameters", {}).get("properties", {})
            if params:
                tools_text += f"   å‚æ•°:\n"
                for param_name, param_info in params.items():
                    param_desc = param_info.get("description", "æ— æè¿°")
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    required = param_name in func_info.get("parameters", {}).get("required", [])
                    required_text = "å¿…éœ€" if required else "å¯é€‰"
                    tools_text += f"     - {param_name} ({param_type}, {required_text}): {param_desc}\n"

            tools_text += "\n"

        return tools_text
    

    def clarify_research_focus_node(self, state: ProposalState) -> ProposalState:
        """æ ¹æ®ç ”ç©¶é¢†åŸŸç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œæˆ–å¤„ç†ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯"""
        research_field = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        existing_questions = state.get("clarification_questions", [])
        revision_guidance = state.get("revision_guidance", "")
        
        # å¦‚æœæœ‰ä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡ç”Ÿæˆæ¾„æ¸…é—®é¢˜
        if revision_guidance:
            logging.info(f"ğŸ“ æ£€æµ‹åˆ°ä¿®è®¢æŒ‡å¯¼ï¼Œè·³è¿‡æ¾„æ¸…é—®é¢˜ç”Ÿæˆæ­¥éª¤")
            state["clarification_questions"] = []
            return state
        
        # åŸæœ‰é€»è¾‘ä¿æŒä¸å˜
        if user_clarifications:
            state["clarification_questions"] = []
            return state
        
        if existing_questions:
            logging.info("ğŸ“ å·²å­˜åœ¨æ¾„æ¸…é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·å›åº”ã€‚")
            # å¦‚æœå·²æœ‰é—®é¢˜ä½†æ— ç”¨æˆ·å›åº”ï¼Œåˆ™ä¸é‡å¤ç”Ÿæˆ
            return state

        logging.info(f"ğŸ¤” æ­£åœ¨ä¸ºç ”ç©¶é¢†åŸŸ '{research_field}' ç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜...")
        
        prompt = CLARIFICATION_QUESTION_PROMPT.format(research_field=research_field)
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        generated_questions_text = response.content.strip()
        questions = [q.strip() for q in generated_questions_text.split('\n') if q.strip()]
        
        if questions:
            state["clarification_questions"] = questions
            logging.info("âœ… æˆåŠŸç”Ÿæˆæ¾„æ¸…æ€§é—®é¢˜ï¼š")
            for i, q in enumerate(questions):
                logging.info(f"  {i+1}. {q}")
            logging.info("ğŸ“¢ è¯·ç”¨æˆ·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜æä¾›å›åº”ï¼Œå¹¶åœ¨ä¸‹æ¬¡è¯·æ±‚æ—¶é€šè¿‡ 'user_clarifications' å­—æ®µä¼ å…¥ã€‚")
        else:
            logging.warning("âš ï¸ æœªèƒ½ä»LLMå“åº”ä¸­è§£æå‡ºæ¾„æ¸…æ€§é—®é¢˜ã€‚")
            state["clarification_questions"] = []
            
        return state

    def create_master_plan_node(self, state: ProposalState) -> ProposalState:
        """é¦–å…ˆåŸºäºé—®é¢˜å»åˆ›å»ºä¸€ä¸ªæ€»ä½“çš„è§„åˆ’"""
        research_field_original = state["research_field"]
        user_clarifications = state.get("user_clarifications", "")
        revision_guidance = state.get("revision_guidance", "")  # è·å–ä¿®è®¢æŒ‡å¯¼
        tools_info = self.get_tools_info_text()

        # --- ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ ---
        logging.info(f"ğŸ” æ­£åœ¨ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¸ '{research_field_original}' ç›¸å…³çš„ä¿¡æ¯...")
        try:
            retrieved_docs = self.long_term_memory.similarity_search(research_field_original, k=2) # æ£€ç´¢æœ€ç›¸å…³çš„2ä¸ª
        except Exception as e:
            logging.warning(f"âš ï¸ ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¿¡æ¯å¤±è´¥: {e}")
            retrieved_docs = []
        
        retrieved_knowledge_text = ""
        if retrieved_docs:
            logging.info(f"âœ… ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ° {len(retrieved_docs)} æ¡ç›¸å…³è®°å½•ã€‚")
            retrieved_knowledge_text += "\n\n### ä¾›å‚è€ƒçš„å†å²ç ”ç©¶é¡¹ç›®æ‘˜è¦\n"
            retrieved_knowledge_text += "è¿™æ˜¯è¿‡å»å®Œæˆçš„ç±»ä¼¼ç ”ç©¶é¡¹ç›®ï¼Œä½ å¯ä»¥å€Ÿé‰´å®ƒä»¬çš„æ€è·¯å’Œç»“è®ºï¼Œä½†ä¸è¦ç…§æ¬ã€‚\n"
            for i, doc in enumerate(retrieved_docs):
                retrieved_knowledge_text += f"\n--- ç›¸å…³å†å²é¡¹ç›® {i+1} ---\n"
                retrieved_knowledge_text += doc.page_content
                retrieved_knowledge_text += "\n--------------------------\n"
        # ------------------------------------

        # --- ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ ---
        logging.info(f"ğŸ” æ­£åœ¨ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¸ '{research_field_original}' ç›¸å…³çš„ä¿¡æ¯...")
        try:
            retrieved_docs = self.long_term_memory.similarity_search(research_field_original, k=2) # æ£€ç´¢æœ€ç›¸å…³çš„2ä¸ª
        except Exception as e:
            logging.warning(f"âš ï¸ ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ä¿¡æ¯å¤±è´¥: {e}")
            retrieved_docs = []
        
        retrieved_knowledge_text = ""
        if retrieved_docs:
            logging.info(f"âœ… ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ° {len(retrieved_docs)} æ¡ç›¸å…³è®°å½•ã€‚")
            retrieved_knowledge_text += "\n\n### ä¾›å‚è€ƒçš„å†å²ç ”ç©¶é¡¹ç›®æ‘˜è¦\n"
            retrieved_knowledge_text += "è¿™æ˜¯è¿‡å»å®Œæˆçš„ç±»ä¼¼ç ”ç©¶é¡¹ç›®ï¼Œä½ å¯ä»¥å€Ÿé‰´å®ƒä»¬çš„æ€è·¯å’Œç»“è®ºï¼Œä½†ä¸è¦ç…§æ¬ã€‚\n"
            for i, doc in enumerate(retrieved_docs):
                retrieved_knowledge_text += f"\n--- ç›¸å…³å†å²é¡¹ç›® {i+1} ---\n"
                retrieved_knowledge_text += doc.page_content
                retrieved_knowledge_text += "\n--------------------------\n"
        # ------------------------------------

        # æ„å»ºæç¤ºæ–‡æœ¬
        prompt_additions = []
        
        if user_clarifications:
            clarification_text= (
                f"\n\né‡è¦å‚è€ƒï¼šç”¨æˆ·ä¸ºè¿›ä¸€æ­¥èšç„¦ç ”ç©¶æ–¹å‘ï¼Œæä¾›äº†ä»¥ä¸‹æ¾„æ¸…ä¿¡æ¯ã€‚åœ¨åˆ¶å®šè®¡åˆ’æ—¶ï¼Œè¯·åŠ¡å¿…ä»”ç»†è€ƒè™‘è¿™äº›å†…å®¹ï¼š\n"
                f"{user_clarifications}\n"
            )
            prompt_additions.append(clarification_text)
            logging.info("ğŸ“ ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ¾„æ¸…ä¿¡æ¯æ¥æŒ‡å¯¼æ€»ä½“è§„åˆ’ã€‚")

        if revision_guidance:
            # æå–ä¿®è®¢æŒ‡å—çš„æ‘˜è¦éƒ¨åˆ†
            revision_summary = ""
            lines = revision_guidance.split("\n")
            in_key_issues = False
            count = 0
            
            for line in lines:
                if "éœ€è¦æ”¹è¿›çš„å…³é”®é—®é¢˜" in line:
                    in_key_issues = True
                    revision_summary += line + "\n"
                    continue
                
                if in_key_issues and line.strip() and not line.startswith("##"):
                    revision_summary += line + "\n"
                    count += 1
                    
                if count > 5 or (in_key_issues and line.startswith("##")):
                    in_key_issues = False
                    
            if not revision_summary:
                # å¦‚æœæ²¡æœ‰æå–åˆ°å…³é”®é—®é¢˜ï¼Œä½¿ç”¨å‰500ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
                revision_summary = revision_guidance[:500] + "...(æ›´å¤šè¯¦ç»†ä¿®è®¢å»ºè®®)"
                
            revision_text = (
                f"\n\nä¿®è®¢æŒ‡å¯¼ï¼šè¯·æ ¹æ®ä»¥ä¸‹ä¿®è®¢å»ºè®®è°ƒæ•´ç ”ç©¶è®¡åˆ’ï¼Œä¿ç•™åŸè®¡åˆ’çš„ä¼˜åŠ¿å¹¶æ”¹è¿›ä¸è¶³ï¼š\n"
                f"{revision_summary}\n"
            )
            prompt_additions.append(revision_text)
            logging.info("ğŸ“ ä½¿ç”¨è¯„å®¡åé¦ˆçš„ä¿®è®¢æŒ‡å¯¼æ¥æ”¹è¿›è®¡åˆ’ã€‚")

        # æ„å»ºå®Œæ•´æç¤º
        base_prompt_template = master_plan_instruction # ä» prompts.py å¯¼å…¥

        lines = base_prompt_template.splitlines()
        new_lines = []
        inserted = False
        for line in lines:
            new_lines.append(line)
            if "{research_field}" in line and prompt_additions:
                # åœ¨åŒ…å« {research_field} çš„è¡Œä¹‹åæ’å…¥æç¤ºä¿¡æ¯
                new_lines.extend(prompt_additions)
                inserted = True
        
        if not inserted and prompt_additions: # åå¤‡ï¼šå¦‚æœå ä½ç¬¦æœªæ‰¾åˆ°ï¼Œåˆ™è¿½åŠ 
            new_lines.extend(prompt_additions)
            
        modified_master_plan_prompt_template = "\n".join(new_lines)
        
        master_planning_prompt = modified_master_plan_prompt_template.format(
            research_field=research_field_original, # æ­¤å¤„ä½¿ç”¨åŸå§‹ç ”ç©¶é¢†åŸŸ
            tools_info=tools_info
        )
        
        # å°†æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯æ•´åˆåˆ°æœ€ç»ˆçš„æç¤ºä¸­
        final_prompt = (
            f"{master_planning_prompt}\n"
            # f"{clarification_text}\n"
            f"{retrieved_knowledge_text}"
        )
        
        logging.info(f"ğŸ¤– Agentæ­£åœ¨ä¸º '{research_field_original}' (å·²è€ƒè™‘ç”¨æˆ·æ¾„æ¸…å’Œå†å²çŸ¥è¯†) åˆ¶å®šæ€»ä½“ç ”ç©¶è®¡åˆ’...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 2,
                                                 self.llm.stream([HumanMessage(content=master_planning_prompt)]))
        state["research_plan"] = full_content
        # response = self.llm.invoke([HumanMessage(content=final_prompt)])
        
        # state["research_plan"] = response.content
        state["available_tools"] = self.tools_description
        state["execution_memory"] = []
        state["history_summary"] = "" # é‡ç½®å†å²æ‘˜è¦
        state["current_step"] = 0
        state["max_iterations"] = 10 

        logging.info("âœ… æ€»ä½“ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ")
        logging.info(f"ç ”ç©¶è®¡åˆ’å†…å®¹ (éƒ¨åˆ†): {state['research_plan'][:300]}...")

        return state
    
    # Ensure this method is correctly indented as part of the ProposalAgent class
    def _decide_after_clarification(self, state: ProposalState) -> str:
        """ç¡®å®šæ¾„æ¸…èŠ‚ç‚¹åçš„ä¸‹ä¸€æ­¥ã€‚"""
        revision_guidance = state.get("revision_guidance", "")
        
        # å¦‚æœæœ‰ä¿®è®¢æŒ‡å¯¼ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€æ­¥
        if revision_guidance:
            logging.info("âœ… æ£€æµ‹åˆ°ä¿®è®¢æŒ‡å¯¼ï¼Œç›´æ¥è¿›å…¥è®¡åˆ’ç”Ÿæˆé˜¶æ®µã€‚")
            return "proceed_to_master_plan"
            
        # åŸæœ‰é€»è¾‘
        if state.get("clarification_questions") and not state.get("user_clarifications"):
            logging.info("â“ Clarification questions generated. Waiting for user input.")
            return "end_for_user_input" 
        logging.info("âœ… No clarification needed or clarifications provided. Proceeding to master plan.")
        return "proceed_to_master_plan"


    def plan_analysis_node(self, state: ProposalState) -> ProposalState:
        """è§£æç ”ç©¶è®¡åˆ’,ç”Ÿæˆå¯æ‰§è¡Œæ­¥éª¤"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        tools_info = self.get_tools_info_text()
        history_summary = state.get("history_summary", "")

        memory_text = ""
        if history_summary:
            memory_text = f"\n\næ‰§è¡Œå†å²æ‘˜è¦:\n{history_summary}\n"
            logging.info("ğŸ§  å·²ä½¿ç”¨å†å²æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡ã€‚")
        else:
            # åªæœ‰åœ¨æ²¡æœ‰æ‘˜è¦æ—¶ï¼Œæ‰ä½¿ç”¨å®Œæ•´çš„æ‰§è¡Œå†å²
            execution_memory = state.get("execution_memory", [])
            if execution_memory:
                memory_text = "\n\nå®Œæ•´æ‰§è¡Œå†å²:\n"
                for step in execution_memory:
                    description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
                    result = step.get('result', 'æ— ç»“æœ')
                    success = step.get('success', False)
                    status = "æˆåŠŸ" if success else "å¤±è´¥"
                    memory_text += f"- {description}: {status} - {result[:100]}...\n"

        
        # é¦–å…ˆè®©Agentåˆ†æè®¡åˆ’ï¼Œç¡®å®šæ£€ç´¢ç­–ç•¥
        plan_analysis_prompt = EXECUTION_PLAN_PROMPT.format(
            research_field=research_field,
            research_plan=research_plan,
            tools_info=tools_info,
            memory_text=memory_text
        )
        logging.info("ğŸ” Agentæ­£åœ¨åˆ†æè®¡åˆ’å¹¶ç”Ÿæˆæ‰§è¡Œæ­¥éª¤...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 1,
                                                 self.llm.stream([HumanMessage(content=plan_analysis_prompt)]))
        # logging.info("ç”Ÿæˆè®¡åˆ’", response.content)
        try:
            # è§£æJSONå“åº”
            full_content = full_content.strip()
            # å¦‚æœå“åº”åŒ…å«```jsonï¼Œåˆ™æå–JSONéƒ¨åˆ†
            if "```json" in full_content:
                start = full_content.find("```json") + 7
                end = full_content.find("```", start)
                if end != -1:
                    full_content = full_content[start:end].strip()
            elif "```" in full_content:
                start = full_content.find("```") + 3
                end = full_content.find("```", start)
                if end != -1:
                    full_content = full_content[start:end].strip()

            plan_data = json.loads(full_content)
            state["execution_plan"] = plan_data.get("steps", [])
        except json.JSONDecodeError:
            logging.error("æ— æ³•è§£ææ‰§è¡Œè®¡åˆ’JSONï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
            logging.error(f"åŸå§‹å“åº”: {full_content}...")
            # é»˜è®¤æ‰§è¡Œè®¡åˆ’
            state["execution_plan"] = [
                {
                    "step_id": 1,
                    "action": "search_arxiv_papers",
                    "parameters": {"query": research_field, "max_results": 5},
                    "description": f"æœç´¢ArXivä¸Šå…³äº{research_field}çš„è®ºæ–‡",
                    "expected_outcome": "æ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡"
                }
            ]

        logging.info(f"âœ… ç”Ÿæˆäº† {len(state['execution_plan'])} ä¸ªæ‰§è¡Œæ­¥éª¤")

        return state
    
    def execute_step_node(self, state: ProposalState) -> ProposalState:
        """æ‰§è¡Œå½“å‰æ­¥éª¤"""
        execution_plan = state.get("execution_plan", [])
        current_step_index = state.get("current_step", 0)
        
        if current_step_index >= len(execution_plan):
            logging.info("æ‰€æœ‰è®¡åˆ’å†…æ­¥éª¤å·²æ‰§è¡Œå®Œæˆï¼Œæ— éœ€è¿›ä¸€æ­¥æ“ä½œã€‚")
            # This case should ideally be caught by should_continue, but as a safeguard:
            return state
        
        # ä½¿ç”¨ç´¢å¼•è·å–å½“å‰æ­¥éª¤ï¼Œä¸ä¿®æ”¹åŸå§‹åˆ—è¡¨
        current_action = execution_plan[current_step_index]
        action_name = current_action.get("action")
        parameters = current_action.get("parameters", {})
        description = current_action.get("description", "")
        
        logging.info(f"ğŸš€ æ‰§è¡Œæ­¥éª¤ {current_step_index + 1}/{len(execution_plan)}: {description}")
        
        result = None
        memory_entry = {}
        try:
            # æ ¹æ®action_nameè°ƒç”¨ç›¸åº”çš„å·¥å…·
            tool_to_call = {
                "search_arxiv_papers": search_arxiv_papers_tool,
                "search_web_content": search_web_content_tool,
                "search_crossref_papers": search_crossref_papers_tool,
                "summarize_pdf": summarize_pdf,
            }.get(action_name)

            if tool_to_call:
                result = tool_to_call.invoke(parameters)
                # ç‰¹å®šäºå·¥å…·çš„çŠ¶æ€æ›´æ–°
                if action_name == "search_arxiv_papers":
                    state["arxiv_papers"].extend(result or [])
                elif action_name in ["search_web_content", "search_crossref_papers"]:
                    state["web_search_results"].extend(result or [])
                elif action_name == "summarize_pdf" and result and "summary" in result:
                     for paper in state["arxiv_papers"]:
                        if paper.get("local_pdf_path") == parameters.get("path"):
                            paper["detailed_summary"] = result["summary"]
                            break
            else:
                result = f"æœªçŸ¥æˆ–ä¸æ”¯æŒçš„ action: {action_name}"
                raise ValueError(result)

            # æ¯æ¬¡æˆåŠŸè·å–æ•°æ®åæ›´æ–°å‚è€ƒæ–‡çŒ®
            state = self.add_references_from_data(state)
            
            memory_entry = {
                "step_id": current_step_index + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": str(result)[:500] if result else "æ— ç»“æœ",
                "success": True,
            }

        except Exception as e:
            logging.error(f"æ‰§è¡Œæ­¥éª¤ '{description}' å¤±è´¥: {e}")
            memory_entry = {
                "step_id": current_step_index + 1,
                "action": f"{action_name}({parameters})",
                "description": description,
                "result": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "success": False,
            }
        
        # æ›´æ–°æ‰§è¡Œå†å²å’Œæ­¥æ•°è®¡æ•°å™¨
        state["execution_memory"].append(memory_entry)
        state["current_step"] = current_step_index + 1
        
        logging.info(f"âœ… æ­¥éª¤ {state['current_step']}/{len(execution_plan)} æ‰§è¡Œå®Œæˆ: {action_name}")
        return state

    def add_references_from_data(self, state: ProposalState) -> ProposalState:
        """ä»æ”¶é›†çš„æ•°æ®ä¸­æå–å¹¶æ·»åŠ å‚è€ƒæ–‡çŒ®"""
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        reference_list = state.get("reference_list", [])
        ref_counter = state.get("ref_counter", 1)

        # å¤„ç†ArXivè®ºæ–‡
        for paper in arxiv_papers:
            if "error" not in paper:
                # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
                paper_title = paper.get('title', 'Unknown')
                existing_ref = next((ref for ref in reference_list if ref.get('title') == paper_title), None)

                if not existing_ref:
                    reference_list.append({
                        "id": ref_counter,
                        "type": "ArXiv",
                        "title": paper_title,
                        "authors": paper.get('authors', []),
                        "published": paper.get('published', 'Unknown'),
                        "arxiv_id": paper.get('arxiv_id', ''),
                        "categories": paper.get('categories', []),
                        "summary": paper.get('detailed_summary', paper.get('summary', ''))  # ä¼˜å…ˆä½¿ç”¨è¯¦ç»†æ‘˜è¦
                    })
                    ref_counter += 1

        # å¤„ç†ç½‘ç»œæœç´¢ç»“æœå’ŒCrossRefç»“æœ
        for result in web_results:
            if "error" not in result:
                result_title = result.get('title', result.get('url', 'Unknown'))
                existing_ref = next((ref for ref in reference_list if ref.get('title') == result_title), None)

                if not existing_ref:
                    # åŒºåˆ†CrossRefå’Œæ™®é€šWebç»“æœ
                    if result.get('doi'):  # CrossRefç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "CrossRef",
                            "title": result_title,
                            "authors": result.get('authors', []),
                            "doi": result.get('doi', ''),
                            "journal": result.get('journal', ''),
                            "published": result.get('published', ''),
                            "url": result.get('url', '')
                        })
                    else:  # æ™®é€šWebç»“æœ
                        reference_list.append({
                            "id": ref_counter,
                            "type": "Web",
                            "title": result_title,
                            "url": result.get('url', ''),
                            "content_preview": result.get('content', result.get('snippet', 'No content'))[:200]
                        })
                    ref_counter += 1

        state["reference_list"] = reference_list
        state["ref_counter"] = ref_counter
        QueueUtil.push_mes(
            StreamMes(state["proposal_id"], 3, f"\nâœ… æˆåŠŸå¤„ç†ä¸‹è½½çš„å‚è€ƒè®ºæ–‡/ç½‘é¡µèµ„æº"))

        return state

    def get_literature_summary_with_refs(self, state: ProposalState, step: int) -> str:
        """è·å–å¸¦æœ‰ç»Ÿä¸€ç¼–å·çš„æ–‡çŒ®æ‘˜è¦"""
        reference_list = state.get("reference_list", [])
        literature_summary = ""

        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        arxiv_refs = [ref for ref in reference_list if ref.get("type") == "ArXiv"]
        web_refs = [ref for ref in reference_list if ref.get("type") == "Web"]

        if arxiv_refs:
            literature_summary += "\n\n**ç›¸å…³Arxivè®ºæ–‡ï¼š**\n"
            for ref in arxiv_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   ä½œè€…: {', '.join(ref['authors'])}\n"
                literature_summary += f"   å‘è¡¨æ—¶é—´: {ref['published']}\n"
                literature_summary += f"   æ‘˜è¦: {ref['summary']}\n"
                literature_summary += f"   åˆ†ç±»: {', '.join(ref['categories'])}\n\n"

        if web_refs:
            literature_summary += "\n**ç›¸å…³ç½‘ç»œä¿¡æ¯ï¼š**\n"
            for ref in web_refs:
                literature_summary += f"[{ref['id']}] {ref['title']}\n"
                literature_summary += f"   æ¥æº: {ref['url']}\n"
                literature_summary += f"   å†…å®¹æ‘˜è¦: {ref['content_preview']}...\n\n"

        QueueUtil.push_mes(StreamMes(state["proposal_id"], step, "\nâœ… æˆåŠŸç”Ÿæˆå¼•ç”¨ç¼–å·\n"))
        return literature_summary

    def generate_reference_section(self, state: ProposalState) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_list = state.get("reference_list", [])

        if not reference_list:
            return ""

        ref_text = "\n\n## å‚è€ƒæ–‡çŒ®\n\n"

        for ref in reference_list:
            if ref["type"] == "ArXiv":
                # ArXivè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                categories_str = ", ".join(ref["categories"]) if ref["categories"] else ""
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. arXiv:{ref['arxiv_id']} ({ref['published']})"
                if categories_str:
                    ref_text += f". Categories: {categories_str}"
                ref_text += "\n\n"
            elif ref["type"] == "CrossRef":
                # CrossRefè®ºæ–‡æ ¼å¼
                authors_str = ", ".join(ref["authors"]) if ref["authors"] else "æœªçŸ¥ä½œè€…"
                ref_text += f"[{ref['id']}] {authors_str}. {ref['title']}. {ref['journal']} ({ref['published']}). DOI: {ref['doi']}\n\n"
            elif ref["type"] == "Web":
                # ç½‘ç»œèµ„æºæ ¼å¼
                ref_text += f"[{ref['id']}] {ref['title']}. è®¿é—®æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}. URL: {ref['url']}\n\n"

        QueueUtil.push_mes(
            StreamMes(state["proposal_id"], 8, "\nâœ… æˆåŠŸç”Ÿæˆå‚è€ƒæ–‡çŒ®"))
        return ref_text

    def write_introduction_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„å¼•è¨€éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]

        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state, step=4)

        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›[1]ï¼Œç‰¹åˆ«æ˜¯åœ¨å½±åƒè¯†åˆ«é¢†åŸŸ[2]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2] çš„æ ¼å¼
        """

        # ä½¿ç”¨prompts.pyä¸­çš„instruction
        introduction_prompt = f"""
        {proposal_introduction_instruction}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        {citation_instruction}

        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„å¼•è¨€éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘600å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜ä»‹ç»ã€é‡è¦æ€§è¯´æ˜ã€ç ”ç©¶ç©ºç™½åˆ°ç ”ç©¶é—®é¢˜çš„æ¨å¯¼
        4. é€‚å½“å¼•ç”¨å·²æ”¶é›†çš„æ–‡çŒ®ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        5. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        6. **ä¸è¦åœ¨å¼•è¨€éƒ¨åˆ†åŒ…å«å‚è€ƒæ–‡çŒ®åˆ—è¡¨**ï¼Œåªåœ¨æ­£æ–‡ä¸­ä½¿ç”¨å¼•ç”¨æ ‡è®°
        7. ä½¿ç”¨`# å¼•è¨€`ä½œä¸ºå¼€å¤´
        """

        logging.info("ğŸ“ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦å¼•è¨€éƒ¨åˆ†...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 4,
                                                 self.llm.stream([HumanMessage(content=introduction_prompt)]))
        # åªä¿å­˜å¼•è¨€æ­£æ–‡ï¼Œä¸åŒ…å«å‚è€ƒæ–‡çŒ®
        state["introduction"] = full_content
        logging.info("âœ… å¼•è¨€éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        return state

    def write_literature_review_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state, step=5)

        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶ã€ç†è®ºæˆ–è§‚ç‚¹æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”ä¸Šè¿°æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•[1,2]ï¼Œä½†åœ¨å¯è§£é‡Šæ€§æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜[3]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨ä¸Šè¿°æä¾›çš„æ–‡çŒ®
        5. å¦‚æœæŸä¸ªè§‚ç‚¹æ¥è‡ªå¤šä¸ªæ–‡çŒ®ï¼Œå¯ä»¥ä½¿ç”¨ [1,2,3] çš„æ ¼å¼
        6. åœ¨è®ºè¿°ä¸åŒè§‚ç‚¹æˆ–ç ”ç©¶å‘ç°æ—¶ï¼Œè¦æ˜ç¡®æ ‡æ³¨æ¥æº
        7. å¯¹äºé‡è¦çš„ç†è®ºæ¡†æ¶æˆ–æ–¹æ³•è®ºï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å¼•è¨€éƒ¨åˆ†çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†é˜…è¯»å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼Œç†è§£å…¶ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜å’Œè¯†åˆ«çš„ç ”ç©¶ç©ºç™½
        2. æ–‡çŒ®ç»¼è¿°åº”è¯¥æ·±åŒ–å’Œæ‹“å±•å¼•è¨€ä¸­ç®€è¦æåŠçš„ç ”ç©¶é¢†åŸŸ
        3. é¿å…é‡å¤å¼•è¨€ä¸­å·²ç»è¯¦ç»†é˜è¿°çš„èƒŒæ™¯ä¿¡æ¯
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°ç ”ç©¶é—®é¢˜"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„..."ç­‰
        5. ç¡®ä¿æ–‡çŒ®ç»¼è¿°çš„ç»“è®ºè‡ªç„¶è¿‡æ¸¡åˆ°å¯¹æ‹Ÿè®®ç ”ç©¶çš„å¿…è¦æ€§è®ºè¯
        6. å¯¹å¼•è¨€ä¸­æåŠçš„å…³é”®æ¦‚å¿µå’Œç†è®ºè¿›è¡Œæ›´æ·±å…¥çš„æ–‡çŒ®åˆ†æ
        """

        # ä½¿ç”¨prompts.pyä¸­çš„LITERATURE_REVIEW_PROMPT
        literature_review_prompt = f"""
        {LITERATURE_REVIEW_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ã€‚
        
        è¦æ±‚ï¼š
        1. å¿…é¡»ä½¿ç”¨ä¸­æ–‡æ’°å†™
        2. è‡³å°‘800å­—
        3. ç»“æ„æ¸…æ™°ï¼ŒæŒ‰ä¸»é¢˜ç»„ç»‡æ–‡çŒ®ï¼Œä¸è¦é€ç¯‡è®ºæ–‡ä»‹ç»
        4. é‡ç‚¹å…³æ³¨ç ”ç©¶è¶‹åŠ¿ã€ä¸»è¦è§‚ç‚¹ã€ç ”ç©¶æ–¹æ³•å’Œå­˜åœ¨çš„äº‰è®®
        5. è¯†åˆ«ç ”ç©¶ç©ºç™½å’Œä¸è¶³ï¼Œä¸ºåç»­ç ”ç©¶æä¾›ä¾æ®
        6. å¿…é¡»åŒ…å«é€‚å½“çš„æ–‡çŒ®å¼•ç”¨ï¼Œä½¿ç”¨ä¸Šè¿°ç¼–å·ç³»ç»Ÿ
        7. è¯­è¨€å­¦æœ¯åŒ–ï¼Œé€‚åˆç ”ç©¶è®¡åˆ’ä¹¦
        8. é¿å…ç®€å•ç½—åˆ—ï¼Œè¦è¿›è¡Œåˆ†æå’Œç»¼åˆ
        9. **ä¸å¼•è¨€éƒ¨åˆ†ä¿æŒè¿è´¯æ€§**ï¼Œé¿å…é‡å¤å†…å®¹ï¼Œæ·±åŒ–å¼•è¨€ä¸­çš„ç ”ç©¶é—®é¢˜
        10. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€è¿æ¥å¼•è¨€éƒ¨åˆ†çš„å†…å®¹
        """

        logging.info("ğŸ“š æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 5,
                                                 self.llm.stream([HumanMessage(content=literature_review_prompt)]))
        # æ³¨æ„ï¼šæ–‡çŒ®ç»¼è¿°ä¸é‡å¤æ·»åŠ å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ï¼Œå› ä¸ºå¼•è¨€å·²ç»åŒ…å«äº†å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
        state["literature_review"] = full_content
        logging.info("âœ… æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        return state

    def write_research_design_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†"""
        research_field = state["research_field"]
        research_plan = state["research_plan"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡çŒ®æ‘˜è¦
        literature_summary = self.get_literature_summary_with_refs(state, step=6)

        # ç”Ÿæˆå¼•ç”¨æŒ‡å¯¼
        citation_instruction = """
        **å¼•ç”¨è¦æ±‚ï¼š**
        1. å½“æåŠç›¸å…³ç ”ç©¶æ–¹æ³•ã€ç†è®ºæ¡†æ¶æˆ–æŠ€æœ¯æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ·»åŠ å¼•ç”¨æ ‡è®°ï¼Œæ ¼å¼ä¸º [ç¼–å·]
        2. å¼•ç”¨æ ‡è®°å¯¹åº”æ–‡çŒ®åˆ—è¡¨ä¸­çš„ç¼–å·
        3. ä¾‹å¦‚ï¼šæœ¬ç ”ç©¶å°†é‡‡ç”¨æ··åˆæ–¹æ³•ç ”ç©¶è®¾è®¡[5]ï¼Œç»“åˆå®šé‡åˆ†æå’Œå®šæ€§è®¿è°ˆ[8,12]ã€‚
        4. ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼Œåªèƒ½å¼•ç”¨å·²æä¾›çš„æ–‡çŒ®
        5. åœ¨æè¿°æ–¹æ³•è®ºä¾æ®æ—¶è¦æ˜ç¡®æ ‡æ³¨æ¥æº
        6. å¯¹äºé‡è¦çš„åˆ†æå·¥å…·å’ŒæŠ€æœ¯æ¡†æ¶ï¼Œå¿…é¡»å¼•ç”¨ç›¸å…³æ–‡çŒ®
        """

        # è¿è´¯æ€§æŒ‡å¯¼
        coherence_instruction = """
        **ä¸å‰æ–‡çš„è¿è´¯æ€§è¦æ±‚ï¼š**
        1. ä»”ç»†åˆ†æå¼•è¨€éƒ¨åˆ†æå‡ºçš„å…·ä½“ç ”ç©¶é—®é¢˜ï¼Œç¡®ä¿ç ”ç©¶è®¾è®¡èƒ½å¤Ÿå›ç­”è¿™äº›é—®é¢˜
        2. åŸºäºæ–‡çŒ®ç»¼è¿°ä¸­è¯†åˆ«çš„æ–¹æ³•è®ºè¶‹åŠ¿å’Œç ”ç©¶ç©ºç™½ï¼Œé€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•
        3. æ‰¿æ¥æ–‡çŒ®ç»¼è¿°ä¸­æåˆ°çš„ç†è®ºæ¡†æ¶å’Œåˆ†ææ–¹æ³•ï¼Œè¯´æ˜å¦‚ä½•åœ¨æœ¬ç ”ç©¶ä¸­åº”ç”¨æˆ–æ”¹è¿›
        4. ä½¿ç”¨æ‰¿æ¥æ€§è¯­è¨€ï¼Œå¦‚"åŸºäºå‰è¿°æ–‡çŒ®åˆ†æ"ã€"é’ˆå¯¹å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜"ã€"å€Ÿé‰´æ–‡çŒ®ç»¼è¿°ä¸­çš„..."ç­‰
        5. ç¡®ä¿ç ”ç©¶è®¾è®¡çš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½ä¸å‰æ–‡å»ºç«‹çš„ç ”ç©¶èƒŒæ™¯å’Œç†è®ºåŸºç¡€ç›¸å‘¼åº”
        6. æ˜ç¡®è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©çš„æ–¹æ³•é€‚åˆè§£å†³å¼•è¨€ä¸­æå‡ºçš„ç ”ç©¶é—®é¢˜
        """

        # ä½¿ç”¨prompts.pyä¸­çš„PROJECT_DESIGN_PROMPT
        research_design_prompt = f"""
        {PROJECT_DESIGN_PROMPT.format(research_field=research_field)}
        
        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}
        
        **ç ”ç©¶è®¡åˆ’æ¦‚è¦ï¼š**
        {research_plan}
        
        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†ï¼š**
        {introduction_content}
        
        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†ï¼š**
        {literature_review_content}
        
        **å·²æ”¶é›†çš„æ–‡çŒ®å’Œä¿¡æ¯ï¼ˆç”¨äºå¯èƒ½çš„å¼•ç”¨ï¼‰ï¼š**
        {literature_summary}
        
        {citation_instruction}
        
        {coherence_instruction}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§instructionçš„è¦æ±‚ï¼Œä¸º"{research_field}"è¿™ä¸ªç ”ç©¶ä¸»é¢˜æ’°å†™ä¸€ä¸ªå­¦æœ¯è§„èŒƒçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†ã€‚
        é‡ç‚¹å…³æ³¨ç ”ç©¶æ•°æ®ã€æ–¹æ³•ã€å·¥ä½œæµç¨‹å’Œå±€é™æ€§ã€‚
        å¿…é¡»**ä½¿ç”¨ä¸­æ–‡æ’°å†™**
        **ä¸è¦åŒ…å«æ—¶é—´å®‰æ’æˆ–é¢„æœŸæˆæœæ€»ç»“ï¼Œè¿™äº›å°†åœ¨ç»“è®ºéƒ¨åˆ†ç»Ÿä¸€é˜è¿°ã€‚**
        """

        logging.info("ğŸ”¬ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç ”ç©¶è®¾è®¡éƒ¨åˆ†...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 6,
                                                 self.llm.stream([HumanMessage(content=research_design_prompt)]))

        state["research_design"] = full_content
        logging.info("âœ… ç ”ç©¶è®¾è®¡éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        return state

    def write_conclusion_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦çš„ç»“è®ºéƒ¨åˆ†"""
        research_field = state["research_field"]
        introduction_content = state.get("introduction", "")
        literature_review_content = state.get("literature_review", "")
        research_design_content = state.get("research_design", "")

        conclusion_prompt_text = f"""
        {CONCLUSION_PROMPT.format(research_field=research_field)}

        **ç ”ç©¶ä¸»é¢˜ï¼š** {research_field}

        **å·²å®Œæˆçš„å¼•è¨€éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç ”ç©¶é—®é¢˜å’ŒèƒŒæ™¯ï¼‰ï¼š**
        {introduction_content[:1000]}... 

        **å·²å®Œæˆçš„æ–‡çŒ®ç»¼è¿°éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾ç†è®ºæ¡†æ¶ï¼‰ï¼š**
        {literature_review_content[:1000]}...

        **å·²å®Œæˆçš„ç ”ç©¶è®¾è®¡éƒ¨åˆ†æ‘˜è¦ï¼ˆç”¨äºå›é¡¾æ–¹æ³•å’Œæµç¨‹ï¼‰ï¼š**
        {research_design_content[:1000]}...

        è¯·åŸºäºä»¥ä¸Šæä¾›çš„å¼•è¨€ã€æ–‡çŒ®ç»¼è¿°å’Œç ”ç©¶è®¾è®¡å†…å®¹ï¼Œæ’°å†™ä¸€ä¸ªè¿è´¯çš„ç»“è®ºéƒ¨åˆ†ã€‚
        ç»“è®ºåº”åŒ…å«æ—¶é—´è½´ã€é¢„æœŸæˆæœå’Œæœ€ç»ˆæ€»ç»“ã€‚
        ç¡®ä¿ç»“è®ºä¸å‰é¢ç« èŠ‚æå‡ºçš„ç ”ç©¶é—®é¢˜ã€æ–¹æ³•è®ºå’Œç›®æ ‡ä¿æŒä¸€è‡´ã€‚
        å¿…é¡»ä½¿ç”¨**ä¸­æ–‡**æ’°å†™
        """

        logging.info("ğŸ“œ æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦ç»“è®ºéƒ¨åˆ†...")
        full_content = stream_mes_2_full_content(state["proposal_id"], 7,
                                                 self.llm.stream([HumanMessage(content=conclusion_prompt_text)]))
        state["conclusion"] = full_content
        logging.info("âœ… ç»“è®ºéƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        return state

    def generate_final_references_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„å‚è€ƒæ–‡çŒ®éƒ¨åˆ†"""
        reference_section = self.generate_reference_section(state)

        # å°†å‚è€ƒæ–‡çŒ®ä½œä¸ºç‹¬ç«‹éƒ¨åˆ†ä¿å­˜
        state["final_references"] = reference_section
        logging.info("âœ… å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ç”Ÿæˆå®Œæˆ")

        return state

    def generate_final_report_node(self, state: ProposalState) -> ProposalState:
        """ç”Ÿæˆæœ€ç»ˆçš„Markdownç ”ç©¶è®¡åˆ’ä¹¦æŠ¥å‘Š"""
        start_timestamp = time.time()
        QueueUtil.push_mes(StreamMes(state['proposal_id'], 9, "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”ç©¶è®¡åˆ’æŠ¥å‘Š~"))
        logging.info("ğŸ“„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆçš„ç ”ç©¶è®¡åˆ’ä¹¦MarkdownæŠ¥å‘Š...")

        research_field = state.get("research_field", "æœªçŸ¥é¢†åŸŸ")
        introduction = state.get("introduction", "æ— å¼•è¨€å†…å®¹")
        literature_review = state.get("literature_review", "æ— æ–‡çŒ®ç»¼è¿°å†…å®¹")
        research_design = state.get("research_design", "æ— ç ”ç©¶è®¾è®¡å†…å®¹")
        conclusion = state.get("conclusion", "æ— ç»“è®ºå†…å®¹")
        final_references = state.get("final_references", "æ— å‚è€ƒæ–‡çŒ®")

        research_plan = state.get("research_plan", "æ— åˆå§‹ç ”ç©¶è®¡åˆ’")
        execution_memory = state.get("execution_memory", [])

        # åˆ›å»ºoutputæ–‡ä»¶å¤¹
        output_dir = "./output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # ç”¨uuidæ›¿æ¢æ—¶é—´æˆ³
        uuid = state["proposal_id"]
        # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_research_field = "".join(
            c for c in research_field if c.isalnum() or c in (' ', '-', '_')).rstrip().replace(' ', '_')[:30]
        report_filename = f"Research_Proposal_{safe_research_field}_{uuid}.md"
        report_filepath = os.path.join(output_dir, report_filename)

        # æ„å»ºMarkdownå†…å®¹
        report_content = f"# ç ”ç©¶è®¡åˆ’ä¹¦ï¼š{research_field}\n\n"

        # report_content += "## 1. å¼•è¨€\n\n"
        report_content += f"{introduction}\n\n"

        # report_content += "## 2. æ–‡çŒ®ç»¼è¿°\n\n"
        report_content += f"{literature_review}\n\n"

        # report_content += "## 3. ç ”ç©¶è®¾è®¡ä¸æ–¹æ³•\n\n"
        report_content += f"{research_design}\n\n"

        # report_content += "## 4. ç»“è®ºä¸å±•æœ›\n\n" # ç»“è®ºéƒ¨åˆ†å·²åŒ…å«æ—¶é—´è½´å’Œé¢„æœŸæˆæœ
        report_content += f"{conclusion}\n\n"

        report_content += f"{final_references}\n\n"  # å‚è€ƒæ–‡çŒ®éƒ¨åˆ†è‡ªå¸¦ "## å‚è€ƒæ–‡çŒ®" æ ‡é¢˜

        report_content += "---\n"
        report_content += "## é™„å½•ï¼šè¿‡ç¨‹èµ„æ–™\n\n"

        report_content += "### A.1 åˆå§‹ç ”ç©¶è®¡åˆ’\n\n"
        report_content += "```markdown\n"
        report_content += f"{research_plan}\n"
        report_content += "```\n\n"

        report_content += "### A.2 æ‰§è¡Œæ­¥éª¤è®°å½•\n\n"
        if execution_memory:
            for i, step_memory in enumerate(execution_memory):
                action = step_memory.get("action", "æœªçŸ¥åŠ¨ä½œ")
                desc = step_memory.get("description", "æ— æè¿°")
                res = step_memory.get("result", "æ— ç»“æœ")
                success_status = "æˆåŠŸ" if step_memory.get("success") else "å¤±è´¥"
                report_content += f"**æ­¥éª¤ {i + 1}: {desc}** ({action})\n"
                report_content += f"- çŠ¶æ€: {success_status}\n"
                report_content += f"- ç»“æœæ‘˜è¦: {str(res)[:150]}...\n\n"
        else:
            report_content += "æ— æ‰§è¡Œè®°å½•ã€‚\n\n"

        report_content += "### A.3 æ”¶é›†çš„æ–‡çŒ®ä¸ä¿¡æ¯æ‘˜è¦\n\n"
        report_content += self.get_literature_summary_with_refs(state, 9) + "\n\n"

        try:
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
            logging.info(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")
            state["final_report_markdown"] = report_content
            QueueUtil.push_mes(StreamMes(state['proposal_id'], 9, "\nâœ… æŠ¥å‘Šç”Ÿæˆå®Œæ¯•"))
            # ç»“æŸæ ‡è®°
            QueueUtil.push_mes(StreamMes(state['proposal_id'], 0, ""))
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜æœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            state["final_report_markdown"] = "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"
            QueueUtil.push_mes(StreamMes(state['proposal_id'], 9, "\nâŒ  æŠ¥å‘Šç”Ÿæˆå¤±è´¥"))

        return state

    def should_continue(self, state: ProposalState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œæˆ–è¿›å…¥å†™ä½œé˜¶æ®µ"""
    
        # 1. é¦–å…ˆæ£€æŸ¥æ¾„æ¸…é—®é¢˜çŠ¶æ€ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        if state.get("clarification_questions") and not state.get("user_clarifications"):
            # å¦‚æœæœ‰æ¾„æ¸…é—®é¢˜ä½†ç”¨æˆ·æœªå›åº”ï¼Œç»§ç»­æ‰§è¡Œä½†å¯èƒ½æ•ˆæœä¸ä½³
            logging.info("â³ æ£€æµ‹åˆ°æœªå›åº”çš„æ¾„æ¸…é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œæµç¨‹")
            pass

        # 2. è·å–åŸºæœ¬çŠ¶æ€ä¿¡æ¯
        current_step_index = state.get("current_step", 0)
        execution_plan = state.get("execution_plan", [])
        execution_memory = state.get("execution_memory", [])
        max_iterations = state.get("max_iterations", 10)
        max_steps = len(execution_plan)

        # 3. æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆå®‰å…¨ä¸Šé™ï¼‰
        if len(execution_memory) >= max_iterations:
            logging.info(f"ğŸ›‘ è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ¬¡æ•° ({max_iterations})ï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"
        
        # 4. æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è®¡åˆ’æ­¥éª¤éƒ½å·²å®Œæˆ
        if current_step_index >= max_steps:
            logging.info("âœ… æ‰€æœ‰è®¡åˆ’å†…æ­¥éª¤å·²æ‰§è¡Œå®Œæˆï¼Œè¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"

        # 5. æ¯æ‰§è¡Œ1æ­¥åè¿›è¡Œå†å²æ‘˜è¦ï¼ˆå¯é…ç½®ï¼‰
        summarize_interval = 1  # å¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼
        if current_step_index > 0 and current_step_index % summarize_interval == 0:
            logging.info(f"ğŸ“ æ‰§è¡Œäº† {current_step_index} æ­¥ï¼Œæ­£åœ¨ç”Ÿæˆå†å²æ‘˜è¦...")
            return "summarize"

        # 6. æ£€æŸ¥æ˜¯å¦æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ï¼ˆæå‰ç»“æŸæ¡ä»¶ï¼‰
        arxiv_papers = state.get("arxiv_papers", [])
        web_results = state.get("web_search_results", [])
        
        if len(arxiv_papers) >= 5 and len(web_results) >= 5:
            logging.info(f"ğŸ“š å·²æ”¶é›†å……è¶³ä¿¡æ¯ ({len(arxiv_papers)} ç¯‡è®ºæ–‡, {len(web_results)} æ¡ç½‘ç»œç»“æœ)ï¼Œæå‰è¿›å…¥å†™ä½œé˜¶æ®µ")
            return "end_report"

        # 7. æ£€æŸ¥æœ€è¿‘æ‰§è¡Œç»“æœè´¨é‡ï¼ˆæ™ºèƒ½é‡è§„åˆ’ï¼‰
        if len(execution_memory) >= 3:
            recent_results = execution_memory[-3:]
            successful_results = [r for r in recent_results if r.get("success", False)]
            
            # å¦‚æœæœ€è¿‘3æ­¥ä¸­æˆåŠŸç‡ä½äº30%ï¼Œè€ƒè™‘é‡æ–°è§„åˆ’
            if len(successful_results) < len(recent_results) * 0.3:
                logging.info("âš ï¸ æœ€è¿‘æ‰§è¡ŒæˆåŠŸç‡è¾ƒä½ï¼Œé‡æ–°è§„åˆ’...")
                state["current_step"] = 0  # é‡ç½®æ­¥æ•°è®¡æ•°å™¨
                return "plan_analysis"

        # 8. é»˜è®¤ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
        logging.info(f"ğŸš€ ç»§ç»­æ‰§è¡Œæ­¥éª¤ {current_step_index + 1}/{max_steps}")
        return "continue"
    
    
    
    def _build_workflow(self) -> StateGraph: # This method uses _decide_after_clarification
        """æ„å»ºå·¥ä½œæµå›¾"""
        workflow = StateGraph(ProposalState)

        # 1. å®šä¹‰æ‰€æœ‰èŠ‚ç‚¹
        workflow.add_node("clarify_focus", self.clarify_research_focus_node)
        workflow.add_node("create_master_plan", self.create_master_plan_node)
        workflow.add_node("plan_analysis", self.plan_analysis_node)
        workflow.add_node("execute_step", self.execute_step_node)
        workflow.add_node("summarize_history", self.summarize_history_node) # çŸ­æœŸè®°å¿†èŠ‚ç‚¹
        workflow.add_node("add_references", self.add_references_from_data)

        # æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
        workflow.add_node("write_introduction", self.write_introduction_node)
        workflow.add_node("write_literature_review", self.write_literature_review_node)
        workflow.add_node("write_research_design", self.write_research_design_node)
        workflow.add_node("write_conclusion", self.write_conclusion_node)
        workflow.add_node("generate_final_references", self.generate_final_references_node)
        workflow.add_node("generate_final_report", self.generate_final_report_node)
        workflow.add_node("save_memory", self.save_to_long_term_memory_node) # é•¿æœŸè®°å¿†èŠ‚ç‚¹

        # 2. è®¾ç½®å›¾çš„å…¥å£ç‚¹
        workflow.set_entry_point("clarify_focus")

        # 3. å®šä¹‰å›¾çš„è¾¹ï¼ˆæµç¨‹ï¼‰
        workflow.add_conditional_edges(
            "clarify_focus",
            self._decide_after_clarification,
            {
                "end_for_user_input": END,
                "proceed_to_master_plan": "create_master_plan"
            }
        )
        
        workflow.add_edge("create_master_plan", "plan_analysis")
        
        # ç”Ÿæˆè®¡åˆ’åï¼Œç›´æ¥è¿›å…¥æ‰§è¡Œ
        workflow.add_edge("plan_analysis", "execute_step")
        
        # æ ¸å¿ƒæ‰§è¡Œå¾ªç¯
        workflow.add_conditional_edges(
            "execute_step",
            self.should_continue,
            {
                "continue": "execute_step", # <-- æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥è¿”å›æ‰§è¡Œä¸‹ä¸€æ­¥
                "plan_analysis": "plan_analysis", # å¦‚æœéœ€è¦é‡æ–°è§„åˆ’
                "summarize": "summarize_history",
                "end_report": "add_references" # ç»“æŸå¾ªç¯ï¼Œå¼€å§‹æ•´åˆæŠ¥å‘Š

            }
        )
        
        # çŸ­æœŸè®°å¿†å¾ªç¯
        workflow.add_edge("summarize_history", "execute_step") # <-- æ ¸å¿ƒä¿®æ”¹ï¼šæ‘˜è¦åè¿”å›æ‰§è¡Œä¸‹ä¸€æ­¥

        # æŠ¥å‘Šç”Ÿæˆæµç¨‹
        workflow.add_edge("add_references", "write_introduction")
        workflow.add_edge("write_introduction", "write_literature_review")
        workflow.add_edge("write_literature_review", "write_research_design")
        workflow.add_edge("write_research_design", "write_conclusion")
        workflow.add_edge("write_conclusion", "generate_final_references")
        workflow.add_edge("generate_final_references", "generate_final_report")

        # æœ€åï¼Œä¿å­˜åˆ°é•¿æœŸè®°å¿†å¹¶ç»“æŸ
        workflow.add_edge("generate_final_report", "save_memory")
        workflow.add_edge("save_memory", END)
        
        # 4. ç¼–è¯‘å›¾
        return workflow.compile(checkpointer=MemorySaver())


    def generate_proposal(self, research_field: str, proposal_id: str,user_clarifications: str = "", revision_guidance: str = "") -> Dict[str, Any]:
        """ç”Ÿæˆç ”ç©¶è®¡åˆ’ä¹¦"""
        if not proposal_id:
            proposal_id = f"proposal_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        config = {"configurable": {"thread_id": proposal_id}}

        initial_state = {
            "research_field": research_field,
            "user_clarifications": user_clarifications, # æ–°å¢ï¼šæ¥æ”¶ç”¨æˆ·æ¾„æ¸…
            "revision_guidance": revision_guidance,
            "proposal_id": proposal_id,  # æ–°å¢ï¼šå”¯ä¸€æ ‡è¯†ç¬¦
            "clarification_questions": [], # æ–°å¢ï¼šåˆå§‹åŒ–æ¾„æ¸…é—®é¢˜åˆ—è¡¨
            "query": "",
            "arxiv_papers": [],
            "web_search_results": [],
            "background": "",
            "objectives": "",
            "methodology": "",
            "timeline": "",
            "expected_outcomes": "",
            "final_proposal": "",
            "messages": [],
            "research_plan": "",
            "available_tools": [],
            "execution_plan": [],
            "execution_memory": [],
            "current_step": 0,
            "max_iterations": 10,
            "introduction": "",
            "literature_review": "",
            "research_design": "",
            "timeline_plan": "",
            "expected_results": "",
            "reference_list": [],  # åˆå§‹åŒ–ç»Ÿä¸€å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            "ref_counter": 1,      # åˆå§‹åŒ–å‚è€ƒæ–‡çŒ®è®¡æ•°å™¨
            "final_references": "",
            "conclusion": "",
            "final_report_markdown": "" # åˆå§‹åŒ–æœ€ç»ˆæŠ¥å‘Šå­—æ®µ
        }
        
        logging.info(f"ğŸš€ å¼€å§‹å¤„ç†ç ”ç©¶é—®é¢˜: '{research_field}' (ä»»åŠ¡ID: {proposal_id})")
        
        
        QueueUtil.new_queue(proposal_id)  # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
        result = self.workflow.invoke(initial_state,config=config)
        clarification_questions = result.get("clarification_questions", [])
        if clarification_questions:
            logging.info(" agentç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥")
            return {"clarification_questions": clarification_questions}
        
        return result

    def summarize_history_node(self, state: ProposalState) -> ProposalState:
        """
        å›é¡¾æ‰§è¡Œå†å²å¹¶ç”Ÿæˆæ‘˜è¦ã€‚
        é‡‡ç”¨å¢é‡å¼æ‘˜è¦ç­–ç•¥ï¼šåŸºäºæ—§çš„æ‘˜è¦å’Œæœ€æ–°çš„ä¸€æ­¥æ¥ç”Ÿæˆæ–°æ‘˜è¦ã€‚
        """
        logging.info("ğŸ§  å¼€å§‹ç”Ÿæˆå¢é‡å¼æ‰§è¡Œå†å²æ‘˜è¦...")
        
        execution_memory = state.get("execution_memory", [])
        if not execution_memory:
            return state # å¦‚æœæ²¡æœ‰å†å²ï¼Œåˆ™è·³è¿‡

        old_summary = state.get("history_summary", "")
        latest_step = execution_memory[-1] # åªå–æœ€æ–°çš„ä¸€æ­¥

        # å°†æœ€æ–°æ­¥éª¤æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
        latest_step_text = (
            f"- æè¿°: {latest_step.get('description', 'N/A')}\n"
            f"- åŠ¨ä½œ: {latest_step.get('action', 'N/A')}\n"
            f"- ç»“æœ: {'æˆåŠŸ' if latest_step.get('success') else 'å¤±è´¥'}\n"
            f"- è¯¦æƒ…: {str(latest_step.get('result', ''))[:200]}..."
        )

        # å¦‚æœæ²¡æœ‰æ—§æ‘˜è¦ï¼ˆè¿™æ˜¯ç¬¬ä¸€æ¬¡æ€»ç»“ï¼‰ï¼Œåˆ™å¯¹ç›®å‰æ‰€æœ‰çš„å†å²è¿›è¡Œæ€»ç»“
        if not old_summary:
            prompt_template = """
            ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©ç†ï¼Œæ­£åœ¨ä¸ºä¸€é¡¹å¤æ‚çš„ç§‘ç ”ä»»åŠ¡æ’°å†™ç¬¬ä¸€ä»½è¿›åº¦æ‘˜è¦ã€‚
            è¯·æ ¹æ®ä»¥ä¸‹åˆ°ç›®å‰ä¸ºæ­¢çš„æ‰€æœ‰æ‰§è¡Œå†å²ï¼Œç”Ÿæˆä¸€æ®µç®€æ´ã€ç²¾ç‚¼çš„æ‘˜è¦ã€‚
            æ‘˜è¦éœ€è¦æ•æ‰åˆ°å…³é”®å‘ç°ã€é‡åˆ°çš„ä¸»è¦éšœç¢æˆ–å¤±è´¥ï¼Œä»¥åŠå°šæœªè§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

            åŸå§‹ç ”ç©¶é—®é¢˜: {research_field}
            
            æ‰§è¡Œå†å²:
            {history}

            è¯·è¾“å‡ºæ‘˜è¦:
            """
            # æ ¼å¼åŒ–å®Œæ•´çš„å†å²è®°å½•
            full_history_text = "\n".join([
                f"- æ­¥éª¤ {i+1}: {mem.get('description', 'N/A')}, ç»“æœ: {'æˆåŠŸ' if mem.get('success') else 'å¤±è´¥'}, è¯¦æƒ…: {str(mem.get('result', ''))[:150]}..."
                for i, mem in enumerate(execution_memory)
            ])
            prompt = prompt_template.format(
                research_field=state['research_field'],
                history=full_history_text
            )
        else:
            # å¦‚æœæœ‰æ—§æ‘˜è¦ï¼Œåˆ™è¿›è¡Œå¢é‡æ›´æ–°
            prompt_template = """
            ä½ æ˜¯ä¸€ä¸ªç ”ç©¶åŠ©ç†ï¼Œæ­£åœ¨å®æ—¶æ›´æ–°ä¸€ä»½ä»»åŠ¡è¿›åº¦æ‘˜è¦ã€‚
            ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€ä¸Šä¸€ç‰ˆçš„æ‘˜è¦ã€‘å’Œã€æœ€æ–°å®Œæˆçš„æ­¥éª¤ã€‘ï¼Œç”Ÿæˆä¸€ä»½ã€æ›´æ–°åçš„æ‘˜è¦ã€‘ã€‚
            è¯·ä¸è¦é‡å¤æ—§æ‘˜è¦å·²æœ‰çš„ä¿¡æ¯ï¼Œé‡ç‚¹åœ¨äºæ•´åˆæ–°ä¿¡æ¯å¹¶æç‚¼å‡ºå½“å‰æœ€å…³é”®çš„å‘ç°ã€éšœç¢å’Œç»“è®ºã€‚

            ã€ä¸Šä¸€ç‰ˆçš„æ‘˜è¦ã€‘:
            {old_summary}

            ã€æœ€æ–°å®Œæˆçš„æ­¥éª¤ã€‘:
            {latest_step}

            è¯·è¾“å‡ºä¸€ä»½ç®€æ´ã€è¿è´¯çš„ã€æ›´æ–°åçš„æ‘˜è¦ã€‘:
            """
            prompt = prompt_template.format(
                old_summary=old_summary,
                latest_step=latest_step_text
            )

        response = self.llm.invoke([SystemMessage(content=prompt)])
        summary = response.content.strip()
        
        state["history_summary"] = summary
        logging.info(f"âœ… ç”Ÿæˆæ‘˜è¦å®Œæˆ: {summary}")
        
        return state

    def save_to_long_term_memory_node(self, state: ProposalState) -> ProposalState:
        """å°†æœ€ç»ˆæŠ¥å‘Šçš„æ ¸å¿ƒæ´å¯Ÿå­˜å…¥é•¿æœŸè®°å¿†"""
        logging.info("ğŸ’¾ æ­£åœ¨å°†æœ¬æ¬¡ç ”ç©¶æˆæœå­˜å…¥é•¿æœŸè®°å¿†...")
        
        proposal_id = state.get("proposal_id")
        if not proposal_id:
            logging.warning("âš ï¸ proposal_id ä¸å­˜åœ¨ï¼Œæ— æ³•å­˜å…¥é•¿æœŸè®°å¿†ã€‚")
            return state

        # ç”Ÿæˆä¸€ä¸ªç”¨äºå­˜å‚¨çš„æ–‡æ¡£
        document_to_store = f"""
        ç ”ç©¶è¯¾é¢˜: {state.get('research_field')}
        ç”¨æˆ·æ¾„æ¸…: {state.get('user_clarifications', 'æ— ')}
        æœ€ç»ˆç ”ç©¶è®¡åˆ’æ‘˜è¦: {state.get('research_plan', '')[:500]}...
        å¼•è¨€æ ¸å¿ƒ: {state.get('introduction', '')[:500]}...
        æ–‡çŒ®ç»¼è¿°è¦ç‚¹: {state.get('literature_review', '')[:500]}...
        æœ€ç»ˆç»“è®º: {state.get('conclusion', '')[:500]}...
        """
        
        try:
            self.long_term_memory.add_texts(
                texts=[document_to_store],
                metadatas=[{"proposal_id": proposal_id, "timestamp": datetime.now().isoformat()}],
                ids=[proposal_id] # ä½¿ç”¨ proposal_id ä½œä¸ºå”¯ä¸€æ ‡è¯†
            )
            # ChromaDB in-memory with persist_directory handles saving automatically on updates.
            # self.long_term_memory.persist() # æ˜¾å¼è°ƒç”¨ persist() å¯èƒ½ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¯ä»¥ç¡®ä¿å†™å…¥
            logging.info(f"âœ… æˆåŠŸå°† proposal_id '{proposal_id}' å­˜å…¥é•¿æœŸè®°å¿†ã€‚")
        except Exception as e:
            logging.error(f"âŒ å­˜å…¥é•¿æœŸè®°å¿†å¤±è´¥: {e}")
        
        return state
